[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 84, "makespan": 24, "avg_agents_density": 0.027659445011392773, "runtime": 0.46874382672831416}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-000"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 74, "makespan": 21, "avg_agents_density": 0.02643531608470365, "runtime": 0.5199499190784991}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-001"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 78, "makespan": 19, "avg_agents_density": 0.033614111148605394, "runtime": 0.47100303368642926}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-002"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 145, "makespan": 28, "avg_agents_density": 0.028091476323349063, "runtime": 0.6959268813952804}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-003"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 113, "makespan": 32, "avg_agents_density": 0.03093545744529931, "runtime": 1.0695171104744077}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-004"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 113, "makespan": 25, "avg_agents_density": 0.032424402784926226, "runtime": 0.6518302904441953}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-005"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 77, "makespan": 19, "avg_agents_density": 0.031298266961925496, "runtime": 0.45525806304067373}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-006"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 161, "makespan": 37, "avg_agents_density": 0.0381261901399465, "runtime": 0.9052059929817915}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-007"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 175, "makespan": 33, "avg_agents_density": 0.03302020527146583, "runtime": 1.1120120040141046}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-008"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 120, "makespan": 28, "avg_agents_density": 0.031042125537968958, "runtime": 0.7075643371790648}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-009"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 95, "makespan": 33, "avg_agents_density": 0.026490999459234055, "runtime": 0.803567330352962}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-010"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 119, "makespan": 25, "avg_agents_density": 0.04032950290467666, "runtime": 0.5636066440492868}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-011"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 170, "makespan": 37, "avg_agents_density": 0.04195539139756933, "runtime": 1.2315031392499804}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-012"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 143, "makespan": 32, "avg_agents_density": 0.025952947725627798, "runtime": 0.7848178772255778}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-013"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 118, "makespan": 26, "avg_agents_density": 0.039252763306847266, "runtime": 0.652034645434469}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-014"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 146, "makespan": 26, "avg_agents_density": 0.04484878690724088, "runtime": 0.6442765966057777}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-015"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 15, "SoC": 71, "makespan": 16, "avg_agents_density": 0.03259314134678289, "runtime": 0.5305735520087183}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-016"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 96, "makespan": 23, "avg_agents_density": 0.03479005274061481, "runtime": 0.5665542115457356}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-017"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 141, "makespan": 31, "avg_agents_density": 0.022868189713747357, "runtime": 0.7207115767523646}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-018"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 148, "makespan": 29, "avg_agents_density": 0.03667841633188332, "runtime": 0.7197541068308055}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-019"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 135, "makespan": 29, "avg_agents_density": 0.03242275440512574, "runtime": 0.7007033452391624}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-020"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 136, "makespan": 27, "avg_agents_density": 0.03301909144815863, "runtime": 0.9247141741216183}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-021"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 139, "makespan": 31, "avg_agents_density": 0.03302548381005618, "runtime": 0.7680694735608995}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-022"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 112, "makespan": 24, "avg_agents_density": 0.038071470677970586, "runtime": 0.7162925661541522}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-023"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 19, "SoC": 117, "makespan": 20, "avg_agents_density": 0.027060403871409382, "runtime": 0.6245733737014234}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-024"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 19, "SoC": 95, "makespan": 20, "avg_agents_density": 0.039196999364233785, "runtime": 0.6899957968853414}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-025"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 110, "makespan": 28, "avg_agents_density": 0.03304451891952031, "runtime": 0.6481657098047435}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-026"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 98, "makespan": 22, "avg_agents_density": 0.03263666875833821, "runtime": 0.5591872832737863}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-027"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 183, "makespan": 36, "avg_agents_density": 0.0283314381556963, "runtime": 0.9030174682848155}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-028"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 137, "makespan": 25, "avg_agents_density": 0.025080919441428432, "runtime": 1.0167070110328496}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-029"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 117, "makespan": 27, "avg_agents_density": 0.04129086770816127, "runtime": 0.6458864039741457}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-030"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 99, "makespan": 22, "avg_agents_density": 0.03236192188918882, "runtime": 0.5558295305818319}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-031"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 117, "makespan": 24, "avg_agents_density": 0.026327478301077845, "runtime": 0.5905362078920007}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-032"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 170, "makespan": 33, "avg_agents_density": 0.03013339132343654, "runtime": 0.8440324636176229}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-033"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 110, "makespan": 26, "avg_agents_density": 0.041443242304812285, "runtime": 0.8622889989055693}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-034"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 107, "makespan": 21, "avg_agents_density": 0.03693449922306266, "runtime": 0.5125477900728583}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-035"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 109, "makespan": 23, "avg_agents_density": 0.04642922510147368, "runtime": 0.7942729163914919}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-036"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 122, "makespan": 32, "avg_agents_density": 0.03315361846937734, "runtime": 0.7194265490397811}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-037"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 123, "makespan": 22, "avg_agents_density": 0.028747730729864168, "runtime": 0.5500946161337197}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-038"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 87, "makespan": 25, "avg_agents_density": 0.025126376094868005, "runtime": 0.6137843672186136}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-039"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 92, "makespan": 19, "avg_agents_density": 0.024734044758766977, "runtime": 0.4985872972756624}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-040"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 142, "makespan": 29, "avg_agents_density": 0.029687119531017946, "runtime": 0.7513112328015268}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-041"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 136, "makespan": 23, "avg_agents_density": 0.03690681548374864, "runtime": 0.5632412978447974}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-042"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 102, "makespan": 24, "avg_agents_density": 0.03226787442205806, "runtime": 0.6545862085185945}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-043"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 110, "makespan": 23, "avg_agents_density": 0.03771167087069905, "runtime": 0.819120196159929}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-044"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 80, "makespan": 27, "avg_agents_density": 0.03595042402612096, "runtime": 0.9584479546174407}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-045"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 113, "makespan": 22, "avg_agents_density": 0.03743860077661196, "runtime": 0.5176935847848654}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-046"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 136, "makespan": 29, "avg_agents_density": 0.03996528703868913, "runtime": 0.7380797644145787}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-047"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 116, "makespan": 24, "avg_agents_density": 0.04712013613829462, "runtime": 0.6254706401377916}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-048"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 121, "makespan": 22, "avg_agents_density": 0.04215002899665352, "runtime": 0.8050707210786641}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-049"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 134, "makespan": 33, "avg_agents_density": 0.03433577074505786, "runtime": 0.807636084035039}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-050"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 115, "makespan": 23, "avg_agents_density": 0.03300210139911791, "runtime": 0.5461797257885337}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-051"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 123, "makespan": 27, "avg_agents_density": 0.021477856209837016, "runtime": 0.7833615867421031}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-052"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 123, "makespan": 26, "avg_agents_density": 0.0475890462813716, "runtime": 0.629203730262816}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-053"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 103, "makespan": 24, "avg_agents_density": 0.03075431030517328, "runtime": 0.8797628497704864}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-054"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 155, "makespan": 31, "avg_agents_density": 0.040707211085462144, "runtime": 0.775509538128972}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-055"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 112, "makespan": 23, "avg_agents_density": 0.03473852194376574, "runtime": 0.5770106315612793}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-056"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 151, "makespan": 27, "avg_agents_density": 0.04025926388309855, "runtime": 0.6612098016776145}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-057"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 120, "makespan": 27, "avg_agents_density": 0.045665047887915915, "runtime": 0.9901062743738294}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-058"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 166, "makespan": 36, "avg_agents_density": 0.04097469945504105, "runtime": 0.8834508620202541}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-059"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 119, "makespan": 24, "avg_agents_density": 0.04048976123295365, "runtime": 0.6105998950079083}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-060"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 120, "makespan": 30, "avg_agents_density": 0.03863081976267636, "runtime": 1.0641760411672294}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-061"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 138, "makespan": 27, "avg_agents_density": 0.029662578064520884, "runtime": 0.661278105340898}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-062"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 144, "makespan": 30, "avg_agents_density": 0.03141579876031103, "runtime": 1.09864846104756}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-063"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 114, "makespan": 26, "avg_agents_density": 0.026365424530626798, "runtime": 0.6227376218885183}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-064"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 124, "makespan": 23, "avg_agents_density": 0.034618687745430164, "runtime": 0.8257583742961287}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-065"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 142, "makespan": 25, "avg_agents_density": 0.027538761236859905, "runtime": 0.5927242357283831}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-066"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 109, "makespan": 28, "avg_agents_density": 0.03143475080046734, "runtime": 0.707157916855067}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-067"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 168, "makespan": 45, "avg_agents_density": 0.035316045425396035, "runtime": 1.5124093918129802}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-068"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 114, "makespan": 24, "avg_agents_density": 0.03348060900390659, "runtime": 0.6104587325826287}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-069"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 128, "makespan": 29, "avg_agents_density": 0.034186247226070894, "runtime": 0.7075155056081712}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-070"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 118, "makespan": 32, "avg_agents_density": 0.03361257231367164, "runtime": 0.7956656091846526}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-071"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 110, "makespan": 23, "avg_agents_density": 0.025471719153729578, "runtime": 0.8148819832131267}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-072"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 133, "makespan": 27, "avg_agents_density": 0.027865956756069697, "runtime": 0.6828956417739391}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-073"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 126, "makespan": 28, "avg_agents_density": 0.028955511844259405, "runtime": 0.6914182552136481}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-074"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 113, "makespan": 23, "avg_agents_density": 0.027898724340856038, "runtime": 0.5807960187084973}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-075"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 19, "SoC": 95, "makespan": 20, "avg_agents_density": 0.028776441355539705, "runtime": 0.7369214962236583}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-076"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 125, "makespan": 21, "avg_agents_density": 0.03500723240161575, "runtime": 0.5284427730366588}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-077"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 119, "makespan": 25, "avg_agents_density": 0.042140358353950684, "runtime": 0.6299995770677924}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-078"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 94, "makespan": 22, "avg_agents_density": 0.03441597036950645, "runtime": 0.6895857970230281}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-079"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 19, "SoC": 104, "makespan": 20, "avg_agents_density": 0.04510976608618379, "runtime": 0.4955518627539277}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-080"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 19, "SoC": 101, "makespan": 20, "avg_agents_density": 0.03626455044864655, "runtime": 0.4941483782604337}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-081"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 152, "makespan": 36, "avg_agents_density": 0.029862502576803743, "runtime": 0.8776465794071555}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-082"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 114, "makespan": 19, "avg_agents_density": 0.03073340141248653, "runtime": 0.4967845813371241}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-083"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 126, "makespan": 25, "avg_agents_density": 0.0341199719290137, "runtime": 0.9287896826863289}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-084"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 104, "makespan": 21, "avg_agents_density": 0.0420938853790131, "runtime": 0.532012009061873}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-085"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 112, "makespan": 28, "avg_agents_density": 0.025684888244282677, "runtime": 0.6482449797913432}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-086"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 173, "makespan": 28, "avg_agents_density": 0.037336329161396266, "runtime": 0.7339667179621756}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-087"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 125, "makespan": 23, "avg_agents_density": 0.031049840854588198, "runtime": 0.7994792386889458}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-088"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 187, "makespan": 48, "avg_agents_density": 0.02737329577165005, "runtime": 1.1757980263791978}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-089"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 167, "makespan": 40, "avg_agents_density": 0.03563575951913518, "runtime": 0.9915347211062908}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-090"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 107, "makespan": 27, "avg_agents_density": 0.0286692678721154, "runtime": 0.5212689572945237}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-091"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 113, "makespan": 27, "avg_agents_density": 0.03555577455644337, "runtime": 0.9861347903497517}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-092"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 132, "makespan": 27, "avg_agents_density": 0.033655975743920825, "runtime": 0.6572402198798954}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-093"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 157, "makespan": 38, "avg_agents_density": 0.042674084995540276, "runtime": 1.344741938635707}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-094"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 189, "makespan": 36, "avg_agents_density": 0.04453629286819268, "runtime": 0.8577797147445381}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-095"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 138, "makespan": 37, "avg_agents_density": 0.02566232534080995, "runtime": 1.2612716467119753}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-096"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 139, "makespan": 25, "avg_agents_density": 0.03531002873551953, "runtime": 0.6330938856117427}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-097"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 151, "makespan": 28, "avg_agents_density": 0.043329093461076607, "runtime": 0.6927772536873817}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-098"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 156, "makespan": 33, "avg_agents_density": 0.025646091501509486, "runtime": 0.8241447727195919}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-099"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 113, "makespan": 23, "avg_agents_density": 0.029661022393126592, "runtime": 0.586028004065156}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-100"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 108, "makespan": 19, "avg_agents_density": 0.03493420522452968, "runtime": 0.4542719516903162}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-101"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 91, "makespan": 22, "avg_agents_density": 0.03703096368451685, "runtime": 0.8571174871176481}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-102"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 111, "makespan": 25, "avg_agents_density": 0.026531220667991247, "runtime": 0.645078529138118}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-103"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 122, "makespan": 30, "avg_agents_density": 0.03710886584384429, "runtime": 0.7493977495469153}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-104"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 163, "makespan": 36, "avg_agents_density": 0.03799722115516511, "runtime": 0.8814900233410299}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-105"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 118, "makespan": 29, "avg_agents_density": 0.02549443649538497, "runtime": 0.914720319211483}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-106"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 127, "makespan": 24, "avg_agents_density": 0.03961199493072856, "runtime": 0.5991605776362121}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-107"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 113, "makespan": 22, "avg_agents_density": 0.043700042143054375, "runtime": 0.5618589669466019}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-108"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 131, "makespan": 25, "avg_agents_density": 0.03215178303645927, "runtime": 0.6014612605795264}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-109"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 143, "makespan": 28, "avg_agents_density": 0.03580832506419654, "runtime": 0.9336245493032038}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-110"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 94, "makespan": 27, "avg_agents_density": 0.04289344962678466, "runtime": 0.6416953527368605}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-111"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 136, "makespan": 33, "avg_agents_density": 0.03292777348144849, "runtime": 0.8253414579667151}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-112"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 125, "makespan": 26, "avg_agents_density": 0.048150481281410244, "runtime": 0.6552200950682163}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-113"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 107, "makespan": 25, "avg_agents_density": 0.04186434935993673, "runtime": 0.8791714836843312}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-114"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 145, "makespan": 24, "avg_agents_density": 0.034789564657715634, "runtime": 0.6223671068437397}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-115"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 117, "makespan": 23, "avg_agents_density": 0.03590900248502201, "runtime": 0.5927120074629784}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-116"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 139, "makespan": 30, "avg_agents_density": 0.04362484811152466, "runtime": 0.7488293000496924}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-117"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 119, "makespan": 36, "avg_agents_density": 0.03071142263923784, "runtime": 1.238147045020014}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-118"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 13, "SoC": 73, "makespan": 14, "avg_agents_density": 0.048964425166372734, "runtime": 0.3459465615451336}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-119"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 107, "makespan": 34, "avg_agents_density": 0.030592651719624542, "runtime": 0.8463672916404903}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-120"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 165, "makespan": 31, "avg_agents_density": 0.028127414981984795, "runtime": 0.7184266773983836}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-121"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 138, "makespan": 33, "avg_agents_density": 0.027236180769902238, "runtime": 1.167895160149783}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-122"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 158, "makespan": 28, "avg_agents_density": 0.03141438841449934, "runtime": 0.7087204386480153}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-123"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 132, "makespan": 26, "avg_agents_density": 0.028841303485242435, "runtime": 0.6669426844455302}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-124"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 114, "makespan": 24, "avg_agents_density": 0.02212993282199134, "runtime": 0.5854798033833504}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-125"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 120, "makespan": 25, "avg_agents_density": 0.0343221784108154, "runtime": 0.8708680276758969}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-126"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 104, "makespan": 23, "avg_agents_density": 0.027971255627698827, "runtime": 0.5819191578775644}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-127"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 249, "makespan": 26, "avg_agents_density": 0.053220790882115225, "runtime": 1.746105691883713}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-000"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 286, "makespan": 34, "avg_agents_density": 0.05545219104725859, "runtime": 2.063445636536926}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-001"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 226, "makespan": 33, "avg_agents_density": 0.050408737673223715, "runtime": 2.100096539594233}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-002"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 284, "makespan": 30, "avg_agents_density": 0.0561321985288609, "runtime": 2.0221474887803197}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-003"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 258, "makespan": 36, "avg_agents_density": 0.04421305182445091, "runtime": 2.2451136270537972}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-004"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 248, "makespan": 29, "avg_agents_density": 0.06115502439440579, "runtime": 1.8051468571648002}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-005"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 199, "makespan": 23, "avg_agents_density": 0.05699109636832091, "runtime": 1.6574668274261057}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-006"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 319, "makespan": 42, "avg_agents_density": 0.058999407667761766, "runtime": 2.708562887273729}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-007"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 428, "makespan": 41, "avg_agents_density": 0.0721875763808779, "runtime": 2.4161020275205374}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-008"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 216, "makespan": 28, "avg_agents_density": 0.057831979852958015, "runtime": 1.8328468492254615}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-009"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 262, "makespan": 39, "avg_agents_density": 0.04837574781790967, "runtime": 2.5962233655154705}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-010"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 209, "makespan": 26, "avg_agents_density": 0.08889408472390041, "runtime": 1.662565182428807}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-011"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 394, "makespan": 37, "avg_agents_density": 0.06845017165411434, "runtime": 2.482362051960081}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-012"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 336, "makespan": 38, "avg_agents_density": 0.06485032356690223, "runtime": 2.436447342392057}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-013"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 253, "makespan": 25, "avg_agents_density": 0.0760300485475737, "runtime": 1.6264725583605468}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-014"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 329, "makespan": 34, "avg_agents_density": 0.07392413043590285, "runtime": 2.21374566340819}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-015"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 189, "makespan": 28, "avg_agents_density": 0.05302017702395448, "runtime": 1.5769781530834734}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-016"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 237, "makespan": 27, "avg_agents_density": 0.04979674562644826, "runtime": 1.7590877381153405}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-017"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 253, "makespan": 27, "avg_agents_density": 0.04933509730370894, "runtime": 1.6378604620695114}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-018"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 344, "makespan": 33, "avg_agents_density": 0.06828016436862284, "runtime": 2.087280448526144}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-019"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 232, "makespan": 30, "avg_agents_density": 0.05655716138909393, "runtime": 1.7777958479709923}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-020"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 258, "makespan": 32, "avg_agents_density": 0.06201646696061841, "runtime": 2.109710132237524}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-021"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 234, "makespan": 33, "avg_agents_density": 0.05679750837120404, "runtime": 2.082405318506062}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-022"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 251, "makespan": 29, "avg_agents_density": 0.07291302205972747, "runtime": 1.949199867900461}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-023"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 242, "makespan": 19, "avg_agents_density": 0.04942786555442764, "runtime": 1.2827274557203054}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-024"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 201, "makespan": 21, "avg_agents_density": 0.06578101585784167, "runtime": 1.3982850732281804}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-025"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 254, "makespan": 35, "avg_agents_density": 0.04591710370334467, "runtime": 2.1426396016031504}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-026"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 236, "makespan": 24, "avg_agents_density": 0.06159153281990962, "runtime": 1.5849776435643435}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-027"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 329, "makespan": 37, "avg_agents_density": 0.061917242125488874, "runtime": 2.551232146564871}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-028"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 285, "makespan": 30, "avg_agents_density": 0.05094883809781919, "runtime": 2.0277227559126914}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-029"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 249, "makespan": 28, "avg_agents_density": 0.062285148106493264, "runtime": 1.7878424609079957}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-030"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 241, "makespan": 26, "avg_agents_density": 0.05513284907018802, "runtime": 1.6542136752977967}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-031"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 227, "makespan": 30, "avg_agents_density": 0.05084015030343741, "runtime": 1.9486124659888446}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-032"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 320, "makespan": 47, "avg_agents_density": 0.048654030874661476, "runtime": 3.0485978997312486}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-033"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 236, "makespan": 30, "avg_agents_density": 0.07364901010683532, "runtime": 1.7249178467318416}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-034"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 203, "makespan": 21, "avg_agents_density": 0.05820018939055571, "runtime": 1.4079034077003598}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-035"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 350, "makespan": 36, "avg_agents_density": 0.0833512759149078, "runtime": 2.282986137084663}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-036"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 260, "makespan": 32, "avg_agents_density": 0.05125034184649435, "runtime": 2.0686275740154088}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-037"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 249, "makespan": 27, "avg_agents_density": 0.05176745095965315, "runtime": 1.8486896441318095}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-038"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 226, "makespan": 25, "avg_agents_density": 0.0478389357333942, "runtime": 1.6254169861786067}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-039"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 247, "makespan": 22, "avg_agents_density": 0.05363311808330873, "runtime": 1.2681799791753292}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-040"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 292, "makespan": 34, "avg_agents_density": 0.0526731791537679, "runtime": 2.3119644029065967}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-041"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 261, "makespan": 30, "avg_agents_density": 0.05686173846500857, "runtime": 2.1244903686456382}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-042"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 228, "makespan": 25, "avg_agents_density": 0.05912146312187058, "runtime": 1.610863181296736}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-043"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 214, "makespan": 22, "avg_agents_density": 0.06121372704279221, "runtime": 1.3412438700906932}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-044"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 234, "makespan": 29, "avg_agents_density": 0.048624311210511764, "runtime": 1.7115540779195726}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-045"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 252, "makespan": 27, "avg_agents_density": 0.05160158048671958, "runtime": 1.8119337065145373}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-046"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 302, "makespan": 33, "avg_agents_density": 0.07911980260762937, "runtime": 2.220609146170318}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-047"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 287, "makespan": 30, "avg_agents_density": 0.06350758650973706, "runtime": 2.044830161612481}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-048"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 282, "makespan": 33, "avg_agents_density": 0.06336559116280421, "runtime": 2.1284908717498183}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-049"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 257, "makespan": 33, "avg_agents_density": 0.05168935914980082, "runtime": 2.0100491642951965}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-050"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 269, "makespan": 27, "avg_agents_density": 0.05222384465084556, "runtime": 1.7050383305177093}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-051"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 243, "makespan": 28, "avg_agents_density": 0.05047256353503322, "runtime": 1.8572736247442663}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-052"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 255, "makespan": 29, "avg_agents_density": 0.07097938991127277, "runtime": 1.5448910198174417}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-053"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 222, "makespan": 26, "avg_agents_density": 0.05897529953568642, "runtime": 1.627479282207787}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-054"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 353, "makespan": 38, "avg_agents_density": 0.05679233164042823, "runtime": 2.478140148334205}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-055"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 220, "makespan": 22, "avg_agents_density": 0.05568312965861053, "runtime": 1.3339534141123295}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-056"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 258, "makespan": 27, "avg_agents_density": 0.05953998161594721, "runtime": 1.7845539203844965}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-057"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 256, "makespan": 27, "avg_agents_density": 0.06596686943908735, "runtime": 1.7418339042924345}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-058"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 292, "makespan": 35, "avg_agents_density": 0.06722888802406751, "runtime": 2.264826910570264}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-059"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 230, "makespan": 28, "avg_agents_density": 0.06164586084734141, "runtime": 1.7535718590952456}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-060"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 289, "makespan": 29, "avg_agents_density": 0.07085892550816845, "runtime": 1.7948129600845277}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-061"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 278, "makespan": 27, "avg_agents_density": 0.04731560701932391, "runtime": 1.664201021194458}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-062"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 379, "makespan": 36, "avg_agents_density": 0.06660764130004003, "runtime": 2.3156456612050533}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-063"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 209, "makespan": 25, "avg_agents_density": 0.05301994827672531, "runtime": 1.517090976703912}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-064"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 266, "makespan": 36, "avg_agents_density": 0.061667193091596344, "runtime": 2.233802662231028}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-065"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 275, "makespan": 28, "avg_agents_density": 0.04534997786892223, "runtime": 1.8383534410968423}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-066"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 226, "makespan": 24, "avg_agents_density": 0.04999007313263471, "runtime": 1.6075597540475428}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-067"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 392, "makespan": 47, "avg_agents_density": 0.062009459128760956, "runtime": 2.9212356004863977}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-068"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 341, "makespan": 37, "avg_agents_density": 0.07797039011141044, "runtime": 2.4411896588280797}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-069"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 310, "makespan": 36, "avg_agents_density": 0.06254759895969215, "runtime": 2.3150871614925563}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-070"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 259, "makespan": 36, "avg_agents_density": 0.05370295214412086, "runtime": 2.193259232211858}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-071"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 249, "makespan": 25, "avg_agents_density": 0.03950822280987221, "runtime": 1.6862610434181988}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-072"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 260, "makespan": 29, "avg_agents_density": 0.04485503765711987, "runtime": 1.8264251770451665}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-073"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 287, "makespan": 42, "avg_agents_density": 0.05720920014425955, "runtime": 2.6191130741499364}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-074"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 237, "makespan": 36, "avg_agents_density": 0.050303683997023875, "runtime": 2.291720536071807}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-075"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 289, "makespan": 36, "avg_agents_density": 0.05813591509303808, "runtime": 2.424157078843564}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-076"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 236, "makespan": 32, "avg_agents_density": 0.05983533822015894, "runtime": 1.8917983388528228}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-077"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 329, "makespan": 35, "avg_agents_density": 0.0642119185327321, "runtime": 2.2335676322691143}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-078"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 205, "makespan": 26, "avg_agents_density": 0.05620494458724403, "runtime": 1.716025936882943}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-079"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 236, "makespan": 27, "avg_agents_density": 0.05655228825136662, "runtime": 1.6399930575862527}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-080"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 211, "makespan": 21, "avg_agents_density": 0.061520819469141626, "runtime": 1.3204612266272306}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-081"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 336, "makespan": 35, "avg_agents_density": 0.04746141118509804, "runtime": 2.2041568914428353}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-082"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 297, "makespan": 25, "avg_agents_density": 0.05259087455276689, "runtime": 1.4074276299215853}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-083"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 313, "makespan": 40, "avg_agents_density": 0.05268526257779482, "runtime": 2.3950400855392218}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-084"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 230, "makespan": 27, "avg_agents_density": 0.06821424331889128, "runtime": 1.6846389309503138}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-085"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 246, "makespan": 37, "avg_agents_density": 0.04349993308581759, "runtime": 2.038991413079202}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-086"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 306, "makespan": 29, "avg_agents_density": 0.06729654052670767, "runtime": 1.8722736211493611}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-087"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 274, "makespan": 24, "avg_agents_density": 0.07083629858938062, "runtime": 1.6242561023682356}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-088"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 407, "makespan": 57, "avg_agents_density": 0.05531444053121096, "runtime": 3.516470012255013}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-089"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 296, "makespan": 42, "avg_agents_density": 0.06241939519175206, "runtime": 2.612268492113799}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-090"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 240, "makespan": 35, "avg_agents_density": 0.0634423613419326, "runtime": 2.0758199831470847}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-091"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 212, "makespan": 31, "avg_agents_density": 0.05099346038720967, "runtime": 1.841011171694845}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-092"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 252, "makespan": 27, "avg_agents_density": 0.05677495319353457, "runtime": 1.7242281143553555}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-093"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 307, "makespan": 32, "avg_agents_density": 0.06879265510117474, "runtime": 2.2996228798292577}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-094"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 384, "makespan": 45, "avg_agents_density": 0.074256230771645, "runtime": 2.8573135384358466}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-095"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 287, "makespan": 40, "avg_agents_density": 0.051810044622522415, "runtime": 2.541798107791692}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-096"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 262, "makespan": 29, "avg_agents_density": 0.05777072694892722, "runtime": 1.8834663107991219}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-097"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 412, "makespan": 43, "avg_agents_density": 0.06856917415616454, "runtime": 2.6919975578784943}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-098"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 299, "makespan": 35, "avg_agents_density": 0.06060905548947673, "runtime": 2.1706055416725576}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-099"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 242, "makespan": 28, "avg_agents_density": 0.042653014629011624, "runtime": 1.8371934168972075}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-100"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 209, "makespan": 24, "avg_agents_density": 0.05487821268161686, "runtime": 1.4510405361652374}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-101"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 266, "makespan": 33, "avg_agents_density": 0.07933895605352, "runtime": 2.3201189595274627}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-102"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 261, "makespan": 27, "avg_agents_density": 0.057440338114594085, "runtime": 1.821276276372373}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-103"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 345, "makespan": 43, "avg_agents_density": 0.04966391566818542, "runtime": 2.7633261773735285}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-104"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 360, "makespan": 38, "avg_agents_density": 0.06517914951348426, "runtime": 2.398694726638496}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-105"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 247, "makespan": 28, "avg_agents_density": 0.04828073281572739, "runtime": 1.8756175287999213}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-106"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 230, "makespan": 24, "avg_agents_density": 0.0651552876971366, "runtime": 1.5340435160323977}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-107"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 221, "makespan": 26, "avg_agents_density": 0.07031757773836152, "runtime": 1.6391992564313114}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-108"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 236, "makespan": 27, "avg_agents_density": 0.053569528757395894, "runtime": 1.7025807085447013}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-109"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 268, "makespan": 28, "avg_agents_density": 0.054973456673460805, "runtime": 1.91738724661991}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-110"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 280, "makespan": 34, "avg_agents_density": 0.06954552706766716, "runtime": 2.1278571682050824}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-111"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 261, "makespan": 32, "avg_agents_density": 0.06269441097919769, "runtime": 1.9946603421121836}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-112"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 239, "makespan": 25, "avg_agents_density": 0.06517449697343651, "runtime": 1.6076337317936122}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-113"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 194, "makespan": 24, "avg_agents_density": 0.06794702347784268, "runtime": 1.4947692528367043}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-114"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 294, "makespan": 31, "avg_agents_density": 0.06743545403453385, "runtime": 2.0212110592983663}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-115"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 297, "makespan": 37, "avg_agents_density": 0.059709945722920675, "runtime": 2.200752188451588}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-116"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 236, "makespan": 30, "avg_agents_density": 0.07343053904626438, "runtime": 1.9837576849386096}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-117"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 349, "makespan": 56, "avg_agents_density": 0.06464591658146943, "runtime": 3.4699026411399245}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-118"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 241, "makespan": 30, "avg_agents_density": 0.05881776535111498, "runtime": 1.8791350638493896}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-119"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 216, "makespan": 33, "avg_agents_density": 0.0524120468264025, "runtime": 2.1338053215295076}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-120"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 260, "makespan": 32, "avg_agents_density": 0.05130192893247377, "runtime": 1.9045828436501324}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-121"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 292, "makespan": 35, "avg_agents_density": 0.0489067473013838, "runtime": 2.3580121099948883}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-122"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 268, "makespan": 28, "avg_agents_density": 0.05835993084400346, "runtime": 1.7767919623292983}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-123"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 330, "makespan": 36, "avg_agents_density": 0.050635448705395186, "runtime": 2.2623389018699527}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-124"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 253, "makespan": 33, "avg_agents_density": 0.048213194789695143, "runtime": 2.1028440105728805}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-125"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 324, "makespan": 32, "avg_agents_density": 0.07410744666600097, "runtime": 2.084138904232532}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-126"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 229, "makespan": 24, "avg_agents_density": 0.06244325582921926, "runtime": 1.4655662453733385}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-127"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 363, "makespan": 29, "avg_agents_density": 0.06738675319851443, "runtime": 2.894114200025797}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-000"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 433, "makespan": 32, "avg_agents_density": 0.08867293590412202, "runtime": 3.0048892120830715}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-001"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 353, "makespan": 34, "avg_agents_density": 0.08001174087833333, "runtime": 3.398057686164975}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-002"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 376, "makespan": 31, "avg_agents_density": 0.07283925601551922, "runtime": 3.411411279812455}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-003"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 344, "makespan": 36, "avg_agents_density": 0.06168037896817117, "runtime": 3.232320360839367}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-004"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 505, "makespan": 42, "avg_agents_density": 0.08135338448331798, "runtime": 3.8288010549731553}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-005"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 358, "makespan": 28, "avg_agents_density": 0.07512773903222382, "runtime": 2.7466216874308884}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-006"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 445, "makespan": 43, "avg_agents_density": 0.08330141544110874, "runtime": 3.9106907323002815}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-007"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 725, "makespan": 45, "avg_agents_density": 0.09591212042008598, "runtime": 4.433597174473107}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-008"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 380, "makespan": 29, "avg_agents_density": 0.07714307276669828, "runtime": 2.8885017009451985}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-009"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 417, "makespan": 38, "avg_agents_density": 0.07039163385809075, "runtime": 3.7698651757091284}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-010"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 315, "makespan": 28, "avg_agents_density": 0.12251206326499925, "runtime": 2.744774331804365}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-011"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 724, "makespan": 50, "avg_agents_density": 0.1010382363291084, "runtime": 4.596861245110631}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-012"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 547, "makespan": 41, "avg_agents_density": 0.07308667011499054, "runtime": 3.8556622792966664}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-013"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 425, "makespan": 25, "avg_agents_density": 0.10443965608840258, "runtime": 2.524599245749414}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-014"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 519, "makespan": 36, "avg_agents_density": 0.08758876146195359, "runtime": 3.3486804752610624}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-015"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 316, "makespan": 28, "avg_agents_density": 0.0770425055836851, "runtime": 2.461092569399625}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-016"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 415, "makespan": 29, "avg_agents_density": 0.07348883380526773, "runtime": 2.7028839527629316}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-017"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 378, "makespan": 31, "avg_agents_density": 0.0697789078785481, "runtime": 2.9109836779534817}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-018"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 706, "makespan": 48, "avg_agents_density": 0.10775752005950019, "runtime": 4.526502131018788}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-019"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 396, "makespan": 37, "avg_agents_density": 0.07859553983121605, "runtime": 3.146669709123671}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-020"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 432, "makespan": 33, "avg_agents_density": 0.09008954289053156, "runtime": 3.1667547868564725}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-021"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 417, "makespan": 44, "avg_agents_density": 0.07964466811634176, "runtime": 4.007644036784768}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-022"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 363, "makespan": 28, "avg_agents_density": 0.09244535309381167, "runtime": 2.6954244687221944}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-023"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 451, "makespan": 36, "avg_agents_density": 0.08037105617599366, "runtime": 3.384884007740766}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-024"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 321, "makespan": 24, "avg_agents_density": 0.08752635972369997, "runtime": 2.4101659078150988}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-025"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 363, "makespan": 32, "avg_agents_density": 0.06370130555179308, "runtime": 2.963058792054653}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-026"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 413, "makespan": 33, "avg_agents_density": 0.09275256794137997, "runtime": 3.203382567036897}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-027"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 575, "makespan": 42, "avg_agents_density": 0.08198222390298743, "runtime": 4.09525533625856}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-028"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 411, "makespan": 34, "avg_agents_density": 0.07765379085809956, "runtime": 3.4296500673517585}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-029"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 375, "makespan": 25, "avg_agents_density": 0.07921306300797629, "runtime": 2.3990337159484625}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-030"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 338, "makespan": 31, "avg_agents_density": 0.07663434814202046, "runtime": 2.4050368890166283}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-031"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 383, "makespan": 29, "avg_agents_density": 0.07734197874687546, "runtime": 2.829693822655827}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-032"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 492, "makespan": 42, "avg_agents_density": 0.0754915267675778, "runtime": 4.028316550888121}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-033"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 461, "makespan": 37, "avg_agents_density": 0.09743511406746498, "runtime": 3.290693881455809}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-034"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 328, "makespan": 28, "avg_agents_density": 0.08943287975652638, "runtime": 2.616508160252124}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-035"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 407, "makespan": 32, "avg_agents_density": 0.10450829785365352, "runtime": 2.876717037986964}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-036"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 415, "makespan": 34, "avg_agents_density": 0.07284933950693065, "runtime": 2.9380050278268754}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-037"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 386, "makespan": 30, "avg_agents_density": 0.07410478345194836, "runtime": 3.0952592226676643}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-038"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 405, "makespan": 29, "avg_agents_density": 0.06906390819542033, "runtime": 2.7151823262684047}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-039"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 420, "makespan": 34, "avg_agents_density": 0.08396736548748837, "runtime": 3.2808239036239684}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-040"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 520, "makespan": 35, "avg_agents_density": 0.07649236675317925, "runtime": 3.7344524012878537}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-041"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 414, "makespan": 31, "avg_agents_density": 0.08342883108193266, "runtime": 3.0966030810959637}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-042"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 346, "makespan": 31, "avg_agents_density": 0.07209991445592542, "runtime": 2.8910116888582706}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-043"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 320, "makespan": 24, "avg_agents_density": 0.08263775363123785, "runtime": 2.2669113595038652}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-044"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 393, "makespan": 33, "avg_agents_density": 0.07600439095326926, "runtime": 2.9960065642371774}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-045"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 392, "makespan": 27, "avg_agents_density": 0.06369405495963602, "runtime": 2.768088144250214}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-046"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 526, "makespan": 45, "avg_agents_density": 0.10775897734284086, "runtime": 4.3215683731250465}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-047"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 454, "makespan": 33, "avg_agents_density": 0.0905316539217481, "runtime": 2.9699459597468376}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-048"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 531, "makespan": 38, "avg_agents_density": 0.09735424768081022, "runtime": 3.8096977043896914}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-049"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 357, "makespan": 37, "avg_agents_density": 0.07292341802838279, "runtime": 3.320425361394882}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-050"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 455, "makespan": 35, "avg_agents_density": 0.08045605041653045, "runtime": 3.453341530635953}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-051"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 464, "makespan": 30, "avg_agents_density": 0.07067888819834096, "runtime": 2.987538191024214}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-052"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 391, "makespan": 28, "avg_agents_density": 0.0969474291575314, "runtime": 2.4220437984913588}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-053"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 435, "makespan": 30, "avg_agents_density": 0.09309513070872653, "runtime": 3.116590953897685}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-054"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 526, "makespan": 44, "avg_agents_density": 0.06980329281067621, "runtime": 4.181210765615106}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-055"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 357, "makespan": 25, "avg_agents_density": 0.06905750438973877, "runtime": 2.391137382015586}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-056"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 359, "makespan": 38, "avg_agents_density": 0.08748128103059691, "runtime": 3.613718742504716}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-057"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 429, "makespan": 34, "avg_agents_density": 0.09667491905598126, "runtime": 3.2303670956753194}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-058"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 484, "makespan": 35, "avg_agents_density": 0.09559560299170054, "runtime": 3.3638439695350826}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-059"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 356, "makespan": 29, "avg_agents_density": 0.08583480581541207, "runtime": 2.729878335725516}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-060"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 354, "makespan": 33, "avg_agents_density": 0.08921867399402961, "runtime": 3.0796058233827353}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-061"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 609, "makespan": 60, "avg_agents_density": 0.06523766104808008, "runtime": 5.610796278808266}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-062"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 669, "makespan": 38, "avg_agents_density": 0.0903065388952314, "runtime": 3.62431656755507}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-063"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 354, "makespan": 34, "avg_agents_density": 0.08258121184805925, "runtime": 3.294780067168176}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-064"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 405, "makespan": 33, "avg_agents_density": 0.08888179809887496, "runtime": 3.10959899565205}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-065"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 465, "makespan": 31, "avg_agents_density": 0.06473624348981445, "runtime": 3.195834188722074}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-066"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 304, "makespan": 27, "avg_agents_density": 0.06903867552490262, "runtime": 2.465332350693643}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-067"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 663, "makespan": 53, "avg_agents_density": 0.08156028535815484, "runtime": 4.977913135197014}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-068"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 503, "makespan": 35, "avg_agents_density": 0.11928848659491191, "runtime": 3.534442206379026}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-069"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 530, "makespan": 35, "avg_agents_density": 0.08424448383976207, "runtime": 3.364723960403353}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-070"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 386, "makespan": 36, "avg_agents_density": 0.07031320682785208, "runtime": 3.3089176090434194}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-071"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 357, "makespan": 30, "avg_agents_density": 0.05602380111252092, "runtime": 2.8234384898096323}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-072"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 406, "makespan": 28, "avg_agents_density": 0.0650209224635488, "runtime": 2.828680319711566}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-073"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 415, "makespan": 34, "avg_agents_density": 0.08924443300325191, "runtime": 3.318213582970202}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-074"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 434, "makespan": 38, "avg_agents_density": 0.07627391377388833, "runtime": 3.6613465747796}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-075"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 548, "makespan": 42, "avg_agents_density": 0.080552744417172, "runtime": 3.7764876252040267}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-076"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 371, "makespan": 32, "avg_agents_density": 0.09116530196315586, "runtime": 3.178766333963722}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-077"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 512, "makespan": 32, "avg_agents_density": 0.09464852594165453, "runtime": 3.4195070029236376}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-078"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 345, "makespan": 29, "avg_agents_density": 0.08101950690283209, "runtime": 2.964815755840391}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-079"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 359, "makespan": 31, "avg_agents_density": 0.07402857317492226, "runtime": 2.915480666793883}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-080"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 358, "makespan": 26, "avg_agents_density": 0.08466007856023905, "runtime": 2.51009144121781}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-081"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 607, "makespan": 51, "avg_agents_density": 0.06608533998836191, "runtime": 4.723048303741962}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-082"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 432, "makespan": 35, "avg_agents_density": 0.08526683044885329, "runtime": 3.3653818634338677}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-083"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 566, "makespan": 52, "avg_agents_density": 0.07170426233118198, "runtime": 4.589968475047499}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-084"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 445, "makespan": 34, "avg_agents_density": 0.08939580329496404, "runtime": 2.9844591529108584}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-085"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 377, "makespan": 35, "avg_agents_density": 0.06643783244943022, "runtime": 3.413717471063137}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-086"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 486, "makespan": 42, "avg_agents_density": 0.08066514468465869, "runtime": 4.034433594439179}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-087"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 414, "makespan": 34, "avg_agents_density": 0.09244698502310904, "runtime": 3.152275034226477}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-088"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 582, "makespan": 50, "avg_agents_density": 0.07422142423365323, "runtime": 4.436901229899377}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-089"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 426, "makespan": 39, "avg_agents_density": 0.0939967177296828, "runtime": 3.5702701853588223}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-090"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 639, "makespan": 55, "avg_agents_density": 0.09535368604259976, "runtime": 5.033979855943471}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-091"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 337, "makespan": 27, "avg_agents_density": 0.06742622823736691, "runtime": 2.653680069837719}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-092"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 455, "makespan": 37, "avg_agents_density": 0.08270473087299353, "runtime": 3.428723890800029}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-093"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 504, "makespan": 46, "avg_agents_density": 0.09179837759592895, "runtime": 4.352608828339726}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-094"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 906, "makespan": 69, "avg_agents_density": 0.10725606345717797, "runtime": 6.329213257879019}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-095"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 490, "makespan": 43, "avg_agents_density": 0.0794552572777426, "runtime": 4.120811506640166}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-096"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 408, "makespan": 33, "avg_agents_density": 0.0787724150664639, "runtime": 3.3542089727707207}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-097"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 619, "makespan": 44, "avg_agents_density": 0.09092276559800692, "runtime": 4.074810442514718}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-098"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 449, "makespan": 36, "avg_agents_density": 0.08486688694894359, "runtime": 3.4174395338632166}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-099"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 404, "makespan": 34, "avg_agents_density": 0.06865971692671313, "runtime": 3.023310524877161}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-100"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 336, "makespan": 27, "avg_agents_density": 0.08547624970025956, "runtime": 2.60782542033121}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-101"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 447, "makespan": 34, "avg_agents_density": 0.09077270479616266, "runtime": 3.320469523780048}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-102"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 362, "makespan": 26, "avg_agents_density": 0.07846711952599066, "runtime": 2.549050807952881}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-103"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 495, "makespan": 34, "avg_agents_density": 0.07491318214639435, "runtime": 3.3139875293709338}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-104"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 754, "makespan": 76, "avg_agents_density": 0.07253339764098997, "runtime": 6.994470144622028}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-105"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 434, "makespan": 34, "avg_agents_density": 0.06431453898072967, "runtime": 3.2318622055463493}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-106"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 370, "makespan": 27, "avg_agents_density": 0.09329506391081548, "runtime": 2.6108902860432863}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-107"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 357, "makespan": 28, "avg_agents_density": 0.09361509962259312, "runtime": 2.5951906256377697}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-108"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 459, "makespan": 44, "avg_agents_density": 0.08017011457183808, "runtime": 3.9189705974422395}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-109"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 403, "makespan": 30, "avg_agents_density": 0.07742920508102615, "runtime": 2.7679542396217585}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-110"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 342, "makespan": 31, "avg_agents_density": 0.08534399948798055, "runtime": 2.9019454792141914}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-111"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 510, "makespan": 44, "avg_agents_density": 0.09270507664208477, "runtime": 4.2709844605997205}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-112"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 335, "makespan": 29, "avg_agents_density": 0.0892678265156905, "runtime": 2.85639922413975}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-113"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 367, "makespan": 30, "avg_agents_density": 0.10189097314248409, "runtime": 2.901827536523342}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-114"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 485, "makespan": 39, "avg_agents_density": 0.09007549878476184, "runtime": 3.5518480287864804}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-115"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 471, "makespan": 29, "avg_agents_density": 0.08952339191002912, "runtime": 2.864584119990468}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-116"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 419, "makespan": 32, "avg_agents_density": 0.09024566194412806, "runtime": 3.106146903242916}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-117"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 481, "makespan": 38, "avg_agents_density": 0.08717724688643089, "runtime": 3.5418081879615784}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-118"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 463, "makespan": 32, "avg_agents_density": 0.07982047872985294, "runtime": 2.879988686647266}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-119"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 349, "makespan": 33, "avg_agents_density": 0.07008061521220962, "runtime": 3.1975818988867104}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-120"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 447, "makespan": 35, "avg_agents_density": 0.07276275008995557, "runtime": 3.48891178984195}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-121"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 444, "makespan": 37, "avg_agents_density": 0.0668916783454985, "runtime": 3.661321386694908}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-122"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 383, "makespan": 29, "avg_agents_density": 0.08487227076880856, "runtime": 2.8005739166401327}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-123"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 548, "makespan": 36, "avg_agents_density": 0.0870054202582929, "runtime": 3.2970258304849267}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-124"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 394, "makespan": 34, "avg_agents_density": 0.07700368224227458, "runtime": 3.2555900258012116}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-125"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 513, "makespan": 34, "avg_agents_density": 0.09901605734661359, "runtime": 3.3396709873341024}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-126"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 364, "makespan": 27, "avg_agents_density": 0.0869706231570334, "runtime": 2.5747767915017903}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-127"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 537, "makespan": 33, "avg_agents_density": 0.08889163510545478, "runtime": 3.9722425639629364}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-000"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 690, "makespan": 35, "avg_agents_density": 0.12219268105357993, "runtime": 4.202178291976452}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-001"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 614, "makespan": 52, "avg_agents_density": 0.08964453252648222, "runtime": 6.426602984778583}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-002"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 527, "makespan": 36, "avg_agents_density": 0.0912981125675731, "runtime": 4.391218665055931}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-003"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 568, "makespan": 55, "avg_agents_density": 0.07903188578093061, "runtime": 6.303545568604022}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-004"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 719, "makespan": 42, "avg_agents_density": 0.09954900265255094, "runtime": 5.059021469205618}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-005"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 596, "makespan": 36, "avg_agents_density": 0.09611224432541052, "runtime": 4.468490203376859}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-006"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 689, "makespan": 48, "avg_agents_density": 0.10116861763716103, "runtime": 5.820290389470756}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-007"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 968, "makespan": 49, "avg_agents_density": 0.12908330167480736, "runtime": 6.24504162138328}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-008"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 447, "makespan": 34, "avg_agents_density": 0.09155773242808145, "runtime": 4.1367875658907}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-009"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 598, "makespan": 38, "avg_agents_density": 0.09945221170586731, "runtime": 4.6200738861225545}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-010"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 511, "makespan": 30, "avg_agents_density": 0.14919369303511773, "runtime": 3.7574786548502743}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-011"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 977, "makespan": 50, "avg_agents_density": 0.12978985676295493, "runtime": 6.212862325832248}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-012"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 818, "makespan": 47, "avg_agents_density": 0.10317729922515388, "runtime": 5.849721007980406}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-013"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 498, "makespan": 31, "avg_agents_density": 0.11641695500262145, "runtime": 3.9801101870834827}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-014"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1084, "makespan": 61, "avg_agents_density": 0.11448174889045493, "runtime": 7.750122969970107}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-015"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 498, "makespan": 30, "avg_agents_density": 0.09969699351636854, "runtime": 3.9268810003995895}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-016"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 644, "makespan": 35, "avg_agents_density": 0.08342826040953127, "runtime": 4.491005050484091}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-017"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 629, "makespan": 41, "avg_agents_density": 0.09319974710293377, "runtime": 5.107092491351068}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-018"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1006, "makespan": 65, "avg_agents_density": 0.14002092962105642, "runtime": 7.980283856857568}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-019"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 539, "makespan": 33, "avg_agents_density": 0.10470436174528362, "runtime": 4.236103442497551}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-020"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 728, "makespan": 47, "avg_agents_density": 0.09745941404868923, "runtime": 5.932260709814727}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-021"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 585, "makespan": 38, "avg_agents_density": 0.09670876995576096, "runtime": 4.771391108166426}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-022"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 522, "makespan": 28, "avg_agents_density": 0.11913106009964433, "runtime": 3.4994044830091298}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-023"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 624, "makespan": 31, "avg_agents_density": 0.10298113157626186, "runtime": 4.1733895489014685}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-024"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 492, "makespan": 31, "avg_agents_density": 0.10493557016796487, "runtime": 3.8860871964134276}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-025"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 476, "makespan": 38, "avg_agents_density": 0.08144489530013958, "runtime": 4.699180418625474}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-026"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 518, "makespan": 27, "avg_agents_density": 0.11762235458664314, "runtime": 3.576821173541248}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-027"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 752, "makespan": 39, "avg_agents_density": 0.0957900425372425, "runtime": 4.902553587220609}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-028"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 557, "makespan": 34, "avg_agents_density": 0.0965276931892951, "runtime": 4.2032851609401405}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-029"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 541, "makespan": 31, "avg_agents_density": 0.10797947255921246, "runtime": 4.108815392944962}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-030"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 485, "makespan": 29, "avg_agents_density": 0.10172442672586167, "runtime": 3.725853976327926}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-031"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 506, "makespan": 33, "avg_agents_density": 0.0969367700042909, "runtime": 4.167705869302154}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-032"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 577, "makespan": 40, "avg_agents_density": 0.09790834877494611, "runtime": 5.128761176019907}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-033"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 703, "makespan": 39, "avg_agents_density": 0.13456641982692435, "runtime": 4.754173568915576}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-034"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 580, "makespan": 33, "avg_agents_density": 0.12173031681922267, "runtime": 4.698660005349666}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-035"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 652, "makespan": 37, "avg_agents_density": 0.13503250017197058, "runtime": 5.437357755377889}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-036"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 586, "makespan": 44, "avg_agents_density": 0.09617113515251813, "runtime": 6.406197349075228}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-037"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 495, "makespan": 28, "avg_agents_density": 0.09024331225308978, "runtime": 2.9198855916038156}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-038"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 539, "makespan": 43, "avg_agents_density": 0.0818493989645321, "runtime": 5.09765650331974}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-039"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 620, "makespan": 36, "avg_agents_density": 0.10160966773204187, "runtime": 4.7837126506492496}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-040"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 947, "makespan": 69, "avg_agents_density": 0.0863082768291671, "runtime": 8.488164941314608}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-041"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 676, "makespan": 33, "avg_agents_density": 0.09939016910443992, "runtime": 3.906928406096995}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-042"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 463, "makespan": 29, "avg_agents_density": 0.09461489780084471, "runtime": 3.580286517739296}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-043"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 611, "makespan": 38, "avg_agents_density": 0.09852550278492796, "runtime": 5.46019472181797}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-044"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 510, "makespan": 28, "avg_agents_density": 0.09242498190963663, "runtime": 3.390971518587321}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-045"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 518, "makespan": 37, "avg_agents_density": 0.08479774547575619, "runtime": 4.889016697648913}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-046"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 784, "makespan": 49, "avg_agents_density": 0.12606482196027072, "runtime": 6.686811393126845}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-047"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 627, "makespan": 32, "avg_agents_density": 0.12838455696340453, "runtime": 3.998295188881457}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-048"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 735, "makespan": 36, "avg_agents_density": 0.13037911633792246, "runtime": 4.748222316149622}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-049"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 638, "makespan": 37, "avg_agents_density": 0.09860842436483504, "runtime": 4.689659357536584}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-050"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 565, "makespan": 35, "avg_agents_density": 0.08911385363028058, "runtime": 4.44110990408808}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-051"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 547, "makespan": 35, "avg_agents_density": 0.09373290653807605, "runtime": 4.3977615791372955}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-052"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 690, "makespan": 38, "avg_agents_density": 0.137033407935061, "runtime": 5.309812830295414}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-053"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 656, "makespan": 39, "avg_agents_density": 0.11066459866229099, "runtime": 5.028215134516358}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-054"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 747, "makespan": 49, "avg_agents_density": 0.08530866558191509, "runtime": 6.257091853301972}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-055"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 484, "makespan": 29, "avg_agents_density": 0.09870600663273356, "runtime": 3.794367211405188}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-056"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 522, "makespan": 31, "avg_agents_density": 0.11157355440129704, "runtime": 4.324964444153011}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-057"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 803, "makespan": 42, "avg_agents_density": 0.13380969578517227, "runtime": 5.442784273531288}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-058"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 668, "makespan": 43, "avg_agents_density": 0.10819777112217861, "runtime": 5.505166156683117}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-059"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 472, "makespan": 28, "avg_agents_density": 0.11889758902565321, "runtime": 3.5487048705108464}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-060"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 583, "makespan": 45, "avg_agents_density": 0.12255086771506543, "runtime": 5.6070170984603465}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-061"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 840, "makespan": 44, "avg_agents_density": 0.08712432855340217, "runtime": 5.7091560158878565}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-062"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 920, "makespan": 54, "avg_agents_density": 0.10796772023151206, "runtime": 6.782081678044051}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-063"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 575, "makespan": 41, "avg_agents_density": 0.09881563456103751, "runtime": 5.104607501998544}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-064"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 651, "makespan": 35, "avg_agents_density": 0.12185560149691782, "runtime": 4.53788401093334}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-065"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 580, "makespan": 35, "avg_agents_density": 0.08982634712542588, "runtime": 4.428392258007079}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-066"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 472, "makespan": 29, "avg_agents_density": 0.08787437520609039, "runtime": 3.8550048042088747}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-067"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1063, "makespan": 65, "avg_agents_density": 0.10229475724713483, "runtime": 7.883200572337955}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-068"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1008, "makespan": 52, "avg_agents_density": 0.15250827128611855, "runtime": 6.592910357750952}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-069"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 704, "makespan": 45, "avg_agents_density": 0.10679297520920653, "runtime": 5.645068186335266}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-070"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 549, "makespan": 41, "avg_agents_density": 0.09531045147875046, "runtime": 5.07486213510856}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-071"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 484, "makespan": 28, "avg_agents_density": 0.07433184035577056, "runtime": 3.6318052457645535}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-072"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 522, "makespan": 31, "avg_agents_density": 0.0859813907267452, "runtime": 3.7564837262034416}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-073"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 645, "makespan": 41, "avg_agents_density": 0.11155602718525288, "runtime": 5.055446851067245}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-074"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 560, "makespan": 38, "avg_agents_density": 0.09988408984547172, "runtime": 4.47239355603233}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-075"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 848, "makespan": 50, "avg_agents_density": 0.09978701242488107, "runtime": 6.095142236445099}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-076"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 648, "makespan": 51, "avg_agents_density": 0.11254971043472188, "runtime": 6.0949124451726675}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-077"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 767, "makespan": 39, "avg_agents_density": 0.11338973593785648, "runtime": 4.866724922787398}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-078"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 449, "makespan": 32, "avg_agents_density": 0.09893731087069954, "runtime": 4.107737104874104}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-079"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 568, "makespan": 29, "avg_agents_density": 0.10228785720320892, "runtime": 3.6735321125015616}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-080"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 620, "makespan": 31, "avg_agents_density": 0.12092896568515324, "runtime": 3.9859036249108613}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-081"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 718, "makespan": 38, "avg_agents_density": 0.0829298866258644, "runtime": 5.241449818946421}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-082"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 588, "makespan": 32, "avg_agents_density": 0.09196307751757846, "runtime": 4.133068018592894}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-083"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 826, "makespan": 50, "avg_agents_density": 0.1048456143239703, "runtime": 6.389398844912648}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-084"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 728, "makespan": 45, "avg_agents_density": 0.11396198737075784, "runtime": 5.584363240748644}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-085"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 501, "makespan": 35, "avg_agents_density": 0.08572075740541746, "runtime": 4.481668817810714}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-086"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 781, "makespan": 42, "avg_agents_density": 0.10254326977871106, "runtime": 5.486582309938967}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-087"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 702, "makespan": 51, "avg_agents_density": 0.11300244942641752, "runtime": 6.06512526422739}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-088"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 968, "makespan": 62, "avg_agents_density": 0.1115246262122566, "runtime": 7.517229781951755}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-089"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 925, "makespan": 57, "avg_agents_density": 0.11958333400192064, "runtime": 6.209749903995544}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-090"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 1166, "makespan": 75, "avg_agents_density": 0.12307467195718484, "runtime": 9.136382456868887}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-091"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 474, "makespan": 35, "avg_agents_density": 0.08765614612714058, "runtime": 4.6066017635166645}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-092"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 680, "makespan": 36, "avg_agents_density": 0.09689953797499998, "runtime": 4.589835831429809}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-093"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 836, "makespan": 57, "avg_agents_density": 0.12133259772691585, "runtime": 7.029007296077907}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-094"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 104, "SoC": 2075, "makespan": 105, "avg_agents_density": 0.14061313506879478, "runtime": 12.967137198429555}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-095"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 741, "makespan": 49, "avg_agents_density": 0.09779839417519055, "runtime": 5.821774721611291}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-096"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 599, "makespan": 35, "avg_agents_density": 0.09778526435750683, "runtime": 4.502891306299716}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-097"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 873, "makespan": 53, "avg_agents_density": 0.11213761988827162, "runtime": 6.7750633978284895}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-098"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 661, "makespan": 44, "avg_agents_density": 0.10847655695995384, "runtime": 5.111258915159851}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-099"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 569, "makespan": 35, "avg_agents_density": 0.09906086229108431, "runtime": 4.542141830082983}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-100"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 557, "makespan": 33, "avg_agents_density": 0.10374370317405329, "runtime": 4.344337132293731}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-101"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 637, "makespan": 35, "avg_agents_density": 0.11691128519188128, "runtime": 4.363692044746131}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-102"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 532, "makespan": 27, "avg_agents_density": 0.1047374567331356, "runtime": 3.3032443560659885}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-103"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 812, "makespan": 42, "avg_agents_density": 0.09120839319801721, "runtime": 5.44242077646777}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-104"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 98, "SoC": 1237, "makespan": 99, "avg_agents_density": 0.10675823503839192, "runtime": 11.89598868926987}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-105"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 539, "makespan": 35, "avg_agents_density": 0.08420333244264006, "runtime": 4.524644705466926}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-106"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 580, "makespan": 34, "avg_agents_density": 0.11289630692334297, "runtime": 4.0349592957645655}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-107"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 697, "makespan": 39, "avg_agents_density": 0.11642857404306887, "runtime": 4.860436546150595}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-108"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 614, "makespan": 43, "avg_agents_density": 0.10047283314993219, "runtime": 5.389820372220129}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-109"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 583, "makespan": 30, "avg_agents_density": 0.09168002276862956, "runtime": 3.719353192485869}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-110"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 494, "makespan": 30, "avg_agents_density": 0.10733196364986922, "runtime": 3.9403213672339916}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-111"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 939, "makespan": 49, "avg_agents_density": 0.12770597920464316, "runtime": 6.1943249218165874}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-112"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 513, "makespan": 29, "avg_agents_density": 0.11881001227246739, "runtime": 3.6500928015448153}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-113"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 502, "makespan": 39, "avg_agents_density": 0.1161948045188709, "runtime": 4.833073194604367}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-114"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 868, "makespan": 42, "avg_agents_density": 0.1318986826610321, "runtime": 5.334246729500592}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-115"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 710, "makespan": 39, "avg_agents_density": 0.12182043829614295, "runtime": 5.36514760972932}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-116"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 561, "makespan": 31, "avg_agents_density": 0.11170140927332411, "runtime": 4.130326360929757}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-117"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 565, "makespan": 38, "avg_agents_density": 0.10562632720195886, "runtime": 4.639994053170085}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-118"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 608, "makespan": 34, "avg_agents_density": 0.1064851239058182, "runtime": 4.266417743172497}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-119"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 555, "makespan": 37, "avg_agents_density": 0.09441848798001873, "runtime": 4.5346803907305}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-120"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 580, "makespan": 31, "avg_agents_density": 0.08792663719644647, "runtime": 4.098737142980099}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-121"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 710, "makespan": 42, "avg_agents_density": 0.07881897526765266, "runtime": 5.3951030797325075}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-122"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 541, "makespan": 34, "avg_agents_density": 0.1013970709031044, "runtime": 4.317315464839339}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-123"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 595, "makespan": 32, "avg_agents_density": 0.10781781023015799, "runtime": 4.186046572867781}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-124"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 556, "makespan": 34, "avg_agents_density": 0.09632519130032222, "runtime": 4.245242432225496}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-125"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 918, "makespan": 46, "avg_agents_density": 0.14343052146055532, "runtime": 5.87031888961792}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-126"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 553, "makespan": 29, "avg_agents_density": 0.11032024577837336, "runtime": 3.76880313269794}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-127"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 894, "makespan": 39, "avg_agents_density": 0.12734522987181363, "runtime": 7.745779814198613}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-000"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 1615, "makespan": 74, "avg_agents_density": 0.1669540768436801, "runtime": 14.449713035020977}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-001"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 873, "makespan": 36, "avg_agents_density": 0.14341679232999027, "runtime": 6.93950967118144}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-002"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 921, "makespan": 38, "avg_agents_density": 0.13789139559771973, "runtime": 7.521143117453903}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-003"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1038, "makespan": 48, "avg_agents_density": 0.11933339831069918, "runtime": 9.196946760639548}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-004"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1269, "makespan": 52, "avg_agents_density": 0.14992736388069935, "runtime": 9.828029642812908}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-005"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 913, "makespan": 38, "avg_agents_density": 0.13924324169730154, "runtime": 7.216355444397777}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-006"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1191, "makespan": 52, "avg_agents_density": 0.14912536472941387, "runtime": 10.163288893643767}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-007"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1922, "makespan": 65, "avg_agents_density": 0.17396788996860318, "runtime": 12.568027335684747}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-008"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 813, "makespan": 37, "avg_agents_density": 0.1306016891642968, "runtime": 7.155997896101326}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-009"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 997, "makespan": 47, "avg_agents_density": 0.13128654796319092, "runtime": 8.982396356761456}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-010"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1129, "makespan": 45, "avg_agents_density": 0.21010941618613643, "runtime": 8.609624408185482}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-011"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1922, "makespan": 66, "avg_agents_density": 0.18345792791788734, "runtime": 13.091845069546252}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-012"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1354, "makespan": 58, "avg_agents_density": 0.12259093396502008, "runtime": 11.298374325968325}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-013"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 868, "makespan": 31, "avg_agents_density": 0.15644118089872974, "runtime": 5.945699219591916}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-014"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2227, "makespan": 76, "avg_agents_density": 0.18176457934485057, "runtime": 14.90146248973906}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-015"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 993, "makespan": 41, "avg_agents_density": 0.15528481428469734, "runtime": 7.748148320242763}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-016"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1026, "makespan": 40, "avg_agents_density": 0.11880288668174516, "runtime": 7.968789453152567}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-017"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1503, "makespan": 58, "avg_agents_density": 0.16174972677951632, "runtime": 11.5249112714082}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-018"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 2207, "makespan": 81, "avg_agents_density": 0.16900590321338418, "runtime": 15.708426383789629}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-019"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1081, "makespan": 50, "avg_agents_density": 0.1432085740447887, "runtime": 9.291719485074282}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-020"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1318, "makespan": 45, "avg_agents_density": 0.15387203352114964, "runtime": 8.735727305524051}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-021"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 912, "makespan": 37, "avg_agents_density": 0.15143348797686948, "runtime": 7.036663019564003}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-022"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1089, "makespan": 45, "avg_agents_density": 0.16449766813578692, "runtime": 8.759070839267224}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-023"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1259, "makespan": 43, "avg_agents_density": 0.1484265337778887, "runtime": 8.296770577784628}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-024"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 954, "makespan": 45, "avg_agents_density": 0.14869183321697155, "runtime": 8.919741705991328}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-025"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 963, "makespan": 40, "avg_agents_density": 0.12534449710458276, "runtime": 7.8176416317000985}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-026"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 918, "makespan": 37, "avg_agents_density": 0.15177673112876616, "runtime": 6.66368220327422}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-027"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1402, "makespan": 46, "avg_agents_density": 0.13375825919131584, "runtime": 9.334537591785192}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-028"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 952, "makespan": 36, "avg_agents_density": 0.154765177670462, "runtime": 7.029067599214613}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-029"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 1118, "makespan": 37, "avg_agents_density": 0.15064912001156816, "runtime": 7.200805614236742}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-030"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 981, "makespan": 36, "avg_agents_density": 0.13385840246843764, "runtime": 7.103537158109248}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-031"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1008, "makespan": 59, "avg_agents_density": 0.15273744871254352, "runtime": 10.954689032398164}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-032"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1140, "makespan": 51, "avg_agents_density": 0.14283255655304028, "runtime": 9.96181651065126}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-033"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 3609, "makespan": 128, "avg_agents_density": 0.22051492318615512, "runtime": 25.710377967450768}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-034"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1149, "makespan": 42, "avg_agents_density": 0.1864211410426007, "runtime": 8.130766191054136}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-035"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1079, "makespan": 39, "avg_agents_density": 0.1858432402855998, "runtime": 7.756817917339504}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-036"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1311, "makespan": 69, "avg_agents_density": 0.14457586729268, "runtime": 14.8176510008052}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-037"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 841, "makespan": 32, "avg_agents_density": 0.14383668253278217, "runtime": 6.263814149424434}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-038"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1154, "makespan": 40, "avg_agents_density": 0.12466251328751023, "runtime": 8.011652773246169}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-039"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1770, "makespan": 69, "avg_agents_density": 0.14915497432942165, "runtime": 13.470250523649156}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-040"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1292, "makespan": 46, "avg_agents_density": 0.14227104139644733, "runtime": 9.773425388615578}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-041"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1407, "makespan": 55, "avg_agents_density": 0.16411479983782068, "runtime": 10.66427300311625}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-042"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 790, "makespan": 39, "avg_agents_density": 0.13528540943658673, "runtime": 7.704697120003402}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-043"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 945, "makespan": 31, "avg_agents_density": 0.15912743774135174, "runtime": 6.3535017697140574}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-044"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1083, "makespan": 48, "avg_agents_density": 0.13126854657033257, "runtime": 8.907761533278972}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-045"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 911, "makespan": 39, "avg_agents_density": 0.12211834789707394, "runtime": 7.6216428354382515}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-046"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 2108, "makespan": 88, "avg_agents_density": 0.1812998141670823, "runtime": 16.62304045120254}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-047"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 1695, "makespan": 76, "avg_agents_density": 0.17736614139843163, "runtime": 14.637605099007487}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-048"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1278, "makespan": 45, "avg_agents_density": 0.16252398032826174, "runtime": 8.779773336369544}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-049"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 1985, "makespan": 94, "avg_agents_density": 0.14854461046796333, "runtime": 17.533693537581712}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-050"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 987, "makespan": 42, "avg_agents_density": 0.13851273350017448, "runtime": 7.972000086680055}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-051"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1425, "makespan": 49, "avg_agents_density": 0.14239930076987284, "runtime": 9.660337104927748}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-052"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 1114, "makespan": 36, "avg_agents_density": 0.1753512682518717, "runtime": 6.998983179219067}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-053"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 1050, "makespan": 38, "avg_agents_density": 0.16881580559961454, "runtime": 7.514053453225642}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-054"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 1719, "makespan": 86, "avg_agents_density": 0.12912417652089, "runtime": 16.4274749327451}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-055"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 943, "makespan": 41, "avg_agents_density": 0.1297357457418219, "runtime": 8.030439000111073}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-056"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1233, "makespan": 47, "avg_agents_density": 0.1533775658391067, "runtime": 8.880665472242981}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-057"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1723, "makespan": 58, "avg_agents_density": 0.21256888740112936, "runtime": 11.633543201722205}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-058"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1363, "makespan": 53, "avg_agents_density": 0.15072137747504039, "runtime": 10.032891856040806}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-059"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 905, "makespan": 42, "avg_agents_density": 0.1611376831319827, "runtime": 8.512167246080935}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-060"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1105, "makespan": 47, "avg_agents_density": 0.19262576723448976, "runtime": 9.273162522353232}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-061"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1669, "makespan": 68, "avg_agents_density": 0.1372283688384506, "runtime": 13.014811933971941}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-062"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1976, "makespan": 66, "avg_agents_density": 0.17469482878907025, "runtime": 12.974227459169924}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-063"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 932, "makespan": 48, "avg_agents_density": 0.1432543840733883, "runtime": 9.355356827378273}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-064"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1111, "makespan": 42, "avg_agents_density": 0.16474483111591925, "runtime": 8.177848035469651}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-065"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1236, "makespan": 44, "avg_agents_density": 0.13130978481801392, "runtime": 8.796899365726858}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-066"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 859, "makespan": 34, "avg_agents_density": 0.1302951359011282, "runtime": 6.772803310770541}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-067"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1918, "makespan": 66, "avg_agents_density": 0.14893288688794537, "runtime": 12.245246681850404}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-068"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.5625, "CSR": 0.0, "ep_length": 127, "SoC": 4615, "makespan": 128, "avg_agents_density": 0.27824584544667047, "runtime": 25.089861144311726}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-069"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1653, "makespan": 67, "avg_agents_density": 0.16901146649043344, "runtime": 13.294697555247694}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-070"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1222, "makespan": 61, "avg_agents_density": 0.14968762285550713, "runtime": 11.977666701655835}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-071"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 805, "makespan": 34, "avg_agents_density": 0.10690516447214941, "runtime": 6.491007135715336}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-072"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 940, "makespan": 33, "avg_agents_density": 0.1348554353072268, "runtime": 6.341716335620731}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-073"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1234, "makespan": 54, "avg_agents_density": 0.15889109703824253, "runtime": 10.395501050166786}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-074"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 931, "makespan": 39, "avg_agents_density": 0.1452990937755359, "runtime": 7.538485988974571}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-075"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1552, "makespan": 66, "avg_agents_density": 0.14280489929667323, "runtime": 12.844048757571727}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-076"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1289, "makespan": 57, "avg_agents_density": 0.16307091101022142, "runtime": 11.29046566830948}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-077"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1689, "makespan": 60, "avg_agents_density": 0.1806515699747108, "runtime": 11.711429257877171}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-078"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 883, "makespan": 36, "avg_agents_density": 0.14900335579270668, "runtime": 6.693240267690271}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-079"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 830, "makespan": 33, "avg_agents_density": 0.1334896391732692, "runtime": 6.514724882785231}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-080"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 1015, "makespan": 37, "avg_agents_density": 0.1559369211139137, "runtime": 7.197988884989172}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-081"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1739, "makespan": 70, "avg_agents_density": 0.14309945070422825, "runtime": 13.324001934845}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-082"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 907, "makespan": 40, "avg_agents_density": 0.13318958858336025, "runtime": 5.942101110704243}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-083"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 110, "SoC": 2241, "makespan": 111, "avg_agents_density": 0.15599963190419816, "runtime": 20.928501148708165}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-084"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1252, "makespan": 47, "avg_agents_density": 0.16669005090940162, "runtime": 8.655621613841504}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-085"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 912, "makespan": 47, "avg_agents_density": 0.10995511536304559, "runtime": 9.03108774451539}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-086"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 1784, "makespan": 92, "avg_agents_density": 0.14612066248698352, "runtime": 16.2549255695194}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-087"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1366, "makespan": 58, "avg_agents_density": 0.17198951139899152, "runtime": 11.390139793045819}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-088"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 108, "SoC": 2685, "makespan": 109, "avg_agents_density": 0.15408812620439988, "runtime": 19.456327161751688}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-089"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1215, "makespan": 53, "avg_agents_density": 0.1663764386841157, "runtime": 9.843607429414988}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-090"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.4166666666666667, "CSR": 0.0, "ep_length": 127, "SoC": 4140, "makespan": 128, "avg_agents_density": 0.2667695767673023, "runtime": 25.06368640763685}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-091"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 823, "makespan": 39, "avg_agents_density": 0.13225464054728167, "runtime": 7.457429838832468}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-092"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1076, "makespan": 42, "avg_agents_density": 0.13984310574194206, "runtime": 8.693850920069963}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-093"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 2369, "makespan": 81, "avg_agents_density": 0.1851470601556153, "runtime": 15.620406735222787}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-094"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.5416666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 3960, "makespan": 128, "avg_agents_density": 0.22822336116539588, "runtime": 25.087158001959324}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-095"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 1426, "makespan": 83, "avg_agents_density": 0.13483504214228453, "runtime": 15.235351463779807}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-096"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1025, "makespan": 48, "avg_agents_density": 0.15124120124022253, "runtime": 9.10952953947708}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-097"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1498, "makespan": 54, "avg_agents_density": 0.16453889305908634, "runtime": 10.510836758185178}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-098"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1121, "makespan": 45, "avg_agents_density": 0.16643462706222104, "runtime": 8.622935069259256}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-099"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1243, "makespan": 48, "avg_agents_density": 0.1413117736696119, "runtime": 9.502882811706513}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-100"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 866, "makespan": 34, "avg_agents_density": 0.14295611518178358, "runtime": 6.849000785499811}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-101"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1210, "makespan": 46, "avg_agents_density": 0.1667245818518611, "runtime": 8.64347065333277}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-102"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 883, "makespan": 32, "avg_agents_density": 0.15546428200282977, "runtime": 5.618818026967347}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-103"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1396, "makespan": 48, "avg_agents_density": 0.1261893166429709, "runtime": 9.563295708503574}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-104"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 95, "SoC": 2628, "makespan": 96, "avg_agents_density": 0.19121116179512018, "runtime": 18.872766588814557}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-105"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 960, "makespan": 38, "avg_agents_density": 0.11924841423824699, "runtime": 7.273723111953586}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-106"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1053, "makespan": 40, "avg_agents_density": 0.16366097467093868, "runtime": 7.607305590994656}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-107"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1049, "makespan": 47, "avg_agents_density": 0.1640990914827501, "runtime": 9.093303048051894}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-108"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1395, "makespan": 57, "avg_agents_density": 0.15302138523086858, "runtime": 11.137699184473604}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-109"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 1077, "makespan": 36, "avg_agents_density": 0.13360493663726644, "runtime": 7.352254203055054}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-110"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1123, "makespan": 43, "avg_agents_density": 0.1730096693106028, "runtime": 8.228264104574919}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-111"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1502, "makespan": 50, "avg_agents_density": 0.18515929629034392, "runtime": 9.256320699118078}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-112"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1109, "makespan": 46, "avg_agents_density": 0.16678164741262272, "runtime": 8.845634838566184}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-113"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 941, "makespan": 45, "avg_agents_density": 0.15100316363172941, "runtime": 8.640037210658193}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-114"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 1024, "makespan": 35, "avg_agents_density": 0.15261767029799456, "runtime": 6.975944129284471}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-115"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 1862, "makespan": 76, "avg_agents_density": 0.18058594276886253, "runtime": 14.726282290648669}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-116"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1016, "makespan": 44, "avg_agents_density": 0.1531842596975068, "runtime": 8.633715588133782}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-117"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1138, "makespan": 51, "avg_agents_density": 0.15418880237289617, "runtime": 9.738912167493254}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-118"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 1203, "makespan": 38, "avg_agents_density": 0.14169336813724223, "runtime": 7.6111845606938004}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-119"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 971, "makespan": 49, "avg_agents_density": 0.13222601753846513, "runtime": 9.207299349829555}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-120"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1038, "makespan": 44, "avg_agents_density": 0.14168878519440836, "runtime": 8.730304099619389}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-121"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1082, "makespan": 44, "avg_agents_density": 0.11348221259696392, "runtime": 8.58946500113234}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-122"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 859, "makespan": 35, "avg_agents_density": 0.1465273189612396, "runtime": 6.966478729620576}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-123"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 1727, "makespan": 81, "avg_agents_density": 0.15153465967182456, "runtime": 15.561072465963662}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-124"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1069, "makespan": 39, "avg_agents_density": 0.13834386047911829, "runtime": 7.915241551119834}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-125"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 2523, "makespan": 90, "avg_agents_density": 0.21492573268235765, "runtime": 17.326749416533858}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-126"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 951, "makespan": 34, "avg_agents_density": 0.15190720802778973, "runtime": 6.776854847557843}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-127"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1563, "makespan": 48, "avg_agents_density": 0.16328836079162168, "runtime": 12.782818290870637}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-000"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.640625, "CSR": 0.0, "ep_length": 127, "SoC": 4658, "makespan": 128, "avg_agents_density": 0.24723769493514128, "runtime": 32.509627592749894}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-001"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1564, "makespan": 50, "avg_agents_density": 0.17478308703251136, "runtime": 13.098038338124752}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-002"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1778, "makespan": 55, "avg_agents_density": 0.18291336662883553, "runtime": 14.35553801432252}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-003"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1866, "makespan": 68, "avg_agents_density": 0.16875371496691377, "runtime": 17.65304319327697}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-004"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1822, "makespan": 55, "avg_agents_density": 0.1785674944469932, "runtime": 13.84685755847022}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-005"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1611, "makespan": 48, "avg_agents_density": 0.19039116492405522, "runtime": 12.369466262403876}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-006"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 2100, "makespan": 62, "avg_agents_density": 0.20094981152362015, "runtime": 16.082195517141372}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-007"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 4060, "makespan": 128, "avg_agents_density": 0.22577615971044493, "runtime": 32.430824384558946}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-008"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1205, "makespan": 41, "avg_agents_density": 0.16899868838964952, "runtime": 11.00017319014296}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-009"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1576, "makespan": 43, "avg_agents_density": 0.17861865533083424, "runtime": 11.405445206910372}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-010"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1923, "makespan": 54, "avg_agents_density": 0.25691127580829815, "runtime": 13.356229225639254}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-011"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.765625, "CSR": 0.0, "ep_length": 127, "SoC": 5258, "makespan": 128, "avg_agents_density": 0.2829820976506645, "runtime": 32.66882240958512}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-012"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2698, "makespan": 76, "avg_agents_density": 0.17970696145053772, "runtime": 19.037018400616944}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-013"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1637, "makespan": 48, "avg_agents_density": 0.2013532849100103, "runtime": 12.446065294090658}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-014"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.734375, "CSR": 0.0, "ep_length": 127, "SoC": 4799, "makespan": 128, "avg_agents_density": 0.23682477453502898, "runtime": 32.617326584644616}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-015"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1386, "makespan": 43, "avg_agents_density": 0.1825663669502709, "runtime": 10.855073382612318}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-016"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1468, "makespan": 42, "avg_agents_density": 0.1552619455564308, "runtime": 11.207918974105269}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-017"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1974, "makespan": 66, "avg_agents_density": 0.19367471279956158, "runtime": 16.800784579478204}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-018"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.578125, "CSR": 0.0, "ep_length": 127, "SoC": 4776, "makespan": 128, "avg_agents_density": 0.25835503031129964, "runtime": 33.65245750453323}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-019"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1675, "makespan": 55, "avg_agents_density": 0.18053672330213305, "runtime": 13.915914818644524}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-020"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1805, "makespan": 55, "avg_agents_density": 0.19433893666803476, "runtime": 14.301776795182377}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-021"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1539, "makespan": 41, "avg_agents_density": 0.2057890710965321, "runtime": 11.064393476117402}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-022"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1926, "makespan": 48, "avg_agents_density": 0.22699295551514556, "runtime": 12.430643220432103}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-023"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 2190, "makespan": 63, "avg_agents_density": 0.20589180107056382, "runtime": 15.998221397865564}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-024"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1408, "makespan": 45, "avg_agents_density": 0.1878505847982641, "runtime": 11.385349460877478}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-025"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1771, "makespan": 65, "avg_agents_density": 0.1605207224992822, "runtime": 16.5291587007232}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-026"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1849, "makespan": 62, "avg_agents_density": 0.20469922375010277, "runtime": 15.933889286592603}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-027"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 2459, "makespan": 82, "avg_agents_density": 0.16913871809266834, "runtime": 20.978775991126895}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-028"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 2035, "makespan": 75, "avg_agents_density": 0.20420834175088168, "runtime": 19.338365707546473}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-029"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1947, "makespan": 54, "avg_agents_density": 0.20539830323768432, "runtime": 14.200268347747624}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-030"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 1392, "makespan": 37, "avg_agents_density": 0.17169678421348256, "runtime": 10.248068382032216}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-031"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1979, "makespan": 63, "avg_agents_density": 0.2095054394010937, "runtime": 16.401562901213765}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-032"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1750, "makespan": 45, "avg_agents_density": 0.18627465269762006, "runtime": 12.042674014344811}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-033"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 127, "SoC": 5557, "makespan": 128, "avg_agents_density": 0.2669555794440551, "runtime": 32.420098348520696}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-034"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 2445, "makespan": 67, "avg_agents_density": 0.24345293838428883, "runtime": 17.73876744415611}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-035"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1966, "makespan": 54, "avg_agents_density": 0.22785081345791217, "runtime": 14.037544741295278}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-036"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 2153, "makespan": 56, "avg_agents_density": 0.18707968539613423, "runtime": 14.192984546534717}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-037"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1423, "makespan": 43, "avg_agents_density": 0.18076550350542608, "runtime": 11.00894534541294}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-038"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1760, "makespan": 51, "avg_agents_density": 0.16305038706247899, "runtime": 13.112803543917835}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-039"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 2431, "makespan": 81, "avg_agents_density": 0.19668391297122367, "runtime": 20.86756523186341}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-040"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 2216, "makespan": 57, "avg_agents_density": 0.19963512796192404, "runtime": 14.698560365010053}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-041"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 2546, "makespan": 66, "avg_agents_density": 0.215371527133835, "runtime": 17.111978984437883}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-042"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 1455, "makespan": 35, "avg_agents_density": 0.18271129018881674, "runtime": 9.228095974307507}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-043"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1666, "makespan": 55, "avg_agents_density": 0.19167534861641222, "runtime": 14.030341945588589}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-044"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1834, "makespan": 51, "avg_agents_density": 0.17850620536528736, "runtime": 12.853159926831722}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-045"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 1256, "makespan": 38, "avg_agents_density": 0.16269305726156602, "runtime": 9.947152701672167}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-046"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 127, "SoC": 4460, "makespan": 128, "avg_agents_density": 0.2454095457784681, "runtime": 33.54108812613413}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-047"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 2216, "makespan": 63, "avg_agents_density": 0.2240746496869288, "runtime": 16.318510414101183}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-048"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 2089, "makespan": 65, "avg_agents_density": 0.21897133881161499, "runtime": 16.48812273563817}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-049"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 2445, "makespan": 72, "avg_agents_density": 0.18567324972597365, "runtime": 18.040476304478943}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-050"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1595, "makespan": 49, "avg_agents_density": 0.17911313167203805, "runtime": 12.586148406844586}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-051"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 2755, "makespan": 88, "avg_agents_density": 0.18194205387623896, "runtime": 22.632313660811633}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-052"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 4867, "makespan": 128, "avg_agents_density": 0.2848129886865566, "runtime": 32.84391159238294}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-053"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1596, "makespan": 47, "avg_agents_density": 0.20813725785019474, "runtime": 12.57098475145176}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-054"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 2551, "makespan": 90, "avg_agents_density": 0.18483861533676307, "runtime": 22.626220042817295}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-055"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 1221, "makespan": 36, "avg_agents_density": 0.18125173623172863, "runtime": 9.282259630039334}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-056"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1783, "makespan": 51, "avg_agents_density": 0.18688704383472682, "runtime": 13.424296376295388}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-057"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 111, "SoC": 4509, "makespan": 112, "avg_agents_density": 0.28010639872472315, "runtime": 29.252049522008747}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-058"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 2364, "makespan": 65, "avg_agents_density": 0.20388486467301087, "runtime": 16.475266113877296}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-059"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1438, "makespan": 40, "avg_agents_density": 0.21616245030245707, "runtime": 10.249491274822503}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-060"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1933, "makespan": 47, "avg_agents_density": 0.24482508681203355, "runtime": 12.728896033018827}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-061"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 3403, "makespan": 84, "avg_agents_density": 0.19640076695051226, "runtime": 21.936905840877444}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-062"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 2808, "makespan": 73, "avg_agents_density": 0.2171321032150809, "runtime": 18.19142525549978}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-063"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1653, "makespan": 46, "avg_agents_density": 0.19193314188119331, "runtime": 12.115648650564253}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-064"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 121, "SoC": 2845, "makespan": 122, "avg_agents_density": 0.20239281488941674, "runtime": 29.43764643697068}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-065"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 126, "SoC": 3565, "makespan": 127, "avg_agents_density": 0.1892873141502705, "runtime": 32.956671038642526}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-066"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1363, "makespan": 42, "avg_agents_density": 0.17494550589992325, "runtime": 9.430712170433253}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-067"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.578125, "CSR": 0.0, "ep_length": 127, "SoC": 4685, "makespan": 128, "avg_agents_density": 0.23036689026923918, "runtime": 32.89274702966213}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-068"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 127, "SoC": 4632, "makespan": 128, "avg_agents_density": 0.288938132147642, "runtime": 33.562855002470315}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-069"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 2691, "makespan": 72, "avg_agents_density": 0.22235346426715666, "runtime": 18.889001574367285}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-070"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1553, "makespan": 45, "avg_agents_density": 0.18956221475779325, "runtime": 11.857565928716213}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-071"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 1150, "makespan": 36, "avg_agents_density": 0.13954332238237757, "runtime": 9.463900237809867}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-072"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1589, "makespan": 48, "avg_agents_density": 0.17061648248283764, "runtime": 12.446195664349943}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-073"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 2019, "makespan": 59, "avg_agents_density": 0.20298698615886673, "runtime": 15.16915357671678}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-074"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1576, "makespan": 53, "avg_agents_density": 0.18398996770370465, "runtime": 13.821504816412926}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-075"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.671875, "CSR": 0.0, "ep_length": 127, "SoC": 4318, "makespan": 128, "avg_agents_density": 0.22983019797873616, "runtime": 32.36779654305428}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-076"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 2227, "makespan": 61, "avg_agents_density": 0.2095252027462035, "runtime": 16.16741442354396}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-077"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2423, "makespan": 68, "avg_agents_density": 0.21925940542526198, "runtime": 17.880770158953965}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-078"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1380, "makespan": 39, "avg_agents_density": 0.1812390420482313, "runtime": 10.449042116291821}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-079"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1525, "makespan": 48, "avg_agents_density": 0.1745053201138197, "runtime": 13.24206518009305}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-080"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1425, "makespan": 39, "avg_agents_density": 0.19655273862237949, "runtime": 10.41307192062959}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-081"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 113, "SoC": 3218, "makespan": 114, "avg_agents_density": 0.1707564054816135, "runtime": 28.469967095647007}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-082"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1445, "makespan": 44, "avg_agents_density": 0.1753037735389927, "runtime": 11.412279261741787}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-083"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 127, "SoC": 4599, "makespan": 128, "avg_agents_density": 0.2210871650021678, "runtime": 33.37233517551795}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-084"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 119, "SoC": 2743, "makespan": 120, "avg_agents_density": 0.20097499791261503, "runtime": 27.755254661664367}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-085"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1262, "makespan": 46, "avg_agents_density": 0.1490787304027958, "runtime": 12.113107541110367}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-086"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 2289, "makespan": 60, "avg_agents_density": 0.21567532787347843, "runtime": 15.68832836765796}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-087"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 98, "SoC": 2980, "makespan": 99, "avg_agents_density": 0.22911251614566955, "runtime": 25.17862120922655}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-088"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 126, "SoC": 4665, "makespan": 127, "avg_agents_density": 0.201005132889643, "runtime": 32.64645590214059}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-089"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 125, "SoC": 3882, "makespan": 126, "avg_agents_density": 0.2183609124748234, "runtime": 31.178815786726773}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-090"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 5130, "makespan": 128, "avg_agents_density": 0.26234548425841486, "runtime": 32.71465934952721}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-091"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1278, "makespan": 42, "avg_agents_density": 0.17572381461479, "runtime": 10.635643493384123}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-092"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1975, "makespan": 58, "avg_agents_density": 0.1824048178922566, "runtime": 15.316347031388432}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-093"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.5625, "CSR": 0.0, "ep_length": 127, "SoC": 5744, "makespan": 128, "avg_agents_density": 0.3014684103364183, "runtime": 33.16248760186136}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-094"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.328125, "CSR": 0.0, "ep_length": 127, "SoC": 5996, "makespan": 128, "avg_agents_density": 0.3548679608711097, "runtime": 33.11734567023814}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-095"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 127, "SoC": 2912, "makespan": 128, "avg_agents_density": 0.17767490142888498, "runtime": 32.68345057172701}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-096"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1622, "makespan": 47, "avg_agents_density": 0.20053223830714031, "runtime": 11.613832794129848}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-097"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 126, "SoC": 4462, "makespan": 127, "avg_agents_density": 0.22660459439821534, "runtime": 32.54909702204168}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-098"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1868, "makespan": 56, "avg_agents_density": 0.19941669313937657, "runtime": 14.021994940005243}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-099"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1963, "makespan": 47, "avg_agents_density": 0.19153780820677566, "runtime": 12.041741752065718}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-100"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1975, "makespan": 55, "avg_agents_density": 0.19808530303175945, "runtime": 14.322757678572088}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-101"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 2012, "makespan": 64, "avg_agents_density": 0.22497231846213708, "runtime": 16.776373502332717}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-102"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1464, "makespan": 47, "avg_agents_density": 0.18863028694322223, "runtime": 12.261081411037594}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-103"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2581, "makespan": 68, "avg_agents_density": 0.18870861218667861, "runtime": 17.942256006412208}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-104"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.859375, "CSR": 0.0, "ep_length": 127, "SoC": 4600, "makespan": 128, "avg_agents_density": 0.255169021810115, "runtime": 33.49980229465291}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-105"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1353, "makespan": 40, "avg_agents_density": 0.16577954307531323, "runtime": 9.950708715710789}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-106"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1560, "makespan": 39, "avg_agents_density": 0.2230756712582381, "runtime": 10.193983873352408}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-107"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2205, "makespan": 68, "avg_agents_density": 0.212436449649298, "runtime": 17.961950396653265}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-108"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 90, "SoC": 2690, "makespan": 91, "avg_agents_density": 0.20594731910347314, "runtime": 23.783715694677085}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-109"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1754, "makespan": 56, "avg_agents_density": 0.1795536336921592, "runtime": 14.777726653032005}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-110"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 2322, "makespan": 67, "avg_agents_density": 0.22119752127812858, "runtime": 17.502416281495243}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-111"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.765625, "CSR": 0.0, "ep_length": 127, "SoC": 4508, "makespan": 128, "avg_agents_density": 0.24823711966066006, "runtime": 33.50082996720448}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-112"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1531, "makespan": 42, "avg_agents_density": 0.2212690094731552, "runtime": 10.428348341491073}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-113"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1404, "makespan": 41, "avg_agents_density": 0.20156570341350713, "runtime": 10.824807306751609}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-114"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2910, "makespan": 76, "avg_agents_density": 0.22152378029176895, "runtime": 18.301287446171045}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-115"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 127, "SoC": 3727, "makespan": 128, "avg_agents_density": 0.24948870414901345, "runtime": 32.92976958397776}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-116"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1484, "makespan": 43, "avg_agents_density": 0.18030086277677512, "runtime": 11.259425377007574}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-117"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 2608, "makespan": 72, "avg_agents_density": 0.21284075006018122, "runtime": 18.395636345259845}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-118"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 2892, "makespan": 80, "avg_agents_density": 0.20188253149957955, "runtime": 20.86381255974993}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-119"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1553, "makespan": 45, "avg_agents_density": 0.17670986189651158, "runtime": 11.585765565745533}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-120"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1625, "makespan": 42, "avg_agents_density": 0.19403693686753462, "runtime": 11.021375899668783}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-121"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1515, "makespan": 53, "avg_agents_density": 0.143304286512183, "runtime": 13.374217615928501}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-122"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 1272, "makespan": 37, "avg_agents_density": 0.19527319470606874, "runtime": 9.977417452726513}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-123"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 116, "SoC": 3393, "makespan": 117, "avg_agents_density": 0.19500499116437173, "runtime": 29.366915897466242}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-124"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 2381, "makespan": 63, "avg_agents_density": 0.1789438389569244, "runtime": 16.422718559391797}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-125"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 127, "SoC": 5018, "makespan": 128, "avg_agents_density": 0.29884746120403777, "runtime": 33.219119454268366}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-126"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1801, "makespan": 57, "avg_agents_density": 0.207572855744229, "runtime": 14.276044713333249}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-127"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-5actions"}]