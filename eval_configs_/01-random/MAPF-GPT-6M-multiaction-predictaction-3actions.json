[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 84, "makespan": 22, "avg_agents_density": 0.029175811746493627, "runtime": 0.19085643580183387}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-000"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 72, "makespan": 19, "avg_agents_density": 0.027261715436207083, "runtime": 0.6514280256815255}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-001"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 78, "makespan": 19, "avg_agents_density": 0.03519920514975597, "runtime": 0.3156521846540272}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-002"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 145, "makespan": 28, "avg_agents_density": 0.027116685231739927, "runtime": 0.7298981286585331}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-003"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 113, "makespan": 32, "avg_agents_density": 0.03033924902660568, "runtime": 1.3045661388896406}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-004"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 120, "makespan": 29, "avg_agents_density": 0.0320676481498865, "runtime": 0.9918041783384979}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-005"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 85, "makespan": 19, "avg_agents_density": 0.031162907887059506, "runtime": 0.3350675655528903}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-006"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 171, "makespan": 40, "avg_agents_density": 0.03331869722147674, "runtime": 1.0134048000909388}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-007"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 169, "makespan": 34, "avg_agents_density": 0.030851378781052315, "runtime": 1.1441655117087066}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-008"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 124, "makespan": 30, "avg_agents_density": 0.031984433218980084, "runtime": 1.0817704345099628}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-009"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 93, "makespan": 32, "avg_agents_density": 0.02212169908907849, "runtime": 0.529853695537895}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-010"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 114, "makespan": 25, "avg_agents_density": 0.03738555422785999, "runtime": 0.7974293562583625}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-011"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 168, "makespan": 40, "avg_agents_density": 0.044539219921166585, "runtime": 1.405751963146031}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-012"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 138, "makespan": 29, "avg_agents_density": 0.025067098122459514, "runtime": 1.0265889074653387}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-013"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 135, "makespan": 26, "avg_agents_density": 0.04060946965066354, "runtime": 0.43870389368385077}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-014"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 161, "makespan": 33, "avg_agents_density": 0.042492092604659304, "runtime": 0.9134912248700857}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-015"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 15, "SoC": 75, "makespan": 16, "avg_agents_density": 0.032529856484987796, "runtime": 0.5507848686538637}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-016"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 93, "makespan": 23, "avg_agents_density": 0.03565926613464659, "runtime": 0.7567962314933538}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-017"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 133, "makespan": 24, "avg_agents_density": 0.026468235076132114, "runtime": 0.8432419351302087}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-018"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 149, "makespan": 28, "avg_agents_density": 0.03598966689189745, "runtime": 0.47348511684685946}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-019"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 145, "makespan": 29, "avg_agents_density": 0.03175945630253054, "runtime": 0.8059301041066647}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-020"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 134, "makespan": 27, "avg_agents_density": 0.03550711898812749, "runtime": 0.9283727803267539}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-021"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 133, "makespan": 30, "avg_agents_density": 0.03153074965150951, "runtime": 1.0728907268494368}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-022"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 111, "makespan": 22, "avg_agents_density": 0.04038046964016156, "runtime": 0.37443494191393256}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-023"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 113, "makespan": 19, "avg_agents_density": 0.026330729572493182, "runtime": 0.5322064119391143}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-024"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 19, "SoC": 99, "makespan": 20, "avg_agents_density": 0.03674478678353917, "runtime": 0.7664245772175491}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-025"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 116, "makespan": 34, "avg_agents_density": 0.03047703776625024, "runtime": 1.134504263754934}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-026"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 99, "makespan": 23, "avg_agents_density": 0.0317688848222396, "runtime": 0.34280933486297727}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-027"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 198, "makespan": 35, "avg_agents_density": 0.030060506555694644, "runtime": 0.9096049750223756}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-028"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 135, "makespan": 25, "avg_agents_density": 0.025163053132083366, "runtime": 0.9118529944680631}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-029"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 116, "makespan": 27, "avg_agents_density": 0.039581067322578205, "runtime": 0.8420590809546411}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-030"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 94, "makespan": 22, "avg_agents_density": 0.03451329796203328, "runtime": 0.3675342150963843}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-031"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 115, "makespan": 24, "avg_agents_density": 0.027053884782457273, "runtime": 0.803883783519268}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-032"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 199, "makespan": 33, "avg_agents_density": 0.026185569078112588, "runtime": 1.1300708018243313}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-033"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 132, "makespan": 27, "avg_agents_density": 0.040378922085884, "runtime": 0.9120523217134178}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-034"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 107, "makespan": 21, "avg_agents_density": 0.03654432936581821, "runtime": 0.780306201428175}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-035"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 109, "makespan": 23, "avg_agents_density": 0.04721356214206226, "runtime": 0.8172564590349793}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-036"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 113, "makespan": 30, "avg_agents_density": 0.029388374868547337, "runtime": 0.9420956508256495}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-037"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 123, "makespan": 22, "avg_agents_density": 0.029975629992261027, "runtime": 0.382539882324636}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-038"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 87, "makespan": 25, "avg_agents_density": 0.025034059504575705, "runtime": 0.8418817464262247}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-039"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 103, "makespan": 27, "avg_agents_density": 0.02368247089397184, "runtime": 0.8770471825264394}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-040"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 136, "makespan": 28, "avg_agents_density": 0.031092843019306413, "runtime": 0.9480053009465337}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-041"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 19, "SoC": 126, "makespan": 20, "avg_agents_density": 0.041434081554803825, "runtime": 0.3547796458005905}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-042"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 103, "makespan": 24, "avg_agents_density": 0.03192071860807664, "runtime": 0.9342269063927233}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-043"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 117, "makespan": 21, "avg_agents_density": 0.041749976615283235, "runtime": 0.7921359157189727}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-044"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 78, "makespan": 27, "avg_agents_density": 0.036974698854744144, "runtime": 0.8827895657159388}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-045"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 115, "makespan": 24, "avg_agents_density": 0.036884987430939584, "runtime": 0.4144290001131594}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-046"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 147, "makespan": 32, "avg_agents_density": 0.039613115587814884, "runtime": 0.5395237426273525}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-047"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 114, "makespan": 24, "avg_agents_density": 0.043090066894605004, "runtime": 0.7959417128004134}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-048"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 131, "makespan": 22, "avg_agents_density": 0.04268730504530783, "runtime": 0.8506304337643087}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-049"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 132, "makespan": 37, "avg_agents_density": 0.03274886512122503, "runtime": 1.270263399463147}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-050"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 123, "makespan": 29, "avg_agents_density": 0.027671684427741317, "runtime": 0.48835061490535736}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-051"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 122, "makespan": 24, "avg_agents_density": 0.0221948414965318, "runtime": 0.8606904814951122}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-052"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 19, "SoC": 117, "makespan": 20, "avg_agents_density": 0.050863212781680656, "runtime": 0.7036221837624907}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-053"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 101, "makespan": 24, "avg_agents_density": 0.030768431558963857, "runtime": 0.8360158833675086}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-054"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 167, "makespan": 37, "avg_agents_density": 0.04342757985003471, "runtime": 1.331344809383154}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-055"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 112, "makespan": 23, "avg_agents_density": 0.03174168097153102, "runtime": 0.3881238657049835}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-056"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 121, "makespan": 27, "avg_agents_density": 0.04103468518629486, "runtime": 0.8859157217666507}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-057"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 156, "makespan": 37, "avg_agents_density": 0.041636326053848434, "runtime": 1.2771122991107404}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-058"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 183, "makespan": 43, "avg_agents_density": 0.04089639697637834, "runtime": 1.5139502668753266}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-059"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 113, "makespan": 25, "avg_agents_density": 0.039721798441952144, "runtime": 0.40929438918828964}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-060"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 120, "makespan": 30, "avg_agents_density": 0.037424327417953436, "runtime": 1.100504360627383}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-061"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 141, "makespan": 27, "avg_agents_density": 0.03126137654100332, "runtime": 0.9414913021028042}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-062"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 136, "makespan": 29, "avg_agents_density": 0.03409957179189997, "runtime": 1.0419365870766342}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-063"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 111, "makespan": 25, "avg_agents_density": 0.025457041170563743, "runtime": 0.6771503943018615}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-064"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 121, "makespan": 22, "avg_agents_density": 0.03480259567559282, "runtime": 0.7538851285353303}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-065"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 137, "makespan": 32, "avg_agents_density": 0.028874949279959778, "runtime": 0.2729209214448929}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-066"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 97, "makespan": 25, "avg_agents_density": 0.028038985177166367, "runtime": 0.4188904748298228}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-067"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 161, "makespan": 51, "avg_agents_density": 0.03507974499406592, "runtime": 1.6442262050695717}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-068"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 116, "makespan": 25, "avg_agents_density": 0.033003742144235855, "runtime": 0.6566430912353098}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-069"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 142, "makespan": 31, "avg_agents_density": 0.03187148260336627, "runtime": 0.26520353415980935}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-070"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 135, "makespan": 32, "avg_agents_density": 0.0335431929267791, "runtime": 0.5205691820010543}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-071"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 116, "makespan": 23, "avg_agents_density": 0.024665803521410647, "runtime": 0.8094091638922691}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-072"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 133, "makespan": 27, "avg_agents_density": 0.02830330438882817, "runtime": 0.6687411498278379}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-073"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 124, "makespan": 26, "avg_agents_density": 0.02952873035538129, "runtime": 0.2208961290307343}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-074"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 111, "makespan": 23, "avg_agents_density": 0.027096700418745522, "runtime": 0.39561608247458935}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-075"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 19, "SoC": 93, "makespan": 20, "avg_agents_density": 0.028510486829347485, "runtime": 0.646688578184694}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-076"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 129, "makespan": 25, "avg_agents_density": 0.035385285379733046, "runtime": 0.663814942818135}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-077"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 123, "makespan": 25, "avg_agents_density": 0.04229925112813448, "runtime": 0.21290684444829822}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-078"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 94, "makespan": 23, "avg_agents_density": 0.0337363134317402, "runtime": 0.5999021199531853}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-079"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 104, "makespan": 19, "avg_agents_density": 0.04624922304107055, "runtime": 0.3184643955901265}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-080"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 105, "makespan": 22, "avg_agents_density": 0.03628749797761496, "runtime": 0.6008675503544509}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-081"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 145, "makespan": 32, "avg_agents_density": 0.026798275924846036, "runtime": 0.2726069106720388}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-082"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 128, "makespan": 23, "avg_agents_density": 0.02980618576984483, "runtime": 0.39540222054347396}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-083"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 140, "makespan": 33, "avg_agents_density": 0.032988416542811295, "runtime": 1.1077146329917014}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-084"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 102, "makespan": 21, "avg_agents_density": 0.041607036451339896, "runtime": 0.6118075456470251}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-085"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 111, "makespan": 27, "avg_agents_density": 0.026321842835535018, "runtime": 0.23480946198105812}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-086"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 170, "makespan": 26, "avg_agents_density": 0.03861532075530416, "runtime": 0.44224469643086195}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-087"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 130, "makespan": 23, "avg_agents_density": 0.03087662863878586, "runtime": 0.8132871026173234}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-088"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 203, "makespan": 58, "avg_agents_density": 0.027487663230119076, "runtime": 1.5253447317518294}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-089"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 175, "makespan": 42, "avg_agents_density": 0.03533116438347705, "runtime": 0.35346507420763373}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-090"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 118, "makespan": 30, "avg_agents_density": 0.029015387599910996, "runtime": 0.4975420976988971}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-091"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 113, "makespan": 27, "avg_agents_density": 0.03276549244116992, "runtime": 0.8523983624763787}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-092"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 128, "makespan": 25, "avg_agents_density": 0.03463956817321407, "runtime": 0.654572615865618}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-093"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 122, "makespan": 28, "avg_agents_density": 0.03976853752387432, "runtime": 1.0582054280675948}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-094"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 214, "makespan": 44, "avg_agents_density": 0.0465145168701597, "runtime": 0.5042230258695781}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-095"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 129, "makespan": 37, "avg_agents_density": 0.024180065121284962, "runtime": 1.246694483794272}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-096"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 156, "makespan": 27, "avg_agents_density": 0.03798963547590379, "runtime": 0.45189198292791843}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-097"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 163, "makespan": 28, "avg_agents_density": 0.04227894333930174, "runtime": 0.23896187637001276}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-098"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 180, "makespan": 33, "avg_agents_density": 0.025956578726012876, "runtime": 1.0827804948203266}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-099"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 113, "makespan": 23, "avg_agents_density": 0.027389277412272834, "runtime": 0.19881576439365745}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-100"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 110, "makespan": 19, "avg_agents_density": 0.03228253165660453, "runtime": 0.3156185196712613}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-101"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 93, "makespan": 26, "avg_agents_density": 0.034078746171531935, "runtime": 0.8984335958957672}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-102"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 123, "makespan": 31, "avg_agents_density": 0.024348093276085156, "runtime": 1.2160671395249665}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-103"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 126, "makespan": 28, "avg_agents_density": 0.0384435931813497, "runtime": 0.2406395641155541}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-104"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 177, "makespan": 36, "avg_agents_density": 0.039904374043226123, "runtime": 0.615068418905139}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-105"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 114, "makespan": 25, "avg_agents_density": 0.0271154876172071, "runtime": 0.8667136295698583}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-106"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 146, "makespan": 31, "avg_agents_density": 0.039801311013068046, "runtime": 1.0224277549423277}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-107"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 116, "makespan": 26, "avg_agents_density": 0.0442584162290211, "runtime": 0.2220640406012535}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-108"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 130, "makespan": 23, "avg_agents_density": 0.032353945310492516, "runtime": 0.3828756823204458}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-109"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 159, "makespan": 29, "avg_agents_density": 0.032483188403082355, "runtime": 0.9828418451361358}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-110"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 90, "makespan": 23, "avg_agents_density": 0.03847818432931407, "runtime": 0.7878894959576428}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-111"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 141, "makespan": 32, "avg_agents_density": 0.03482239548812144, "runtime": 0.27220391761511564}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-112"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 119, "makespan": 25, "avg_agents_density": 0.04718561063168152, "runtime": 0.42294273572042584}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-113"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 111, "makespan": 28, "avg_agents_density": 0.04083511998380596, "runtime": 1.0280971499159932}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-114"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 148, "makespan": 24, "avg_agents_density": 0.03995353656251095, "runtime": 0.808004911057651}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-115"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 121, "makespan": 24, "avg_agents_density": 0.036233391795677486, "runtime": 0.20193989016115665}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-116"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 137, "makespan": 30, "avg_agents_density": 0.044527840152665206, "runtime": 0.49854573933407664}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-117"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 121, "makespan": 36, "avg_agents_density": 0.03123970410729572, "runtime": 1.2251498089171946}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-118"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 13, "SoC": 73, "makespan": 14, "avg_agents_density": 0.04947131215006946, "runtime": 0.5142234261147678}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-119"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 106, "makespan": 33, "avg_agents_density": 0.030058929914708793, "runtime": 0.280600315425545}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-120"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 174, "makespan": 33, "avg_agents_density": 0.03121483813585051, "runtime": 0.5566963390447199}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-121"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 143, "makespan": 33, "avg_agents_density": 0.02691210249082416, "runtime": 1.1531881913542747}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-122"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 158, "makespan": 29, "avg_agents_density": 0.029315172353333373, "runtime": 0.9313316573388875}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-123"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 132, "makespan": 26, "avg_agents_density": 0.028841303485242435, "runtime": 0.2321518799290061}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-124"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 113, "makespan": 23, "avg_agents_density": 0.023911694874829626, "runtime": 0.3951089605689049}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-125"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 123, "makespan": 27, "avg_agents_density": 0.035526003740642735, "runtime": 0.9557540556415915}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-126"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 110, "makespan": 23, "avg_agents_density": 0.02872172834532517, "runtime": 0.613719277549535}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-127"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 254, "makespan": 30, "avg_agents_density": 0.04866832038913024, "runtime": 1.9826195044443011}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-000"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 310, "makespan": 35, "avg_agents_density": 0.05638126010261705, "runtime": 2.247772815171629}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-001"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 237, "makespan": 36, "avg_agents_density": 0.0496353722832916, "runtime": 2.359299398958683}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-002"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 267, "makespan": 27, "avg_agents_density": 0.049986266444938206, "runtime": 1.8037918452173471}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-003"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 249, "makespan": 33, "avg_agents_density": 0.0422621292585014, "runtime": 2.131003928836435}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-004"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 244, "makespan": 25, "avg_agents_density": 0.06151355476241838, "runtime": 1.7191658150404692}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-005"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 196, "makespan": 22, "avg_agents_density": 0.057637989923593834, "runtime": 1.4512583492323756}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-006"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 293, "makespan": 38, "avg_agents_density": 0.05905407303800217, "runtime": 2.3738621240481734}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-007"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 424, "makespan": 39, "avg_agents_density": 0.07260243822893991, "runtime": 2.6376363071613014}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-008"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 251, "makespan": 35, "avg_agents_density": 0.05806126345082115, "runtime": 2.3870992963202298}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-009"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 241, "makespan": 39, "avg_agents_density": 0.0511707510540942, "runtime": 2.6074966294690967}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-010"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 226, "makespan": 29, "avg_agents_density": 0.085716655097094, "runtime": 1.8751141279935837}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-011"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 432, "makespan": 39, "avg_agents_density": 0.0736114374880588, "runtime": 2.741247203666717}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-012"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 286, "makespan": 38, "avg_agents_density": 0.05105442569836353, "runtime": 2.362029954791069}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-013"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 255, "makespan": 26, "avg_agents_density": 0.0749577995911377, "runtime": 1.6475422498770058}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-014"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 344, "makespan": 36, "avg_agents_density": 0.06823789211587364, "runtime": 2.362867237534374}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-015"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 197, "makespan": 32, "avg_agents_density": 0.05400944656819519, "runtime": 1.9217414041049778}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-016"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 236, "makespan": 30, "avg_agents_density": 0.05224492822683701, "runtime": 1.8850874998606741}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-017"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 244, "makespan": 27, "avg_agents_density": 0.04898409579833157, "runtime": 1.6675599599257112}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-018"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 322, "makespan": 40, "avg_agents_density": 0.06451647481447267, "runtime": 2.538402949925512}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-019"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 240, "makespan": 30, "avg_agents_density": 0.05868843009999711, "runtime": 1.9760264456272125}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-020"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 264, "makespan": 31, "avg_agents_density": 0.05918761173003908, "runtime": 2.038202499039471}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-021"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 244, "makespan": 30, "avg_agents_density": 0.05748183913318187, "runtime": 1.7582375593483448}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-022"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 276, "makespan": 34, "avg_agents_density": 0.07223086546253515, "runtime": 2.1295805536210537}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-023"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 290, "makespan": 36, "avg_agents_density": 0.04543689706645202, "runtime": 2.2345514870248735}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-024"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 204, "makespan": 22, "avg_agents_density": 0.06307532915516312, "runtime": 1.4706788957118988}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-025"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 243, "makespan": 34, "avg_agents_density": 0.045032981003263514, "runtime": 2.136691370047629}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-026"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 228, "makespan": 23, "avg_agents_density": 0.06505470286053984, "runtime": 1.514332642313093}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-027"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 343, "makespan": 33, "avg_agents_density": 0.06029308151249711, "runtime": 2.2407018919475377}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-028"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 275, "makespan": 30, "avg_agents_density": 0.053164199503603266, "runtime": 2.053593489341438}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-029"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 232, "makespan": 25, "avg_agents_density": 0.0596811963380076, "runtime": 1.640277850907296}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-030"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 238, "makespan": 30, "avg_agents_density": 0.057219776319605564, "runtime": 1.9931087563745677}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-031"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 213, "makespan": 26, "avg_agents_density": 0.05056646972294046, "runtime": 1.7446405934169888}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-032"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 319, "makespan": 44, "avg_agents_density": 0.04550886533676738, "runtime": 2.839903417509049}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-033"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 222, "makespan": 29, "avg_agents_density": 0.07038483735219353, "runtime": 1.8280011527240276}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-034"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 204, "makespan": 22, "avg_agents_density": 0.0582721373288691, "runtime": 1.61863210843876}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-035"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 252, "makespan": 31, "avg_agents_density": 0.07574294636483798, "runtime": 1.9546962538734078}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-036"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 286, "makespan": 33, "avg_agents_density": 0.050461123428860506, "runtime": 2.0861879400908947}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-037"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 240, "makespan": 22, "avg_agents_density": 0.048527032934432605, "runtime": 1.4587777983397245}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-038"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 249, "makespan": 34, "avg_agents_density": 0.04766351290043452, "runtime": 2.1733708968386054}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-039"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 297, "makespan": 40, "avg_agents_density": 0.05188640929382483, "runtime": 2.5091534201055765}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-040"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 365, "makespan": 48, "avg_agents_density": 0.05149406242039668, "runtime": 3.180381395854056}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-041"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 275, "makespan": 32, "avg_agents_density": 0.05542550766283253, "runtime": 2.1062168972566724}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-042"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 233, "makespan": 24, "avg_agents_density": 0.05727616476918434, "runtime": 1.6276359944604337}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-043"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 223, "makespan": 23, "avg_agents_density": 0.06037067532236153, "runtime": 1.7296301005408168}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-044"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 231, "makespan": 27, "avg_agents_density": 0.04777897968130292, "runtime": 1.6344733648002148}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-045"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 248, "makespan": 25, "avg_agents_density": 0.05826494063926129, "runtime": 1.6480564111843705}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-046"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 292, "makespan": 28, "avg_agents_density": 0.08338014922462628, "runtime": 1.8525630254298449}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-047"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 284, "makespan": 28, "avg_agents_density": 0.06639068009903444, "runtime": 2.100649682339281}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-048"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 326, "makespan": 40, "avg_agents_density": 0.06637411293588188, "runtime": 2.483151894528419}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-049"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 245, "makespan": 37, "avg_agents_density": 0.05061132404685976, "runtime": 2.4048806405626237}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-050"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 297, "makespan": 28, "avg_agents_density": 0.06030628789895976, "runtime": 1.8563692341558635}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-051"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 283, "makespan": 36, "avg_agents_density": 0.04946034309541675, "runtime": 2.438673398923129}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-052"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 217, "makespan": 24, "avg_agents_density": 0.07189722418272586, "runtime": 1.4225890235975385}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-053"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 250, "makespan": 26, "avg_agents_density": 0.061874695538484875, "runtime": 1.5903698364272714}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-054"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 393, "makespan": 48, "avg_agents_density": 0.057905567444133305, "runtime": 2.9748477791436017}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-055"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 212, "makespan": 22, "avg_agents_density": 0.052922594162218846, "runtime": 1.4420776828192174}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-056"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 221, "makespan": 27, "avg_agents_density": 0.06389336876372202, "runtime": 1.8344990755431354}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-057"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 253, "makespan": 30, "avg_agents_density": 0.06735460827950522, "runtime": 2.0451150154694915}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-058"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 343, "makespan": 41, "avg_agents_density": 0.06474708032015945, "runtime": 2.6025329837575555}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-059"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 230, "makespan": 26, "avg_agents_density": 0.06378798003761751, "runtime": 1.6012170873582363}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-060"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 273, "makespan": 34, "avg_agents_density": 0.07158145714124053, "runtime": 2.168939599301666}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-061"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 307, "makespan": 33, "avg_agents_density": 0.04569899817669415, "runtime": 2.0851768366992474}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-062"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 360, "makespan": 34, "avg_agents_density": 0.06181244934594965, "runtime": 2.2517165425233543}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-063"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 226, "makespan": 28, "avg_agents_density": 0.05487998194704379, "runtime": 1.815394445322454}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-064"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 269, "makespan": 36, "avg_agents_density": 0.060580746410052226, "runtime": 2.2653214568272233}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-065"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 271, "makespan": 28, "avg_agents_density": 0.04873955044511148, "runtime": 1.8682926800101995}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-066"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 236, "makespan": 26, "avg_agents_density": 0.048584645041906606, "runtime": 1.479121052660048}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-067"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 411, "makespan": 53, "avg_agents_density": 0.0603812583238169, "runtime": 3.402397329453379}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-068"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 275, "makespan": 33, "avg_agents_density": 0.07319200116774591, "runtime": 2.0582497571595013}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-069"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 302, "makespan": 33, "avg_agents_density": 0.06701719822508509, "runtime": 1.8677594452165067}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-070"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 326, "makespan": 51, "avg_agents_density": 0.04764614715173809, "runtime": 2.905395613051951}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-071"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 251, "makespan": 23, "avg_agents_density": 0.042328126412076415, "runtime": 1.5694318301975727}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-072"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 242, "makespan": 27, "avg_agents_density": 0.04694468364754267, "runtime": 1.6901122480630875}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-073"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 277, "makespan": 33, "avg_agents_density": 0.05682940706110711, "runtime": 1.9291001856327057}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-074"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 254, "makespan": 40, "avg_agents_density": 0.04975726820517216, "runtime": 2.2795954709872603}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-075"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 276, "makespan": 35, "avg_agents_density": 0.05720082984519332, "runtime": 2.2219239021651447}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-076"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 252, "makespan": 33, "avg_agents_density": 0.057309671820858006, "runtime": 2.095722371712327}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-077"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 351, "makespan": 37, "avg_agents_density": 0.05938485384863824, "runtime": 1.981743429787457}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-078"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 205, "makespan": 27, "avg_agents_density": 0.054843672947856074, "runtime": 1.6277430159971118}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-079"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 236, "makespan": 26, "avg_agents_density": 0.05808098590873668, "runtime": 1.6484888922423124}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-080"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 258, "makespan": 28, "avg_agents_density": 0.05868404438314757, "runtime": 1.7369463392533362}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-081"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 337, "makespan": 42, "avg_agents_density": 0.048358526635613706, "runtime": 2.557244378142059}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-082"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 290, "makespan": 27, "avg_agents_density": 0.06297379786253832, "runtime": 0.9689642759039998}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-083"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 515, "makespan": 77, "avg_agents_density": 0.0506438926050416, "runtime": 4.614703868981451}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-084"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 238, "makespan": 29, "avg_agents_density": 0.07262535637069693, "runtime": 1.7606249139644206}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-085"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 250, "makespan": 37, "avg_agents_density": 0.04424647694089083, "runtime": 2.2693622102960944}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-086"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 341, "makespan": 38, "avg_agents_density": 0.061261421275628246, "runtime": 1.577906467486173}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-087"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 298, "makespan": 26, "avg_agents_density": 0.06884485226084072, "runtime": 1.6921647093258798}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-088"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 447, "makespan": 56, "avg_agents_density": 0.05454071752534249, "runtime": 2.2281693783588707}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-089"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 360, "makespan": 52, "avg_agents_density": 0.06502439110545445, "runtime": 3.2176669989712536}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-090"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 277, "makespan": 35, "avg_agents_density": 0.06581012503045941, "runtime": 2.1332584056071937}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-091"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 214, "makespan": 29, "avg_agents_density": 0.052892421522826465, "runtime": 1.1310276491567492}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-092"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 262, "makespan": 32, "avg_agents_density": 0.058116593409925206, "runtime": 2.118308259639889}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-093"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 252, "makespan": 33, "avg_agents_density": 0.0639317690925295, "runtime": 2.0499278120696545}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-094"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 427, "makespan": 42, "avg_agents_density": 0.07785853030742432, "runtime": 2.4269145959988236}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-095"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 281, "makespan": 42, "avg_agents_density": 0.05142115248794909, "runtime": 2.5058312509208918}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-096"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 283, "makespan": 32, "avg_agents_density": 0.056558822621160174, "runtime": 2.138555658981204}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-097"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 354, "makespan": 35, "avg_agents_density": 0.06800468356085897, "runtime": 2.1796798715367913}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-098"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 287, "makespan": 35, "avg_agents_density": 0.06274034173693632, "runtime": 2.1897571510635316}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-099"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 252, "makespan": 28, "avg_agents_density": 0.04419638363105968, "runtime": 1.7187178651802242}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-100"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 202, "makespan": 23, "avg_agents_density": 0.058580057085739656, "runtime": 1.5118867601267993}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-101"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 227, "makespan": 32, "avg_agents_density": 0.0737103876755534, "runtime": 2.019907038193196}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-102"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 263, "makespan": 32, "avg_agents_density": 0.05263707301020172, "runtime": 1.9899814752861857}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-103"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 374, "makespan": 39, "avg_agents_density": 0.05433497309712308, "runtime": 2.4345655562356114}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-104"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 428, "makespan": 49, "avg_agents_density": 0.0621763294812942, "runtime": 3.155275891069323}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-105"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 242, "makespan": 25, "avg_agents_density": 0.049561894271752734, "runtime": 1.5918627982027829}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-106"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 261, "makespan": 26, "avg_agents_density": 0.06656631123295252, "runtime": 1.711967084556818}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-107"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 228, "makespan": 28, "avg_agents_density": 0.0735353810965765, "runtime": 1.779113142285496}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-108"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 228, "makespan": 27, "avg_agents_density": 0.05327682466792761, "runtime": 1.7826525471173227}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-109"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 269, "makespan": 31, "avg_agents_density": 0.05406327103895919, "runtime": 1.9829098503105342}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-110"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 270, "makespan": 42, "avg_agents_density": 0.06922412636603008, "runtime": 2.6361382016912103}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-111"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 272, "makespan": 36, "avg_agents_density": 0.06040527488286763, "runtime": 2.1646980862133205}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-112"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 243, "makespan": 25, "avg_agents_density": 0.06268123248387586, "runtime": 1.6081206831149757}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-113"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 217, "makespan": 26, "avg_agents_density": 0.06786595648361346, "runtime": 1.687652944587171}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-114"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 299, "makespan": 29, "avg_agents_density": 0.05701816125939355, "runtime": 1.8568708430975676}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-115"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 291, "makespan": 33, "avg_agents_density": 0.06243985701967041, "runtime": 2.005522014107555}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-116"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 240, "makespan": 29, "avg_agents_density": 0.06699911364524776, "runtime": 1.7828502710908651}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-117"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 339, "makespan": 41, "avg_agents_density": 0.06571959137262857, "runtime": 2.788506653159857}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-118"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 243, "makespan": 28, "avg_agents_density": 0.06147085017312883, "runtime": 1.829104951582849}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-119"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 213, "makespan": 37, "avg_agents_density": 0.05198194048941344, "runtime": 2.1430666060186923}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-120"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 305, "makespan": 36, "avg_agents_density": 0.052256586832543854, "runtime": 2.243205481674522}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-121"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 311, "makespan": 37, "avg_agents_density": 0.04687445396463595, "runtime": 2.4430016139522195}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-122"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 262, "makespan": 30, "avg_agents_density": 0.0575011782644841, "runtime": 1.9907587594352663}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-123"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 299, "makespan": 35, "avg_agents_density": 0.05674180436207453, "runtime": 2.07507630251348}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-124"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 277, "makespan": 37, "avg_agents_density": 0.04674816448417871, "runtime": 2.24661833839491}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-125"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 365, "makespan": 34, "avg_agents_density": 0.07660675998990465, "runtime": 2.246942257974297}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-126"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 223, "makespan": 23, "avg_agents_density": 0.06002277834875045, "runtime": 1.3949428582563996}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-127"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 397, "makespan": 33, "avg_agents_density": 0.06643915606736324, "runtime": 3.2838252182118595}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-000"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 494, "makespan": 39, "avg_agents_density": 0.09132445786251467, "runtime": 3.488235466182232}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-001"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 321, "makespan": 33, "avg_agents_density": 0.07666402226270441, "runtime": 2.9832381661981344}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-002"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 378, "makespan": 29, "avg_agents_density": 0.06897562245165452, "runtime": 3.014542466029525}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-003"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 359, "makespan": 34, "avg_agents_density": 0.059760351054009356, "runtime": 3.3052777014672756}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-004"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 429, "makespan": 30, "avg_agents_density": 0.07708255113356707, "runtime": 2.9334526103921235}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-005"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 327, "makespan": 25, "avg_agents_density": 0.07476028816450872, "runtime": 2.5670183463953435}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-006"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 469, "makespan": 56, "avg_agents_density": 0.0809066936640255, "runtime": 5.44337806943804}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-007"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 685, "makespan": 44, "avg_agents_density": 0.09562015794616968, "runtime": 4.307177231647074}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-008"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 382, "makespan": 32, "avg_agents_density": 0.07629400231220265, "runtime": 2.9750991538167}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-009"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 439, "makespan": 37, "avg_agents_density": 0.06938296677609011, "runtime": 3.510855281725526}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-010"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 344, "makespan": 26, "avg_agents_density": 0.12650564219393043, "runtime": 2.4651064230129123}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-011"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 664, "makespan": 43, "avg_agents_density": 0.10336113214893071, "runtime": 4.389001184143126}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-012"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 539, "makespan": 39, "avg_agents_density": 0.08081946521193659, "runtime": 3.783808335196227}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-013"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 424, "makespan": 27, "avg_agents_density": 0.09829820113053582, "runtime": 2.556588837876916}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-014"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 617, "makespan": 46, "avg_agents_density": 0.08422292004121673, "runtime": 4.093513722997159}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-015"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 296, "makespan": 28, "avg_agents_density": 0.07643320032886018, "runtime": 2.748254037462175}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-016"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 410, "makespan": 28, "avg_agents_density": 0.07130429211790569, "runtime": 2.6840811371803284}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-017"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 395, "makespan": 32, "avg_agents_density": 0.06742019147717751, "runtime": 3.046394255477935}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-018"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 603, "makespan": 53, "avg_agents_density": 0.10747666084574709, "runtime": 4.949382534250617}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-019"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 392, "makespan": 34, "avg_agents_density": 0.07805851843137417, "runtime": 3.2124727107584476}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-020"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 461, "makespan": 39, "avg_agents_density": 0.08422362598137503, "runtime": 3.3948917808011174}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-021"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 398, "makespan": 33, "avg_agents_density": 0.07829669813133162, "runtime": 3.009850767441094}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-022"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 365, "makespan": 29, "avg_agents_density": 0.09734868596937667, "runtime": 2.6626117331907153}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-023"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 427, "makespan": 29, "avg_agents_density": 0.07555177670389761, "runtime": 2.582022051792592}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-024"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 365, "makespan": 34, "avg_agents_density": 0.08302766538277678, "runtime": 2.953531787265092}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-025"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 374, "makespan": 36, "avg_agents_density": 0.06244985919449599, "runtime": 3.3662066077813506}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-026"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 428, "makespan": 26, "avg_agents_density": 0.09458484546265584, "runtime": 2.3838640078902245}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-027"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 512, "makespan": 42, "avg_agents_density": 0.06875474252265623, "runtime": 3.846518656704575}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-028"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 409, "makespan": 29, "avg_agents_density": 0.07560923761647596, "runtime": 3.0539025752805173}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-029"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 402, "makespan": 34, "avg_agents_density": 0.07808586226747685, "runtime": 3.32425993680954}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-030"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 398, "makespan": 29, "avg_agents_density": 0.07469294230245131, "runtime": 2.8058759826235473}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-031"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 378, "makespan": 34, "avg_agents_density": 0.0742063975895555, "runtime": 3.2903679222799838}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-032"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 443, "makespan": 41, "avg_agents_density": 0.07318659260625109, "runtime": 3.8110098969191313}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-033"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 502, "makespan": 40, "avg_agents_density": 0.09909880358651092, "runtime": 4.042605297639966}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-034"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 350, "makespan": 23, "avg_agents_density": 0.09109795250778856, "runtime": 2.2820621682330966}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-035"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 452, "makespan": 32, "avg_agents_density": 0.10200024582768111, "runtime": 3.044247525278479}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-036"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 439, "makespan": 40, "avg_agents_density": 0.07190370282208687, "runtime": 3.8066724687814713}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-037"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 380, "makespan": 31, "avg_agents_density": 0.07418997940878497, "runtime": 3.032494117040187}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-038"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 386, "makespan": 27, "avg_agents_density": 0.06702006644546035, "runtime": 2.8556924960576}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-039"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 391, "makespan": 27, "avg_agents_density": 0.08490200975506981, "runtime": 2.773492945358157}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-040"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 543, "makespan": 46, "avg_agents_density": 0.07065878611744628, "runtime": 4.645035093650222}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-041"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 421, "makespan": 33, "avg_agents_density": 0.07966106347753212, "runtime": 3.377958551980555}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-042"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 341, "makespan": 23, "avg_agents_density": 0.07507539506812728, "runtime": 2.1814455525018275}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-043"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 343, "makespan": 28, "avg_agents_density": 0.08231414701321499, "runtime": 3.0374087537638843}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-044"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 366, "makespan": 33, "avg_agents_density": 0.07249342855668298, "runtime": 3.184378437232226}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-045"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 408, "makespan": 32, "avg_agents_density": 0.06349062063372982, "runtime": 3.019900913350284}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-046"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 537, "makespan": 50, "avg_agents_density": 0.10472565949676127, "runtime": 4.369281601160765}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-047"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 446, "makespan": 34, "avg_agents_density": 0.0879964318673551, "runtime": 3.236264139879495}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-048"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 485, "makespan": 33, "avg_agents_density": 0.09619519277702247, "runtime": 3.2081578774377704}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-049"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 433, "makespan": 42, "avg_agents_density": 0.07109670112685476, "runtime": 3.6311656939797103}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-050"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 400, "makespan": 32, "avg_agents_density": 0.07683069533334624, "runtime": 3.1726672258228064}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-051"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 451, "makespan": 31, "avg_agents_density": 0.07085649570220745, "runtime": 3.248441883828491}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-052"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 485, "makespan": 29, "avg_agents_density": 0.1100587586233826, "runtime": 2.8579029315151274}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-053"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 453, "makespan": 32, "avg_agents_density": 0.08502512011128742, "runtime": 3.1300685205496848}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-054"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 652, "makespan": 82, "avg_agents_density": 0.06616809811410194, "runtime": 7.781640948727727}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-055"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 375, "makespan": 35, "avg_agents_density": 0.06955324366878252, "runtime": 3.2555105155333877}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-056"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 430, "makespan": 48, "avg_agents_density": 0.08598785410800318, "runtime": 4.421012806240469}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-057"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 464, "makespan": 35, "avg_agents_density": 0.09367231894198048, "runtime": 3.356850799638778}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-058"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 505, "makespan": 39, "avg_agents_density": 0.09474609230278051, "runtime": 3.780710000079125}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-059"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 369, "makespan": 33, "avg_agents_density": 0.08388877785319851, "runtime": 3.063405792694539}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-060"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 372, "makespan": 31, "avg_agents_density": 0.08750854220564011, "runtime": 2.8787765810266137}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-061"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 626, "makespan": 41, "avg_agents_density": 0.07210401920793112, "runtime": 3.7359140496701}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-062"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 665, "makespan": 40, "avg_agents_density": 0.08855464698886854, "runtime": 3.757582249585539}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-063"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 364, "makespan": 27, "avg_agents_density": 0.08434684780093853, "runtime": 2.6035017729736865}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-064"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 445, "makespan": 41, "avg_agents_density": 0.08539877999571584, "runtime": 3.7044182238169014}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-065"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 474, "makespan": 37, "avg_agents_density": 0.06397710547667602, "runtime": 3.610147485509515}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-066"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 359, "makespan": 30, "avg_agents_density": 0.06888333245131305, "runtime": 2.908707001246512}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-067"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 721, "makespan": 59, "avg_agents_density": 0.08482023404229885, "runtime": 5.278112268541008}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-068"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 677, "makespan": 48, "avg_agents_density": 0.11553153368365243, "runtime": 4.480355133768171}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-069"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 504, "makespan": 38, "avg_agents_density": 0.0894691393946396, "runtime": 3.6840173439122736}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-070"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 375, "makespan": 44, "avg_agents_density": 0.06953502727682173, "runtime": 4.120653542689979}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-071"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 358, "makespan": 27, "avg_agents_density": 0.056665954156826175, "runtime": 2.709240682888776}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-072"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 412, "makespan": 28, "avg_agents_density": 0.06804020493014706, "runtime": 2.595500012859702}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-073"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 483, "makespan": 34, "avg_agents_density": 0.08668384494470642, "runtime": 3.0840240474790335}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-074"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 457, "makespan": 41, "avg_agents_density": 0.07687973281475725, "runtime": 3.6274213707074523}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-075"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 602, "makespan": 53, "avg_agents_density": 0.0849162980145915, "runtime": 4.715038237161934}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-076"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 397, "makespan": 34, "avg_agents_density": 0.09736960470692485, "runtime": 2.894609314855188}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-077"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 610, "makespan": 50, "avg_agents_density": 0.09847754512346604, "runtime": 4.444383944384754}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-078"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 356, "makespan": 28, "avg_agents_density": 0.08317930148395884, "runtime": 2.5127695365808904}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-079"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 370, "makespan": 27, "avg_agents_density": 0.07738508210267735, "runtime": 2.627295755315572}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-080"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 393, "makespan": 25, "avg_agents_density": 0.09323152204181219, "runtime": 2.3200114257633686}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-081"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 529, "makespan": 44, "avg_agents_density": 0.06983438897660237, "runtime": 3.82644747197628}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-082"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 408, "makespan": 30, "avg_agents_density": 0.08386722357242617, "runtime": 2.9748275629244745}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-083"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 513, "makespan": 50, "avg_agents_density": 0.07037994890563583, "runtime": 4.657526201568544}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-084"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 509, "makespan": 38, "avg_agents_density": 0.0926670135887197, "runtime": 3.522371252067387}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-085"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 363, "makespan": 41, "avg_agents_density": 0.07210153205888818, "runtime": 3.5169264813885093}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-086"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 461, "makespan": 37, "avg_agents_density": 0.08458185695205167, "runtime": 3.2711134706623852}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-087"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 435, "makespan": 29, "avg_agents_density": 0.08974880605351514, "runtime": 2.829335513524711}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-088"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 632, "makespan": 53, "avg_agents_density": 0.07625226038804815, "runtime": 4.793823420070112}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-089"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 567, "makespan": 45, "avg_agents_density": 0.0950724794610783, "runtime": 3.936557346023619}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-090"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 591, "makespan": 61, "avg_agents_density": 0.08501208697940892, "runtime": 5.520743920467794}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-091"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 330, "makespan": 29, "avg_agents_density": 0.07189707323396806, "runtime": 2.767277213279158}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-092"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 456, "makespan": 36, "avg_agents_density": 0.08174614935652419, "runtime": 3.5532765612006187}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-093"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 467, "makespan": 43, "avg_agents_density": 0.0924195676995438, "runtime": 3.7968659861944616}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-094"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 883, "makespan": 58, "avg_agents_density": 0.1141873908300673, "runtime": 5.7204388990066946}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-095"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 496, "makespan": 44, "avg_agents_density": 0.07919617264811868, "runtime": 4.25163884088397}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-096"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 408, "makespan": 34, "avg_agents_density": 0.07985274163308886, "runtime": 3.2522262865677476}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-097"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 576, "makespan": 40, "avg_agents_density": 0.08858848042480566, "runtime": 3.806600411888212}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-098"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 481, "makespan": 38, "avg_agents_density": 0.08361129678990634, "runtime": 3.5700266524218023}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-099"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 406, "makespan": 42, "avg_agents_density": 0.06866700491587156, "runtime": 3.922047905623913}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-100"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 318, "makespan": 22, "avg_agents_density": 0.08094651627427973, "runtime": 2.1745934560894966}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-101"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 446, "makespan": 34, "avg_agents_density": 0.0946473735746041, "runtime": 3.2531336713582277}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-102"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 414, "makespan": 27, "avg_agents_density": 0.07579102041336448, "runtime": 2.7190001672133803}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-103"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 603, "makespan": 48, "avg_agents_density": 0.07452796497766528, "runtime": 4.440869129262865}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-104"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 620, "makespan": 45, "avg_agents_density": 0.08230879801615396, "runtime": 4.361662048380822}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-105"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 404, "makespan": 32, "avg_agents_density": 0.0624053210583347, "runtime": 3.0572597575373948}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-106"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 497, "makespan": 45, "avg_agents_density": 0.09013281320361735, "runtime": 4.10216314252466}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-107"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 426, "makespan": 34, "avg_agents_density": 0.09087838812475606, "runtime": 3.260125787463039}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-108"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 486, "makespan": 34, "avg_agents_density": 0.0860472974635124, "runtime": 3.263580698519945}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-109"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 414, "makespan": 28, "avg_agents_density": 0.07582199202278275, "runtime": 2.707336532883346}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-110"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 334, "makespan": 28, "avg_agents_density": 0.08478641159367026, "runtime": 2.7891737511381507}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-111"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 520, "makespan": 42, "avg_agents_density": 0.09001640398729552, "runtime": 3.8689416898414493}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-112"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 368, "makespan": 28, "avg_agents_density": 0.09521461032181246, "runtime": 2.719445058144629}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-113"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 332, "makespan": 29, "avg_agents_density": 0.10062255639756208, "runtime": 2.8501853295601904}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-114"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 425, "makespan": 26, "avg_agents_density": 0.09244466315466263, "runtime": 2.8023986467160285}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-115"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 511, "makespan": 30, "avg_agents_density": 0.09346779020188042, "runtime": 2.947033972479403}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-116"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 502, "makespan": 37, "avg_agents_density": 0.0864421469189634, "runtime": 3.471806552261114}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-117"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 535, "makespan": 42, "avg_agents_density": 0.09130512009239054, "runtime": 4.1043321317993104}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-118"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 444, "makespan": 40, "avg_agents_density": 0.0813996917160584, "runtime": 3.7778732706792653}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-119"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 371, "makespan": 34, "avg_agents_density": 0.06953439769129863, "runtime": 3.046392375603318}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-120"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 472, "makespan": 35, "avg_agents_density": 0.079148531565154, "runtime": 3.450123520568013}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-121"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 530, "makespan": 49, "avg_agents_density": 0.06461822610440499, "runtime": 4.642001550644636}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-122"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 393, "makespan": 33, "avg_agents_density": 0.08448347814831234, "runtime": 3.1252611596137285}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-123"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 486, "makespan": 39, "avg_agents_density": 0.08127126696025647, "runtime": 3.420178330503404}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-124"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 466, "makespan": 36, "avg_agents_density": 0.0828423406687134, "runtime": 3.4906144496053457}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-125"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 515, "makespan": 40, "avg_agents_density": 0.10066176077956372, "runtime": 3.7505347039550543}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-126"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 402, "makespan": 33, "avg_agents_density": 0.08323782854220488, "runtime": 3.1584670040756464}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-127"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 514, "makespan": 32, "avg_agents_density": 0.08986634936173409, "runtime": 4.444495088420808}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-000"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 823, "makespan": 49, "avg_agents_density": 0.12480022752556628, "runtime": 6.3809274062514305}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-001"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 528, "makespan": 41, "avg_agents_density": 0.09272914028367293, "runtime": 5.0745864398777485}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-002"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 540, "makespan": 33, "avg_agents_density": 0.09278168481135678, "runtime": 4.105464905966073}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-003"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 485, "makespan": 34, "avg_agents_density": 0.08172175810579496, "runtime": 4.1861677947454154}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-004"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 682, "makespan": 39, "avg_agents_density": 0.10195419674041939, "runtime": 5.124368604272604}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-005"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 592, "makespan": 34, "avg_agents_density": 0.09592215169983534, "runtime": 4.312268874142319}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-006"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 684, "makespan": 48, "avg_agents_density": 0.10018754985840797, "runtime": 6.075699867680669}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-007"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 1211, "makespan": 93, "avg_agents_density": 0.10874047583406941, "runtime": 11.342856834176928}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-008"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 528, "makespan": 37, "avg_agents_density": 0.09262583605034205, "runtime": 4.513593730982393}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-009"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 661, "makespan": 37, "avg_agents_density": 0.10247307386931398, "runtime": 4.728992462623864}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-010"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 632, "makespan": 37, "avg_agents_density": 0.15123255135304844, "runtime": 4.7857445534318686}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-011"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 98, "SoC": 1627, "makespan": 99, "avg_agents_density": 0.14055801653186228, "runtime": 12.238759304396808}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-012"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 780, "makespan": 46, "avg_agents_density": 0.10278551793833679, "runtime": 6.345523642376065}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-013"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 551, "makespan": 29, "avg_agents_density": 0.11987091915308594, "runtime": 3.6781998579390347}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-014"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 821, "makespan": 41, "avg_agents_density": 0.11085811927429588, "runtime": 5.400855953805149}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-015"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 474, "makespan": 29, "avg_agents_density": 0.10438531840913963, "runtime": 3.663538981694728}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-016"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 636, "makespan": 36, "avg_agents_density": 0.08623304551294131, "runtime": 4.364774995017797}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-017"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 681, "makespan": 40, "avg_agents_density": 0.09064992355615069, "runtime": 4.842470444273204}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-018"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1047, "makespan": 64, "avg_agents_density": 0.12498739119221654, "runtime": 7.714630813803524}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-019"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 589, "makespan": 36, "avg_agents_density": 0.10294316082652712, "runtime": 4.412897527217865}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-020"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 784, "makespan": 39, "avg_agents_density": 0.10281518219412203, "runtime": 4.796447045635432}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-021"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 605, "makespan": 37, "avg_agents_density": 0.09889719267175649, "runtime": 4.528394426219165}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-022"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 644, "makespan": 54, "avg_agents_density": 0.11744286154048658, "runtime": 6.5600559171289206}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-023"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 666, "makespan": 34, "avg_agents_density": 0.1129201271214532, "runtime": 4.4385360246524215}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-024"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 554, "makespan": 35, "avg_agents_density": 0.1003244146333673, "runtime": 4.159316397737712}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-025"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 457, "makespan": 33, "avg_agents_density": 0.08187654253705322, "runtime": 4.3236336866393685}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-026"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 484, "makespan": 30, "avg_agents_density": 0.11215430831036598, "runtime": 3.8787886407226324}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-027"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 800, "makespan": 40, "avg_agents_density": 0.10312941316238901, "runtime": 5.218322208616883}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-028"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 609, "makespan": 32, "avg_agents_density": 0.10180675204472613, "runtime": 4.21617473103106}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-029"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 613, "makespan": 32, "avg_agents_density": 0.10140498118700492, "runtime": 4.073552428279072}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-030"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 542, "makespan": 29, "avg_agents_density": 0.10156115119125625, "runtime": 4.33919428056106}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-031"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 569, "makespan": 42, "avg_agents_density": 0.09783391848355148, "runtime": 5.830065916292369}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-032"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 688, "makespan": 46, "avg_agents_density": 0.09947186925946144, "runtime": 6.275718765333295}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-033"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1119, "makespan": 65, "avg_agents_density": 0.1433929038403871, "runtime": 8.157648884225637}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-034"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 600, "makespan": 30, "avg_agents_density": 0.1218985264426692, "runtime": 4.003808546345681}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-035"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 843, "makespan": 46, "avg_agents_density": 0.1381077907534615, "runtime": 5.742421329487115}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-036"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 699, "makespan": 56, "avg_agents_density": 0.09628852790555915, "runtime": 6.996467398479581}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-037"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 525, "makespan": 31, "avg_agents_density": 0.09492005340175455, "runtime": 4.433037707116455}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-038"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 525, "makespan": 31, "avg_agents_density": 0.08369121086394041, "runtime": 3.628200516104698}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-039"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 641, "makespan": 37, "avg_agents_density": 0.10463462967403148, "runtime": 4.713174738921225}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-040"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 831, "makespan": 43, "avg_agents_density": 0.09876187483272227, "runtime": 5.616314240265638}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-041"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 661, "makespan": 36, "avg_agents_density": 0.10522350101537989, "runtime": 5.4401306794025}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-042"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 470, "makespan": 32, "avg_agents_density": 0.09771812028487181, "runtime": 4.645120181143284}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-043"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 616, "makespan": 37, "avg_agents_density": 0.1027036856356991, "runtime": 4.788400658406317}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-044"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 517, "makespan": 30, "avg_agents_density": 0.09122677389718623, "runtime": 3.8081472562626004}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-045"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 453, "makespan": 29, "avg_agents_density": 0.08894926035136892, "runtime": 3.7224622732028365}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-046"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 682, "makespan": 42, "avg_agents_density": 0.12892174477488857, "runtime": 5.121890258044004}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-047"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 600, "makespan": 37, "avg_agents_density": 0.11973155661752269, "runtime": 4.547540285158902}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-048"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 694, "makespan": 33, "avg_agents_density": 0.13036228456874918, "runtime": 4.491604743525386}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-049"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 658, "makespan": 44, "avg_agents_density": 0.09371053871804952, "runtime": 5.725565894972533}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-050"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 571, "makespan": 30, "avg_agents_density": 0.09656509696091639, "runtime": 3.844555476680398}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-051"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 634, "makespan": 42, "avg_agents_density": 0.09347267969033285, "runtime": 5.515211206395179}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-052"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 619, "makespan": 30, "avg_agents_density": 0.13394240852536815, "runtime": 3.9392565763555467}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-053"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 802, "makespan": 53, "avg_agents_density": 0.10131395916472634, "runtime": 7.234342931304127}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-054"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 865, "makespan": 51, "avg_agents_density": 0.08883850025951193, "runtime": 6.6316891219466925}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-055"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 460, "makespan": 27, "avg_agents_density": 0.09629840580848104, "runtime": 3.3915052744559944}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-056"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 584, "makespan": 34, "avg_agents_density": 0.11575483826704457, "runtime": 4.130203728564084}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-057"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 758, "makespan": 51, "avg_agents_density": 0.12440893927572946, "runtime": 6.171614966355264}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-058"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 653, "makespan": 35, "avg_agents_density": 0.1110875610861339, "runtime": 4.428308926522732}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-059"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 571, "makespan": 31, "avg_agents_density": 0.11991706460952306, "runtime": 4.000817721709609}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-060"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 608, "makespan": 37, "avg_agents_density": 0.12541879199669143, "runtime": 5.551672118715942}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-061"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 838, "makespan": 53, "avg_agents_density": 0.0838371049717696, "runtime": 6.163920337334275}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-062"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 954, "makespan": 50, "avg_agents_density": 0.10788672603747522, "runtime": 6.116903675720096}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-063"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 597, "makespan": 35, "avg_agents_density": 0.10127458067656399, "runtime": 4.420404770411551}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-064"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 690, "makespan": 42, "avg_agents_density": 0.11622888094671856, "runtime": 5.236627801787108}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-065"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 609, "makespan": 37, "avg_agents_density": 0.08966789855862164, "runtime": 4.684937761630863}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-066"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 502, "makespan": 29, "avg_agents_density": 0.0926053636017238, "runtime": 3.847993179690093}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-067"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1109, "makespan": 57, "avg_agents_density": 0.1081086803817989, "runtime": 7.544168189633638}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-068"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1048, "makespan": 48, "avg_agents_density": 0.16218198494738958, "runtime": 6.2524257162585855}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-069"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 706, "makespan": 41, "avg_agents_density": 0.10785703202302409, "runtime": 5.160644871648401}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-070"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 673, "makespan": 48, "avg_agents_density": 0.09761375566201035, "runtime": 5.87671036273241}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-071"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 486, "makespan": 28, "avg_agents_density": 0.06946111919930197, "runtime": 3.541201200336218}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-072"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 521, "makespan": 30, "avg_agents_density": 0.08606369459352552, "runtime": 3.728676695842296}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-073"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 616, "makespan": 37, "avg_agents_density": 0.10428323747377029, "runtime": 4.921912865713239}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-074"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 582, "makespan": 40, "avg_agents_density": 0.10123881470244915, "runtime": 4.523714991286397}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-075"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 913, "makespan": 50, "avg_agents_density": 0.10274823565511024, "runtime": 6.073410737328231}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-076"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 607, "makespan": 41, "avg_agents_density": 0.11766840073759835, "runtime": 5.202427485957742}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-077"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 801, "makespan": 49, "avg_agents_density": 0.11610399328340171, "runtime": 6.066397658083588}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-078"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 484, "makespan": 32, "avg_agents_density": 0.09692376937640766, "runtime": 4.03270047949627}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-079"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 518, "makespan": 27, "avg_agents_density": 0.10564341955869808, "runtime": 3.445644684135914}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-080"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 558, "makespan": 28, "avg_agents_density": 0.11011116320598156, "runtime": 3.6421491587534547}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-081"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 721, "makespan": 41, "avg_agents_density": 0.0932464999854155, "runtime": 5.343060281127691}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-082"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 538, "makespan": 31, "avg_agents_density": 0.09118495671444515, "runtime": 3.935907042119652}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-083"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 863, "makespan": 55, "avg_agents_density": 0.10330495925825825, "runtime": 6.782902148552239}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-084"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 641, "makespan": 38, "avg_agents_density": 0.11444570185697292, "runtime": 4.813861191738397}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-085"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 498, "makespan": 39, "avg_agents_density": 0.08503302412967931, "runtime": 4.63260038010776}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-086"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 691, "makespan": 35, "avg_agents_density": 0.11461272321946304, "runtime": 4.026733445934951}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-087"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 573, "makespan": 34, "avg_agents_density": 0.1151849785989778, "runtime": 4.246408144943416}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-088"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 982, "makespan": 60, "avg_agents_density": 0.10742904402522163, "runtime": 7.4768579406663775}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-089"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 898, "makespan": 54, "avg_agents_density": 0.11611473612916803, "runtime": 6.715428730472922}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-090"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 112, "SoC": 1938, "makespan": 113, "avg_agents_density": 0.14185984086560174, "runtime": 12.34121964033693}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-091"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 476, "makespan": 35, "avg_agents_density": 0.08878477181232883, "runtime": 4.254469248466194}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-092"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 751, "makespan": 46, "avg_agents_density": 0.10503068337648787, "runtime": 5.797544464003295}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-093"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 90, "SoC": 1207, "makespan": 91, "avg_agents_density": 0.12966363638148454, "runtime": 11.494468440301716}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-094"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1414, "makespan": 66, "avg_agents_density": 0.13103909578253597, "runtime": 8.123293271753937}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-095"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 752, "makespan": 47, "avg_agents_density": 0.10100690685755565, "runtime": 6.215638794470578}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-096"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 579, "makespan": 35, "avg_agents_density": 0.10195404244016186, "runtime": 4.404636160004884}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-097"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 950, "makespan": 62, "avg_agents_density": 0.12125224640883295, "runtime": 7.826579648070037}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-098"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 640, "makespan": 39, "avg_agents_density": 0.11498671786654198, "runtime": 4.675084162503481}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-099"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 602, "makespan": 34, "avg_agents_density": 0.10146583259788328, "runtime": 4.058430332690477}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-100"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 558, "makespan": 33, "avg_agents_density": 0.10308337852838746, "runtime": 4.331986938137561}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-101"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 805, "makespan": 42, "avg_agents_density": 0.1189613623352498, "runtime": 5.497506174724549}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-102"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 577, "makespan": 31, "avg_agents_density": 0.10711447271113929, "runtime": 4.1438172473572195}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-103"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 810, "makespan": 62, "avg_agents_density": 0.08717160773330729, "runtime": 7.590733249206096}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-104"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1065, "makespan": 61, "avg_agents_density": 0.11109086232528129, "runtime": 7.833498167805374}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-105"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 600, "makespan": 38, "avg_agents_density": 0.08216880206635976, "runtime": 5.003385778516531}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-106"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 567, "makespan": 29, "avg_agents_density": 0.1171261637573079, "runtime": 3.721577438991517}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-107"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 607, "makespan": 33, "avg_agents_density": 0.11612154583369369, "runtime": 4.279548557475209}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-108"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 600, "makespan": 36, "avg_agents_density": 0.10460420945180156, "runtime": 4.474220270756632}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-109"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 609, "makespan": 30, "avg_agents_density": 0.09221709428833662, "runtime": 3.7122772755101323}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-110"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 507, "makespan": 31, "avg_agents_density": 0.10415412735303528, "runtime": 4.144561359658837}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-111"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 828, "makespan": 43, "avg_agents_density": 0.13174399159770658, "runtime": 5.578756541013718}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-112"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 599, "makespan": 33, "avg_agents_density": 0.11643517225059616, "runtime": 4.175374530721456}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-113"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 500, "makespan": 26, "avg_agents_density": 0.12091400824913803, "runtime": 3.233754353132099}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-114"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 769, "makespan": 40, "avg_agents_density": 0.1202859467309646, "runtime": 5.119597180746496}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-115"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 699, "makespan": 34, "avg_agents_density": 0.11483784005031387, "runtime": 4.436816005036235}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-116"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 659, "makespan": 45, "avg_agents_density": 0.10630990792847853, "runtime": 5.7320976057089865}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-117"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 666, "makespan": 38, "avg_agents_density": 0.10806738088633136, "runtime": 4.772774374578148}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-118"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 801, "makespan": 47, "avg_agents_density": 0.10597130083718505, "runtime": 6.131189724430442}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-119"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 528, "makespan": 35, "avg_agents_density": 0.09216049205285795, "runtime": 4.372936363797635}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-120"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 596, "makespan": 41, "avg_agents_density": 0.10011428638244461, "runtime": 5.1452654409222305}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-121"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 722, "makespan": 42, "avg_agents_density": 0.07811682714797585, "runtime": 4.915576708037406}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-122"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 614, "makespan": 42, "avg_agents_density": 0.10006955382791248, "runtime": 5.1145013542845845}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-123"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 674, "makespan": 43, "avg_agents_density": 0.11098328925860299, "runtime": 5.446817679330707}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-124"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 568, "makespan": 38, "avg_agents_density": 0.09317968168581699, "runtime": 4.767332257702947}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-125"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 925, "makespan": 52, "avg_agents_density": 0.1407832496731626, "runtime": 6.466594073455781}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-126"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 639, "makespan": 38, "avg_agents_density": 0.11026914494910404, "runtime": 4.701658026780933}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-127"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 976, "makespan": 34, "avg_agents_density": 0.12851197032286313, "runtime": 6.884256175719202}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-000"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 2266, "makespan": 90, "avg_agents_density": 0.1793735148796744, "runtime": 16.740282967220992}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-001"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1183, "makespan": 48, "avg_agents_density": 0.15283428397409937, "runtime": 9.100357755552977}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-002"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 935, "makespan": 38, "avg_agents_density": 0.13991772514024234, "runtime": 7.468554352410138}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-003"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 927, "makespan": 40, "avg_agents_density": 0.12211696932473175, "runtime": 7.732526706531644}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-004"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1359, "makespan": 51, "avg_agents_density": 0.14655610751316367, "runtime": 9.514390444848686}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-005"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 922, "makespan": 35, "avg_agents_density": 0.1395848176851968, "runtime": 7.11981520941481}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-006"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1229, "makespan": 50, "avg_agents_density": 0.153471452673297, "runtime": 9.854069202207029}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-007"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 98, "SoC": 2543, "makespan": 99, "avg_agents_density": 0.1825736574593662, "runtime": 18.655603010673076}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-008"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 781, "makespan": 39, "avg_agents_density": 0.12690422754728306, "runtime": 7.593174288980663}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-009"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 1229, "makespan": 88, "avg_agents_density": 0.11979546184799347, "runtime": 16.165605598129332}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-010"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 114, "SoC": 1368, "makespan": 115, "avg_agents_density": 0.19903525524227922, "runtime": 21.397447439841926}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-011"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 2021, "makespan": 77, "avg_agents_density": 0.1857691212447649, "runtime": 14.5407708841376}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-012"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1423, "makespan": 68, "avg_agents_density": 0.12750886406064718, "runtime": 13.35554180527106}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-013"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 968, "makespan": 35, "avg_agents_density": 0.15867672337264144, "runtime": 6.6290285577997565}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-014"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 108, "SoC": 3210, "makespan": 109, "avg_agents_density": 0.19746615008700516, "runtime": 21.267308638431132}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-015"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 898, "makespan": 38, "avg_agents_density": 0.15413853952607232, "runtime": 7.048682383261621}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-016"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 1026, "makespan": 36, "avg_agents_density": 0.1215183333355065, "runtime": 7.09054166264832}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-017"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1532, "makespan": 65, "avg_agents_density": 0.1440547342097881, "runtime": 12.56987670250237}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-018"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 2416, "makespan": 90, "avg_agents_density": 0.1653713337937417, "runtime": 17.284308902919292}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-019"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1160, "makespan": 47, "avg_agents_density": 0.14556294144057502, "runtime": 9.213429991155863}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-020"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1260, "makespan": 52, "avg_agents_density": 0.15417440783525013, "runtime": 9.633437141310424}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-021"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1008, "makespan": 45, "avg_agents_density": 0.15834122429601144, "runtime": 8.456168722361326}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-022"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 1091, "makespan": 34, "avg_agents_density": 0.17118299295242365, "runtime": 6.694568941835314}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-023"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1155, "makespan": 40, "avg_agents_density": 0.1378190337777507, "runtime": 7.823590155225247}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-024"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1218, "makespan": 62, "avg_agents_density": 0.15149311744281052, "runtime": 11.05195732647553}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-025"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 942, "makespan": 38, "avg_agents_density": 0.12773418969702227, "runtime": 7.292272850871086}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-026"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 1003, "makespan": 38, "avg_agents_density": 0.15502673623203583, "runtime": 7.503500813618302}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-027"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1440, "makespan": 53, "avg_agents_density": 0.13614867006562978, "runtime": 10.363502854947}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-028"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 1054, "makespan": 33, "avg_agents_density": 0.15487201588682328, "runtime": 6.697211482562125}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-029"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 989, "makespan": 38, "avg_agents_density": 0.15421596546216212, "runtime": 7.100092659704387}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-030"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1009, "makespan": 39, "avg_agents_density": 0.13309101188210443, "runtime": 7.464435721747577}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-031"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1182, "makespan": 54, "avg_agents_density": 0.15744231796378919, "runtime": 10.455843607429415}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-032"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1255, "makespan": 46, "avg_agents_density": 0.13887929842171393, "runtime": 9.867222545202821}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-033"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 2480, "makespan": 93, "avg_agents_density": 0.20176951454788497, "runtime": 18.82108798669651}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-034"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1554, "makespan": 66, "avg_agents_density": 0.18582073772777657, "runtime": 12.314222835469991}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-035"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1263, "makespan": 49, "avg_agents_density": 0.1869199995744615, "runtime": 9.380641173105687}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-036"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 1677, "makespan": 74, "avg_agents_density": 0.1547030499953354, "runtime": 14.331106425728649}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-037"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1122, "makespan": 40, "avg_agents_density": 0.1437247743561972, "runtime": 7.784764975309372}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-038"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1100, "makespan": 41, "avg_agents_density": 0.129856558041103, "runtime": 7.965429544914514}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-039"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1415, "makespan": 48, "avg_agents_density": 0.15981465609986364, "runtime": 10.09732090914622}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-040"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1640, "makespan": 63, "avg_agents_density": 0.1484300762228022, "runtime": 13.159574499353766}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-041"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1520, "makespan": 68, "avg_agents_density": 0.15525452516930344, "runtime": 13.14127075765282}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-042"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 890, "makespan": 33, "avg_agents_density": 0.13758454278580637, "runtime": 6.280227342154831}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-043"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1070, "makespan": 41, "avg_agents_density": 0.14819960611622912, "runtime": 8.402611919213086}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-044"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1030, "makespan": 44, "avg_agents_density": 0.13627877619254988, "runtime": 9.249634382780641}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-045"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1004, "makespan": 47, "avg_agents_density": 0.12224316905936698, "runtime": 9.286007208749652}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-046"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 123, "SoC": 3183, "makespan": 124, "avg_agents_density": 0.19782730573895174, "runtime": 23.646843940019608}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-047"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1349, "makespan": 56, "avg_agents_density": 0.17311910334791822, "runtime": 11.004765566904098}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-048"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1412, "makespan": 47, "avg_agents_density": 0.17715202636198957, "runtime": 9.729390242602676}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-049"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1500, "makespan": 62, "avg_agents_density": 0.1541795049477852, "runtime": 11.704613549634814}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-050"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 1038, "makespan": 36, "avg_agents_density": 0.14410076748226067, "runtime": 7.09483298799023}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-051"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1367, "makespan": 48, "avg_agents_density": 0.14317947418200183, "runtime": 9.152624026406556}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-052"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1151, "makespan": 43, "avg_agents_density": 0.17633629180757635, "runtime": 8.55843161046505}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-053"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1284, "makespan": 43, "avg_agents_density": 0.17096532703015635, "runtime": 8.63509237440303}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-054"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 2360, "makespan": 100, "avg_agents_density": 0.14448672281400599, "runtime": 19.230010501109064}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-055"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 921, "makespan": 35, "avg_agents_density": 0.13518752551658653, "runtime": 6.80596634792164}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-056"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1052, "makespan": 40, "avg_agents_density": 0.15790836361304972, "runtime": 7.776327139232308}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-057"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1510, "makespan": 46, "avg_agents_density": 0.20356609622521188, "runtime": 9.22144047357142}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-058"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1218, "makespan": 51, "avg_agents_density": 0.15385291574796026, "runtime": 9.970716356299818}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-059"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 978, "makespan": 36, "avg_agents_density": 0.15847779909730605, "runtime": 7.160206964705139}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-060"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1545, "makespan": 59, "avg_agents_density": 0.19989361283612364, "runtime": 12.08902186807245}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-061"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1605, "makespan": 65, "avg_agents_density": 0.12663934393943455, "runtime": 12.258470345754176}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-062"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1627, "makespan": 49, "avg_agents_density": 0.16659631421455576, "runtime": 9.67323384154588}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-063"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 907, "makespan": 37, "avg_agents_density": 0.14681354779697453, "runtime": 7.2814172566868365}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-064"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1402, "makespan": 60, "avg_agents_density": 0.1740547004314832, "runtime": 11.361098352819681}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-065"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1117, "makespan": 43, "avg_agents_density": 0.13005374380765286, "runtime": 8.299214181490242}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-066"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 825, "makespan": 31, "avg_agents_density": 0.135468801106849, "runtime": 5.59497131081298}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-067"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 2022, "makespan": 70, "avg_agents_density": 0.15566331542984743, "runtime": 14.124264419544488}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-068"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 2234, "makespan": 74, "avg_agents_density": 0.2281651982025991, "runtime": 14.554458073806018}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-069"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 1572, "makespan": 85, "avg_agents_density": 0.15740967885595214, "runtime": 16.46439905371517}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-070"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1462, "makespan": 65, "avg_agents_density": 0.14658213289712954, "runtime": 12.531341915950179}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-071"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 787, "makespan": 33, "avg_agents_density": 0.10468322431578436, "runtime": 6.654938672203571}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-072"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1095, "makespan": 43, "avg_agents_density": 0.13150827624215686, "runtime": 8.707798480056226}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-073"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1139, "makespan": 55, "avg_agents_density": 0.15194127787208175, "runtime": 10.31141649140045}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-074"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 958, "makespan": 45, "avg_agents_density": 0.1457396740842697, "runtime": 8.756546299438924}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-075"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1689, "makespan": 71, "avg_agents_density": 0.14647834735396006, "runtime": 13.407868677284569}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-076"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1226, "makespan": 49, "avg_agents_density": 0.1664993154595381, "runtime": 9.210241044871509}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-077"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1375, "makespan": 62, "avg_agents_density": 0.16503353818972097, "runtime": 12.14220717176795}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-078"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 878, "makespan": 31, "avg_agents_density": 0.15420412739970907, "runtime": 5.242017309181392}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-079"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 931, "makespan": 38, "avg_agents_density": 0.13675358385028583, "runtime": 7.452250711154193}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-080"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 969, "makespan": 39, "avg_agents_density": 0.1509180105191839, "runtime": 7.497396629303694}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-081"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 1796, "makespan": 76, "avg_agents_density": 0.13901173217485754, "runtime": 13.284416939131916}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-082"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1135, "makespan": 51, "avg_agents_density": 0.1355516829121895, "runtime": 9.150896527338773}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-083"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1683, "makespan": 70, "avg_agents_density": 0.1537482526732898, "runtime": 13.286464421544224}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-084"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1623, "makespan": 64, "avg_agents_density": 0.16821481061030666, "runtime": 12.503866489510983}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-085"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 769, "makespan": 37, "avg_agents_density": 0.11365487832930103, "runtime": 5.747205044608563}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-086"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1692, "makespan": 73, "avg_agents_density": 0.16379757788995897, "runtime": 14.35156492330134}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-087"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1243, "makespan": 42, "avg_agents_density": 0.1741609747394222, "runtime": 7.835275819525123}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-088"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1928, "makespan": 72, "avg_agents_density": 0.15951950128794617, "runtime": 13.467807828914374}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-089"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1401, "makespan": 67, "avg_agents_density": 0.1653045423727896, "runtime": 11.177503048907965}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-090"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 112, "SoC": 3231, "makespan": 113, "avg_agents_density": 0.2080265678120133, "runtime": 21.713521786034107}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-091"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 995, "makespan": 40, "avg_agents_density": 0.1380863403798847, "runtime": 7.881478050723672}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-092"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1249, "makespan": 44, "avg_agents_density": 0.13839263937290516, "runtime": 7.189324577804655}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-093"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 105, "SoC": 3247, "makespan": 106, "avg_agents_density": 0.20931509869300974, "runtime": 20.554090259596705}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-094"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 3990, "makespan": 128, "avg_agents_density": 0.23744449914985238, "runtime": 24.644414573907852}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-095"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1367, "makespan": 48, "avg_agents_density": 0.14420521211158435, "runtime": 9.300306437071413}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-096"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1048, "makespan": 46, "avg_agents_density": 0.14728645982048036, "runtime": 8.927374200895429}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-097"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 2001, "makespan": 87, "avg_agents_density": 0.16744592964653185, "runtime": 16.663478227332234}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-098"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1121, "makespan": 43, "avg_agents_density": 0.16019971091315496, "runtime": 8.359497061930597}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-099"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 1186, "makespan": 38, "avg_agents_density": 0.14313430672642843, "runtime": 7.257194502744824}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-100"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 996, "makespan": 34, "avg_agents_density": 0.14748192222198397, "runtime": 6.919758753851056}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-101"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1428, "makespan": 56, "avg_agents_density": 0.16822392947329287, "runtime": 10.236929327715188}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-102"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 961, "makespan": 36, "avg_agents_density": 0.14772794202882944, "runtime": 6.761890187393874}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-103"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1382, "makespan": 47, "avg_agents_density": 0.13028199485240713, "runtime": 9.300232907291502}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-104"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2272, "makespan": 86, "avg_agents_density": 0.18420887134612618, "runtime": 16.875194128602743}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-105"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 979, "makespan": 36, "avg_agents_density": 0.12464131982979089, "runtime": 6.980449291877449}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-106"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1229, "makespan": 68, "avg_agents_density": 0.15980420448381763, "runtime": 11.811754212714732}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-107"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1052, "makespan": 45, "avg_agents_density": 0.16450171847708184, "runtime": 8.894809435587376}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-108"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 1919, "makespan": 80, "avg_agents_density": 0.1534876635890665, "runtime": 15.158033699262887}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-109"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1051, "makespan": 44, "avg_agents_density": 0.1342981800562029, "runtime": 8.259608136489987}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-110"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1073, "makespan": 46, "avg_agents_density": 0.1599851917671623, "runtime": 8.487031084485352}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-111"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1530, "makespan": 62, "avg_agents_density": 0.184701539825322, "runtime": 11.761525394394994}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-112"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 995, "makespan": 40, "avg_agents_density": 0.16663175329710658, "runtime": 7.688541798386723}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-113"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 881, "makespan": 34, "avg_agents_density": 0.15171598123114072, "runtime": 6.726505106315017}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-114"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1264, "makespan": 50, "avg_agents_density": 0.15714279754939736, "runtime": 9.266431768424809}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-115"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 1926, "makespan": 76, "avg_agents_density": 0.18749334981044116, "runtime": 14.630014567170292}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-116"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1020, "makespan": 43, "avg_agents_density": 0.14853540432335932, "runtime": 8.522752082906663}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-117"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1217, "makespan": 59, "avg_agents_density": 0.15238422249757647, "runtime": 11.233255617320538}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-118"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1533, "makespan": 63, "avg_agents_density": 0.14868158440217266, "runtime": 12.30462953262031}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-119"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 863, "makespan": 42, "avg_agents_density": 0.12995117093327752, "runtime": 7.967631517909467}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-120"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1056, "makespan": 42, "avg_agents_density": 0.14130232351644936, "runtime": 7.711316735483706}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-121"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1181, "makespan": 61, "avg_agents_density": 0.10915434765654032, "runtime": 12.066519651561975}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-122"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1151, "makespan": 45, "avg_agents_density": 0.1505072256056871, "runtime": 8.768639375455678}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-123"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1393, "makespan": 61, "avg_agents_density": 0.14857529951400267, "runtime": 11.952877883799374}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-124"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1206, "makespan": 42, "avg_agents_density": 0.14746252588310924, "runtime": 7.771664266008884}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-125"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 3318, "makespan": 128, "avg_agents_density": 0.2290585479036255, "runtime": 24.593879993073642}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-126"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 958, "makespan": 34, "avg_agents_density": 0.14953846998368742, "runtime": 6.920359231997281}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-127"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1334, "makespan": 46, "avg_agents_density": 0.15866592304135899, "runtime": 11.924699863418937}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-000"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 127, "SoC": 3929, "makespan": 128, "avg_agents_density": 0.21185793189782492, "runtime": 32.271166728343815}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-001"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1487, "makespan": 51, "avg_agents_density": 0.16991569644270277, "runtime": 12.883208559826016}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-002"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1604, "makespan": 45, "avg_agents_density": 0.18343400880724836, "runtime": 11.993617889937013}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-003"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2681, "makespan": 86, "avg_agents_density": 0.1741757027628786, "runtime": 22.0833521746099}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-004"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 2197, "makespan": 61, "avg_agents_density": 0.18618385579245117, "runtime": 15.747187052853405}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-005"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1690, "makespan": 49, "avg_agents_density": 0.1883865807397559, "runtime": 12.489023137837648}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-006"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 2196, "makespan": 59, "avg_agents_density": 0.22131264120497918, "runtime": 15.543734503444284}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-007"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.53125, "CSR": 0.0, "ep_length": 127, "SoC": 5565, "makespan": 128, "avg_agents_density": 0.3018786971787034, "runtime": 32.77842438686639}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-008"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1185, "makespan": 49, "avg_agents_density": 0.16725528600978257, "runtime": 12.725084005389363}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-009"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1609, "makespan": 55, "avg_agents_density": 0.1747837531649869, "runtime": 13.72551550110802}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-010"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 125, "SoC": 2380, "makespan": 126, "avg_agents_density": 0.2440563005557513, "runtime": 30.60403827857226}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-011"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.578125, "CSR": 0.0, "ep_length": 127, "SoC": 5919, "makespan": 128, "avg_agents_density": 0.30443582583769285, "runtime": 33.24277546489611}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-012"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.734375, "CSR": 0.0, "ep_length": 127, "SoC": 4161, "makespan": 128, "avg_agents_density": 0.21772139490010103, "runtime": 33.320916049648076}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-013"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1410, "makespan": 45, "avg_agents_density": 0.18862594445795128, "runtime": 11.370374683756381}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-014"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.578125, "CSR": 0.0, "ep_length": 127, "SoC": 5016, "makespan": 128, "avg_agents_density": 0.24854110632306836, "runtime": 33.32129263272509}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-015"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1817, "makespan": 54, "avg_agents_density": 0.20283918175726176, "runtime": 14.273977804929018}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-016"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1497, "makespan": 46, "avg_agents_density": 0.15661144903939747, "runtime": 11.75893323123455}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-017"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 2427, "makespan": 78, "avg_agents_density": 0.19025881958820356, "runtime": 20.325544845778495}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-018"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 127, "SoC": 5794, "makespan": 128, "avg_agents_density": 0.2634006716342115, "runtime": 32.898764243815094}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-019"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1686, "makespan": 55, "avg_agents_density": 0.1813524108657588, "runtime": 14.262190922629088}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-020"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 2311, "makespan": 70, "avg_agents_density": 0.2043328004868007, "runtime": 18.01011083414778}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-021"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1622, "makespan": 47, "avg_agents_density": 0.2043661384053349, "runtime": 12.45878584496677}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-022"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 2009, "makespan": 52, "avg_agents_density": 0.2178032669884791, "runtime": 13.696247887797654}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-023"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1844, "makespan": 48, "avg_agents_density": 0.19400871188661717, "runtime": 12.773676396347582}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-024"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 1509, "makespan": 38, "avg_agents_density": 0.19379010752438178, "runtime": 9.333467344753444}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-025"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1402, "makespan": 44, "avg_agents_density": 0.16293773156313024, "runtime": 11.494258281309158}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-026"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 2069, "makespan": 55, "avg_agents_density": 0.2175208702114199, "runtime": 13.681576853618026}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-027"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 2585, "makespan": 74, "avg_agents_density": 0.17252843955324196, "runtime": 18.47163983853534}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-028"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1852, "makespan": 53, "avg_agents_density": 0.20075438808029875, "runtime": 14.24183144280687}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-029"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 2385, "makespan": 66, "avg_agents_density": 0.20307159409133288, "runtime": 17.472262520343065}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-030"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1415, "makespan": 46, "avg_agents_density": 0.16202479738534983, "runtime": 12.410989089403301}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-031"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 2074, "makespan": 88, "avg_agents_density": 0.19755113336437247, "runtime": 22.40081783104688}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-032"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2045, "makespan": 71, "avg_agents_density": 0.18918289825839207, "runtime": 18.672916686162353}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-033"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.625, "CSR": 0.0, "ep_length": 127, "SoC": 5528, "makespan": 128, "avg_agents_density": 0.3040624756272736, "runtime": 33.19217038573697}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-034"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 2435, "makespan": 62, "avg_agents_density": 0.24547683633338432, "runtime": 16.199978231918067}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-035"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 2113, "makespan": 49, "avg_agents_density": 0.2382936347940655, "runtime": 11.976044810842723}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-036"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 127, "SoC": 3146, "makespan": 128, "avg_agents_density": 0.18033889562032732, "runtime": 32.71516105346382}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-037"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1571, "makespan": 43, "avg_agents_density": 0.19644393763026635, "runtime": 11.073783403728157}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-038"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 2331, "makespan": 78, "avg_agents_density": 0.16614106809490692, "runtime": 19.572136861737818}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-039"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1938, "makespan": 51, "avg_agents_density": 0.19320883791998747, "runtime": 13.242624554783106}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-040"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 106, "SoC": 3328, "makespan": 107, "avg_agents_density": 0.2014445361347977, "runtime": 27.86901307757944}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-041"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 97, "SoC": 2830, "makespan": 98, "avg_agents_density": 0.20043437467643113, "runtime": 24.029211120214313}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-042"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1818, "makespan": 60, "avg_agents_density": 0.17125917881429478, "runtime": 15.651034613605589}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-043"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1479, "makespan": 42, "avg_agents_density": 0.1914629296555144, "runtime": 11.269841525238007}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-044"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1605, "makespan": 44, "avg_agents_density": 0.17090424752198777, "runtime": 11.676450718194246}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-045"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1560, "makespan": 50, "avg_agents_density": 0.15923836777794556, "runtime": 12.92400917224586}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-046"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 111, "SoC": 3672, "makespan": 112, "avg_agents_density": 0.24440158743741824, "runtime": 28.922989448998123}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-047"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 105, "SoC": 3986, "makespan": 106, "avg_agents_density": 0.23076432647385325, "runtime": 27.30710815778002}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-048"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 2268, "makespan": 72, "avg_agents_density": 0.21916977701513896, "runtime": 17.250821286346763}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-049"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 97, "SoC": 2839, "makespan": 98, "avg_agents_density": 0.1910088600106794, "runtime": 25.123222722671926}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-050"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 2119, "makespan": 61, "avg_agents_density": 0.18322577543516153, "runtime": 16.371072734240443}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-051"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 2772, "makespan": 84, "avg_agents_density": 0.18525675614776713, "runtime": 21.978245151229203}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-052"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 2113, "makespan": 67, "avg_agents_density": 0.23698677388513964, "runtime": 16.82973766606301}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-053"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 2747, "makespan": 77, "avg_agents_density": 0.21191229867860947, "runtime": 19.290197803173214}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-054"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2377, "makespan": 71, "avg_agents_density": 0.1849813507995726, "runtime": 18.606933208182454}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-055"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1291, "makespan": 39, "avg_agents_density": 0.18099635744035794, "runtime": 10.380038063973188}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-056"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1554, "makespan": 48, "avg_agents_density": 0.19601343136927035, "runtime": 12.492020935285836}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-057"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 110, "SoC": 4670, "makespan": 111, "avg_agents_density": 0.27540306275976645, "runtime": 28.13224706845358}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-058"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 2541, "makespan": 69, "avg_agents_density": 0.19583764912153925, "runtime": 18.062199540436268}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-059"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1404, "makespan": 39, "avg_agents_density": 0.215259503593151, "runtime": 10.07672854885459}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-060"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 3412, "makespan": 103, "avg_agents_density": 0.25922587957533144, "runtime": 26.233853197656572}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-061"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 3062, "makespan": 87, "avg_agents_density": 0.18970818753428842, "runtime": 21.94426262145862}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-062"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 3339, "makespan": 93, "avg_agents_density": 0.21479961657801036, "runtime": 23.57865400519222}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-063"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1691, "makespan": 60, "avg_agents_density": 0.18559281184082674, "runtime": 15.86582461418584}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-064"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 2065, "makespan": 53, "avg_agents_density": 0.22993334963571954, "runtime": 13.956617571413517}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-065"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 90, "SoC": 2800, "makespan": 91, "avg_agents_density": 0.17057429712529867, "runtime": 23.231256459839642}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-066"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1302, "makespan": 49, "avg_agents_density": 0.17101490041102793, "runtime": 12.79256648523733}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-067"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.640625, "CSR": 0.0, "ep_length": 127, "SoC": 4366, "makespan": 128, "avg_agents_density": 0.221307383958454, "runtime": 32.279315658379346}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-068"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.328125, "CSR": 0.0, "ep_length": 127, "SoC": 6318, "makespan": 128, "avg_agents_density": 0.36327774022766757, "runtime": 33.39094556635246}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-069"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 113, "SoC": 3771, "makespan": 114, "avg_agents_density": 0.2353620908945941, "runtime": 29.218328388873488}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-070"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 2150, "makespan": 102, "avg_agents_density": 0.1854641601957063, "runtime": 26.094555912539363}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-071"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 1286, "makespan": 38, "avg_agents_density": 0.14204307280915657, "runtime": 8.64238868188113}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-072"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1565, "makespan": 53, "avg_agents_density": 0.1686284969429496, "runtime": 14.08177833352238}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-073"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 127, "SoC": 3344, "makespan": 128, "avg_agents_density": 0.20937722615239485, "runtime": 32.221766638569534}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-074"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1542, "makespan": 51, "avg_agents_density": 0.18944319912400825, "runtime": 13.11948392726481}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-075"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 108, "SoC": 3505, "makespan": 109, "avg_agents_density": 0.20528732794629534, "runtime": 27.423497672658414}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-076"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1898, "makespan": 53, "avg_agents_density": 0.2204871036219927, "runtime": 14.137116461526603}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-077"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 3289, "makespan": 102, "avg_agents_density": 0.21853390561920247, "runtime": 26.122377685736865}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-078"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1468, "makespan": 47, "avg_agents_density": 0.17769349680503352, "runtime": 11.680872206110507}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-079"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1471, "makespan": 39, "avg_agents_density": 0.18636285190964946, "runtime": 9.835897905752063}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-080"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1581, "makespan": 43, "avg_agents_density": 0.2052085519793905, "runtime": 10.943470210302621}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-081"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 3294, "makespan": 85, "avg_agents_density": 0.17478942378597095, "runtime": 19.94843674590811}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-082"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1452, "makespan": 42, "avg_agents_density": 0.17375825467020792, "runtime": 10.929263152647763}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-083"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 127, "SoC": 5299, "makespan": 128, "avg_agents_density": 0.2502635123819387, "runtime": 32.00731469132006}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-084"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 106, "SoC": 2782, "makespan": 107, "avg_agents_density": 0.20263721805530469, "runtime": 24.718653387390077}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-085"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1232, "makespan": 39, "avg_agents_density": 0.14847303237815498, "runtime": 10.070748121012002}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-086"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 3142, "makespan": 85, "avg_agents_density": 0.23459531081541324, "runtime": 21.022704991977662}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-087"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 2797, "makespan": 74, "avg_agents_density": 0.23879153173469134, "runtime": 18.93825502693653}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-088"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 114, "SoC": 4279, "makespan": 115, "avg_agents_density": 0.1971169754794784, "runtime": 30.280343691818416}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-089"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 95, "SoC": 2803, "makespan": 96, "avg_agents_density": 0.20508932081997377, "runtime": 21.72311520250514}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-090"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.453125, "CSR": 0.0, "ep_length": 127, "SoC": 5506, "makespan": 128, "avg_agents_density": 0.3309589726280978, "runtime": 31.75521471630782}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-091"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1282, "makespan": 46, "avg_agents_density": 0.1755573935667436, "runtime": 11.98829893860966}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-092"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1697, "makespan": 57, "avg_agents_density": 0.17967787814102257, "runtime": 14.343772034160793}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-093"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.4375, "CSR": 0.0, "ep_length": 127, "SoC": 5586, "makespan": 128, "avg_agents_density": 0.30883568644533343, "runtime": 32.464736907277256}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-094"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.484375, "CSR": 0.0, "ep_length": 127, "SoC": 5832, "makespan": 128, "avg_agents_density": 0.32158312786126264, "runtime": 33.92622672859579}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-095"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 127, "SoC": 2575, "makespan": 128, "avg_agents_density": 0.17600855687585934, "runtime": 32.02813051408157}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-096"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 2445, "makespan": 84, "avg_agents_density": 0.19162185430186673, "runtime": 22.0971944401972}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-097"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 121, "SoC": 3924, "makespan": 122, "avg_agents_density": 0.21595508322384577, "runtime": 30.87649477319792}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-098"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 2145, "makespan": 69, "avg_agents_density": 0.1989730561249572, "runtime": 17.495553540531546}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-099"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 2535, "makespan": 88, "avg_agents_density": 0.1949746822656603, "runtime": 22.525532996747643}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-100"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1946, "makespan": 54, "avg_agents_density": 0.19603639844253395, "runtime": 14.156105721369386}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-101"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 2066, "makespan": 69, "avg_agents_density": 0.22275374423736827, "runtime": 17.47401554044336}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-102"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 1537, "makespan": 38, "avg_agents_density": 0.20416297028217228, "runtime": 9.983354862313718}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-103"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 2331, "makespan": 90, "avg_agents_density": 0.17466157836162294, "runtime": 22.057157726958394}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-104"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 127, "SoC": 4318, "makespan": 128, "avg_agents_density": 0.22514212816835813, "runtime": 32.19222792191431}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-105"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1291, "makespan": 40, "avg_agents_density": 0.162256894927734, "runtime": 10.243154021911323}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-106"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1833, "makespan": 54, "avg_agents_density": 0.22539008992603513, "runtime": 13.741111704148352}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-107"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 2227, "makespan": 61, "avg_agents_density": 0.22391573194734934, "runtime": 16.299569326918572}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-108"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 113, "SoC": 3694, "makespan": 114, "avg_agents_density": 0.2254593872359972, "runtime": 29.47638886468485}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-109"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1769, "makespan": 50, "avg_agents_density": 0.18359804453334477, "runtime": 13.41884690290317}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-110"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 2208, "makespan": 66, "avg_agents_density": 0.22003239930373905, "runtime": 17.581451267469674}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-111"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 127, "SoC": 3951, "makespan": 128, "avg_agents_density": 0.2373612728714569, "runtime": 32.52813399536535}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-112"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1559, "makespan": 43, "avg_agents_density": 0.21198560542832323, "runtime": 10.49479721300304}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-113"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1313, "makespan": 42, "avg_agents_density": 0.20597503488505123, "runtime": 10.682160888798535}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-114"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2106, "makespan": 68, "avg_agents_density": 0.20036389149950384, "runtime": 16.81006942363456}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-115"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 126, "SoC": 5335, "makespan": 127, "avg_agents_density": 0.262120170764464, "runtime": 32.957503494340926}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-116"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 1757, "makespan": 81, "avg_agents_density": 0.17068931032906284, "runtime": 20.793930462561548}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-117"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 2856, "makespan": 92, "avg_agents_density": 0.19601815762492103, "runtime": 24.45844362443313}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-118"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 2465, "makespan": 80, "avg_agents_density": 0.187929644619877, "runtime": 20.894561370834708}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-119"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1562, "makespan": 56, "avg_agents_density": 0.17948740080440903, "runtime": 14.205595410894603}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-120"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1612, "makespan": 52, "avg_agents_density": 0.18858535453495862, "runtime": 13.218444215133786}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-121"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 1920, "makespan": 86, "avg_agents_density": 0.13731785104646638, "runtime": 22.427406617440283}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-122"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1638, "makespan": 48, "avg_agents_density": 0.1953573076074986, "runtime": 12.895845785271376}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-123"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 97, "SoC": 2667, "makespan": 98, "avg_agents_density": 0.19477595828322092, "runtime": 24.750385533086956}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-124"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1914, "makespan": 61, "avg_agents_density": 0.18014200898952035, "runtime": 15.090826970525086}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-125"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 0.59375, "CSR": 0.0, "ep_length": 127, "SoC": 6136, "makespan": 128, "avg_agents_density": 0.31770580901984957, "runtime": 32.85778919700533}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-126"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1855, "makespan": 64, "avg_agents_density": 0.19872180570033998, "runtime": 16.975051203742623}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-127"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-3actions"}]