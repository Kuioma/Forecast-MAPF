[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 83, "makespan": 22, "avg_agents_density": 0.028377747497255624, "runtime": 0.5528437658213079}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-000"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 72, "makespan": 19, "avg_agents_density": 0.02714619573107971, "runtime": 0.6483083134517074}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-001"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 86, "makespan": 21, "avg_agents_density": 0.03397497939198176, "runtime": 0.6616234742105007}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-002"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 147, "makespan": 27, "avg_agents_density": 0.03193129276119482, "runtime": 0.654155382886529}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-003"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 131, "makespan": 32, "avg_agents_density": 0.03000251322959149, "runtime": 0.8806045884266496}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-004"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 109, "makespan": 22, "avg_agents_density": 0.03333141664303444, "runtime": 0.8348503899760544}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-005"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 81, "makespan": 19, "avg_agents_density": 0.03256808694337689, "runtime": 0.4715003492310643}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-006"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 171, "makespan": 39, "avg_agents_density": 0.039855414890795735, "runtime": 0.9212695960886776}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-007"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 173, "makespan": 34, "avg_agents_density": 0.031211429662311625, "runtime": 0.8611668818630278}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-008"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 123, "makespan": 29, "avg_agents_density": 0.030204668002654003, "runtime": 1.1115003852173686}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-009"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 89, "makespan": 28, "avg_agents_density": 0.025784640410687548, "runtime": 0.7713770275004208}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-010"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 114, "makespan": 24, "avg_agents_density": 0.03867812326573372, "runtime": 0.5088845775462687}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-011"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 206, "makespan": 44, "avg_agents_density": 0.0429700480327668, "runtime": 1.0982388625852764}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-012"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 143, "makespan": 29, "avg_agents_density": 0.025767778619850835, "runtime": 1.0053978604264557}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-013"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 115, "makespan": 24, "avg_agents_density": 0.038535620244055796, "runtime": 0.6320194341242313}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-014"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 172, "makespan": 29, "avg_agents_density": 0.04839022297280518, "runtime": 0.7249059821479023}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-015"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 15, "SoC": 73, "makespan": 16, "avg_agents_density": 0.030390513516349124, "runtime": 0.39331377670168877}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-016"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 95, "makespan": 23, "avg_agents_density": 0.03460662573751897, "runtime": 0.8281376943923533}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-017"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 124, "makespan": 21, "avg_agents_density": 0.025874975181714496, "runtime": 0.855137178208679}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-018"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 148, "makespan": 26, "avg_agents_density": 0.03795600487969247, "runtime": 0.6565724746324122}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-019"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 132, "makespan": 30, "avg_agents_density": 0.03230122380036921, "runtime": 0.74215776193887}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-020"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 149, "makespan": 30, "avg_agents_density": 0.03401439893302495, "runtime": 0.7544764163903892}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-021"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 134, "makespan": 31, "avg_agents_density": 0.029819766604541675, "runtime": 1.0161770656704903}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-022"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 120, "makespan": 29, "avg_agents_density": 0.040045406188841, "runtime": 0.7131790709681809}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-023"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 121, "makespan": 19, "avg_agents_density": 0.027427134319245906, "runtime": 0.49400834925472736}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-024"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 19, "SoC": 93, "makespan": 20, "avg_agents_density": 0.0399968974502198, "runtime": 0.5144400475546718}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-025"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 109, "makespan": 29, "avg_agents_density": 0.03271421059766428, "runtime": 1.0375185408629477}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-026"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 98, "makespan": 22, "avg_agents_density": 0.03208113470823441, "runtime": 0.5179899977520108}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-027"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 211, "makespan": 38, "avg_agents_density": 0.032303652284144606, "runtime": 0.9523370582610369}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-028"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 135, "makespan": 25, "avg_agents_density": 0.025822766554670088, "runtime": 0.6202505752444267}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-029"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 112, "makespan": 21, "avg_agents_density": 0.03594300969014965, "runtime": 0.5367034478113055}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-030"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 97, "makespan": 26, "avg_agents_density": 0.03163733886599939, "runtime": 0.6954660452902317}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-031"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 125, "makespan": 24, "avg_agents_density": 0.02942246159245208, "runtime": 0.5979217351414263}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-032"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 183, "makespan": 36, "avg_agents_density": 0.030681751888995412, "runtime": 0.8856735480949283}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-033"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 134, "makespan": 28, "avg_agents_density": 0.039362279484403344, "runtime": 0.7211216087453067}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-034"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 109, "makespan": 21, "avg_agents_density": 0.03561133908721568, "runtime": 0.720075442455709}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-035"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 111, "makespan": 23, "avg_agents_density": 0.047560845910984174, "runtime": 0.644815671723336}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-036"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 126, "makespan": 31, "avg_agents_density": 0.029259259660357445, "runtime": 0.7762254234403372}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-037"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 128, "makespan": 22, "avg_agents_density": 0.027756014760323598, "runtime": 0.6658786148764193}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-038"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 95, "makespan": 30, "avg_agents_density": 0.025558983118546662, "runtime": 0.991856780834496}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-039"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 94, "makespan": 19, "avg_agents_density": 0.023624327564716628, "runtime": 0.4727121228352189}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-040"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 141, "makespan": 28, "avg_agents_density": 0.031601542244959986, "runtime": 0.7116377912461758}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-041"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 143, "makespan": 27, "avg_agents_density": 0.036743533257671525, "runtime": 0.6819550860673189}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-042"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 118, "makespan": 26, "avg_agents_density": 0.032295348182207965, "runtime": 0.929417644161731}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-043"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 108, "makespan": 23, "avg_agents_density": 0.03947190362668036, "runtime": 0.589829561766237}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-044"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 80, "makespan": 29, "avg_agents_density": 0.036408004317927754, "runtime": 0.7145747235044837}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-045"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 118, "makespan": 23, "avg_agents_density": 0.030968356015598015, "runtime": 0.5972830783575773}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-046"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 136, "makespan": 28, "avg_agents_density": 0.03942795574908872, "runtime": 0.7078731311485171}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-047"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 129, "makespan": 29, "avg_agents_density": 0.04228863329740966, "runtime": 0.72183548938483}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-048"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 124, "makespan": 23, "avg_agents_density": 0.04325205583720884, "runtime": 0.5234745037741959}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-049"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 133, "makespan": 33, "avg_agents_density": 0.03474819699908648, "runtime": 1.0387681340798736}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-050"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 123, "makespan": 29, "avg_agents_density": 0.028473545409727945, "runtime": 0.8786151148378849}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-051"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 120, "makespan": 24, "avg_agents_density": 0.02233081480363711, "runtime": 0.8652635449543595}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-052"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 120, "makespan": 25, "avg_agents_density": 0.049913037294310555, "runtime": 0.6057434603571892}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-053"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 105, "makespan": 24, "avg_agents_density": 0.031170755878492065, "runtime": 0.6267018369399011}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-054"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 174, "makespan": 40, "avg_agents_density": 0.04085872386288751, "runtime": 1.3484210455790162}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-055"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 113, "makespan": 23, "avg_agents_density": 0.03138933967213256, "runtime": 0.7174058565869927}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-056"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 147, "makespan": 27, "avg_agents_density": 0.03836257399783015, "runtime": 0.6738678431138396}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-057"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 143, "makespan": 37, "avg_agents_density": 0.04230139188313428, "runtime": 1.0610610987059772}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-058"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 168, "makespan": 40, "avg_agents_density": 0.04187622442169169, "runtime": 1.38259383616969}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-059"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 122, "makespan": 22, "avg_agents_density": 0.0373474805985618, "runtime": 0.6004049000330269}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-060"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 130, "makespan": 32, "avg_agents_density": 0.03904820568973249, "runtime": 0.841916976030916}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-061"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 144, "makespan": 27, "avg_agents_density": 0.02917202596557334, "runtime": 0.9141681552864611}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-062"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 136, "makespan": 30, "avg_agents_density": 0.03730869481611, "runtime": 0.861472228076309}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-063"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 104, "makespan": 31, "avg_agents_density": 0.025010630462792338, "runtime": 0.7589358100667596}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-064"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 118, "makespan": 22, "avg_agents_density": 0.03204148824072723, "runtime": 0.5540198259986937}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-065"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 133, "makespan": 25, "avg_agents_density": 0.02722975142626181, "runtime": 0.6219710134901106}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-066"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 97, "makespan": 25, "avg_agents_density": 0.027573473942928216, "runtime": 0.21695708809420466}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-067"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 185, "makespan": 45, "avg_agents_density": 0.03502091059859005, "runtime": 1.0911981430836022}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-068"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 114, "makespan": 24, "avg_agents_density": 0.03366349571148375, "runtime": 0.8531006691046059}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-069"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 130, "makespan": 30, "avg_agents_density": 0.034209022502567354, "runtime": 0.7438643733039498}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-070"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 120, "makespan": 30, "avg_agents_density": 0.03284815295105235, "runtime": 0.25820652302354574}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-071"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 112, "makespan": 23, "avg_agents_density": 0.026979068417343183, "runtime": 0.5581336300820112}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-072"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 146, "makespan": 31, "avg_agents_density": 0.02982074283941446, "runtime": 1.0986974709667265}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-073"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 135, "makespan": 27, "avg_agents_density": 0.02885893346340711, "runtime": 0.6828088732436299}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-074"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 115, "makespan": 23, "avg_agents_density": 0.026489807711656894, "runtime": 0.20040149753913283}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-075"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 99, "makespan": 22, "avg_agents_density": 0.02658466304425569, "runtime": 0.4603467411361635}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-076"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 121, "makespan": 21, "avg_agents_density": 0.037718615678495965, "runtime": 0.81524055916816}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-077"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 138, "makespan": 31, "avg_agents_density": 0.03938058302189734, "runtime": 0.7549518588930368}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-078"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 98, "makespan": 21, "avg_agents_density": 0.03132411273114739, "runtime": 0.7139510777778924}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-079"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 102, "makespan": 19, "avg_agents_density": 0.04709740071008023, "runtime": 0.16792699741199613}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-080"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 19, "SoC": 107, "makespan": 20, "avg_agents_density": 0.03686839811421987, "runtime": 0.9321429678238928}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-081"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 147, "makespan": 32, "avg_agents_density": 0.02714296425379518, "runtime": 0.7537407889030874}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-082"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 114, "makespan": 19, "avg_agents_density": 0.029223455006393728, "runtime": 0.16712926048785448}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-083"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 139, "makespan": 33, "avg_agents_density": 0.03520848435931677, "runtime": 0.8005404635332525}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-084"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 105, "makespan": 22, "avg_agents_density": 0.04257426242576048, "runtime": 0.748198532499373}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-085"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 111, "makespan": 27, "avg_agents_density": 0.02649159285491837, "runtime": 0.6763048032298684}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-086"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 169, "makespan": 30, "avg_agents_density": 0.036536468864942176, "runtime": 0.25785870710387826}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-087"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 127, "makespan": 21, "avg_agents_density": 0.028745964556327427, "runtime": 0.5450559882447124}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-088"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 194, "makespan": 49, "avg_agents_density": 0.028383469387457193, "runtime": 1.7359974100254476}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-089"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 179, "makespan": 39, "avg_agents_density": 0.03260524985270465, "runtime": 0.9718968663364649}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-090"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 107, "makespan": 27, "avg_agents_density": 0.02969785775131924, "runtime": 0.2290799911133945}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-091"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 116, "makespan": 27, "avg_agents_density": 0.036816886148752226, "runtime": 0.6580475736409426}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-092"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 134, "makespan": 29, "avg_agents_density": 0.035450541696523265, "runtime": 1.0771488617174327}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-093"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 145, "makespan": 35, "avg_agents_density": 0.037301882163080856, "runtime": 0.8636677674949169}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-094"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 207, "makespan": 39, "avg_agents_density": 0.04307179999131553, "runtime": 0.9818178862333298}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-095"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 131, "makespan": 37, "avg_agents_density": 0.024333675998468234, "runtime": 0.8925652736797929}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-096"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 166, "makespan": 39, "avg_agents_density": 0.03169403601023781, "runtime": 0.334054013248533}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-097"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 186, "makespan": 35, "avg_agents_density": 0.03811556677793011, "runtime": 0.8868563561700284}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-098"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 158, "makespan": 34, "avg_agents_density": 0.026839279171355698, "runtime": 1.248533840291202}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-099"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 115, "makespan": 23, "avg_agents_density": 0.03140420368359111, "runtime": 0.5700244987383485}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-100"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 19, "SoC": 116, "makespan": 20, "avg_agents_density": 0.03331502189842734, "runtime": 0.5205412856303155}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-101"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 100, "makespan": 28, "avg_agents_density": 0.03750651689393315, "runtime": 0.7029674896039069}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-102"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 119, "makespan": 25, "avg_agents_density": 0.02817934186509172, "runtime": 0.8062822008505464}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-103"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 133, "makespan": 35, "avg_agents_density": 0.03846030758093845, "runtime": 0.8838576497510076}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-104"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 172, "makespan": 36, "avg_agents_density": 0.03979111463469431, "runtime": 1.0446249805390835}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-105"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 114, "makespan": 25, "avg_agents_density": 0.027470028423629833, "runtime": 0.623760228510946}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-106"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 122, "makespan": 25, "avg_agents_density": 0.03833543318327059, "runtime": 0.818891835398972}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-107"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 108, "makespan": 22, "avg_agents_density": 0.04557686530497696, "runtime": 0.5457954620942473}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-108"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 132, "makespan": 27, "avg_agents_density": 0.03415079693116282, "runtime": 0.6731509258970618}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-109"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 134, "makespan": 27, "avg_agents_density": 0.03243129835875574, "runtime": 0.6839340291917324}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-110"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 89, "makespan": 23, "avg_agents_density": 0.040188668620040224, "runtime": 0.7738014245405793}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-111"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 196, "makespan": 48, "avg_agents_density": 0.03378519985261833, "runtime": 1.1932438658550382}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-112"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 128, "makespan": 27, "avg_agents_density": 0.04957194443725303, "runtime": 0.6872703465633094}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-113"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 104, "makespan": 24, "avg_agents_density": 0.041685754789650656, "runtime": 0.6318565751425922}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-114"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 149, "makespan": 24, "avg_agents_density": 0.034346413502549175, "runtime": 0.8044301951304078}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-115"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 139, "makespan": 24, "avg_agents_density": 0.038843529952482164, "runtime": 0.5863861432299018}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-116"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 142, "makespan": 29, "avg_agents_density": 0.045981825706267763, "runtime": 0.6745099923573434}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-117"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 123, "makespan": 37, "avg_agents_density": 0.03156276127833856, "runtime": 0.861824051477015}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-118"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 13, "SoC": 73, "makespan": 14, "avg_agents_density": 0.048771740500953495, "runtime": 0.5211254730820656}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-119"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 108, "makespan": 33, "avg_agents_density": 0.0299522229529639, "runtime": 0.9254898997023702}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-120"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 160, "makespan": 34, "avg_agents_density": 0.026517162533566053, "runtime": 0.29281715117394924}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-121"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 130, "makespan": 31, "avg_agents_density": 0.026640894477614877, "runtime": 0.9154546614736319}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-122"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 161, "makespan": 30, "avg_agents_density": 0.028946928874978708, "runtime": 1.0123391123488545}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-123"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 131, "makespan": 24, "avg_agents_density": 0.02549319881694501, "runtime": 0.5865277866832912}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-124"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 114, "makespan": 23, "avg_agents_density": 0.02449837052662641, "runtime": 0.20170636288821697}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-125"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 115, "makespan": 25, "avg_agents_density": 0.03550562419091682, "runtime": 0.646392812486738}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-126"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 115, "makespan": 24, "avg_agents_density": 0.03389812110626372, "runtime": 0.9711551922373474}, "env_grid_search": {"num_agents": 8, "map_name": "validation-random-seed-127"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 262, "makespan": 28, "avg_agents_density": 0.04475558781800459, "runtime": 1.8848172756843269}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-000"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 302, "makespan": 37, "avg_agents_density": 0.05885804521619773, "runtime": 2.3638921440578997}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-001"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 228, "makespan": 33, "avg_agents_density": 0.04808336299609167, "runtime": 2.0129630379378796}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-002"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 278, "makespan": 31, "avg_agents_density": 0.050416626412192876, "runtime": 2.0252345046028495}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-003"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 268, "makespan": 37, "avg_agents_density": 0.043820801837421784, "runtime": 2.5080182068049908}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-004"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 273, "makespan": 28, "avg_agents_density": 0.05986494346187958, "runtime": 1.972240670118481}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-005"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 198, "makespan": 23, "avg_agents_density": 0.05621957304970653, "runtime": 1.4834592607803643}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-006"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 300, "makespan": 42, "avg_agents_density": 0.0575319610261703, "runtime": 2.6327172643505037}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-007"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 406, "makespan": 43, "avg_agents_density": 0.07112159981313121, "runtime": 2.7509588189423084}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-008"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 227, "makespan": 30, "avg_agents_density": 0.06101319416996271, "runtime": 1.875988190062344}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-009"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 242, "makespan": 40, "avg_agents_density": 0.05120684409099251, "runtime": 2.555063486099243}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-010"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 218, "makespan": 29, "avg_agents_density": 0.08955073507617696, "runtime": 1.7994132172316313}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-011"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 401, "makespan": 41, "avg_agents_density": 0.06721319637147938, "runtime": 2.7647309256717563}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-012"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 357, "makespan": 35, "avg_agents_density": 0.058531902177305827, "runtime": 2.3316067648120224}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-013"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 255, "makespan": 24, "avg_agents_density": 0.07487519095309972, "runtime": 1.5616321596316993}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-014"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 313, "makespan": 31, "avg_agents_density": 0.07159219722372745, "runtime": 2.0510552204214036}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-015"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 189, "makespan": 32, "avg_agents_density": 0.05164297820500625, "runtime": 1.9533554231747985}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-016"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 224, "makespan": 25, "avg_agents_density": 0.05317206661561775, "runtime": 1.61632890580222}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-017"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 239, "makespan": 22, "avg_agents_density": 0.049290547788713654, "runtime": 1.5073671163991094}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-018"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 354, "makespan": 40, "avg_agents_density": 0.061495518681680746, "runtime": 2.5578758413903415}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-019"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 250, "makespan": 29, "avg_agents_density": 0.059101376408028115, "runtime": 1.8095759293064475}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-020"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 268, "makespan": 33, "avg_agents_density": 0.06115175811347693, "runtime": 2.2903788797557354}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-021"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 234, "makespan": 30, "avg_agents_density": 0.05621296427351026, "runtime": 1.9571108031086624}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-022"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 252, "makespan": 28, "avg_agents_density": 0.07432031729154129, "runtime": 1.8390626637265086}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-023"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 279, "makespan": 31, "avg_agents_density": 0.0543070321508594, "runtime": 1.857181514147669}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-024"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 242, "makespan": 26, "avg_agents_density": 0.062079202837317465, "runtime": 1.5628839642740786}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-025"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 252, "makespan": 34, "avg_agents_density": 0.045154479558456084, "runtime": 2.1683702529408038}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-026"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 238, "makespan": 26, "avg_agents_density": 0.06466548256294782, "runtime": 1.6472190618515015}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-027"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 387, "makespan": 44, "avg_agents_density": 0.05577520023303276, "runtime": 2.6652130875736475}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-028"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 282, "makespan": 29, "avg_agents_density": 0.05082289514843481, "runtime": 1.9779391619376838}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-029"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 269, "makespan": 32, "avg_agents_density": 0.06535557735322432, "runtime": 2.170875135343522}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-030"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 250, "makespan": 29, "avg_agents_density": 0.05721803481914933, "runtime": 1.8689010990783572}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-031"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 237, "makespan": 32, "avg_agents_density": 0.049962071046395405, "runtime": 2.1678507905453444}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-032"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 349, "makespan": 49, "avg_agents_density": 0.04465470105609439, "runtime": 3.0115558649413288}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-033"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 217, "makespan": 33, "avg_agents_density": 0.06927381452047973, "runtime": 2.0474655949510634}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-034"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 208, "makespan": 27, "avg_agents_density": 0.05723250370489773, "runtime": 1.4357420108281076}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-035"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 326, "makespan": 37, "avg_agents_density": 0.07963747944073613, "runtime": 2.455839362926781}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-036"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 319, "makespan": 38, "avg_agents_density": 0.04961434314493783, "runtime": 2.2481341385282576}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-037"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 244, "makespan": 24, "avg_agents_density": 0.05109200047448405, "runtime": 1.4937273422256112}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-038"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 251, "makespan": 32, "avg_agents_density": 0.04750664145894997, "runtime": 2.0232146154157817}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-039"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 231, "makespan": 24, "avg_agents_density": 0.05162975443603944, "runtime": 1.6380240116268396}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-040"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 287, "makespan": 37, "avg_agents_density": 0.05431220392142723, "runtime": 2.115882255602628}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-041"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 274, "makespan": 36, "avg_agents_density": 0.057074030281418, "runtime": 2.3937350693158805}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-042"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 237, "makespan": 26, "avg_agents_density": 0.05642381567784239, "runtime": 1.5764797651208937}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-043"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 222, "makespan": 27, "avg_agents_density": 0.0663276718526154, "runtime": 1.740683909971267}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-044"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 232, "makespan": 27, "avg_agents_density": 0.04864816039208743, "runtime": 1.8262756895273924}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-045"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 251, "makespan": 30, "avg_agents_density": 0.054075314575479365, "runtime": 1.824896918144077}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-046"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 352, "makespan": 35, "avg_agents_density": 0.07769894136100519, "runtime": 2.347814843058586}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-047"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 512, "makespan": 53, "avg_agents_density": 0.07090105843162978, "runtime": 3.3077734084799886}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-048"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 299, "makespan": 26, "avg_agents_density": 0.07358477042375136, "runtime": 1.717507510446012}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-049"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 250, "makespan": 38, "avg_agents_density": 0.049881148353993585, "runtime": 2.327876928728074}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-050"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 265, "makespan": 29, "avg_agents_density": 0.05538570303698467, "runtime": 2.080611017998308}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-051"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 247, "makespan": 28, "avg_agents_density": 0.04831238229704942, "runtime": 1.8967629526741803}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-052"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 259, "makespan": 31, "avg_agents_density": 0.06850802079410001, "runtime": 1.9522855458781123}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-053"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 260, "makespan": 29, "avg_agents_density": 0.060256405130465866, "runtime": 1.7198267029598355}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-054"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 404, "makespan": 57, "avg_agents_density": 0.05798514768978053, "runtime": 3.6684447242878377}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-055"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 240, "makespan": 28, "avg_agents_density": 0.0532368281078063, "runtime": 1.857327557168901}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-056"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 249, "makespan": 32, "avg_agents_density": 0.06177328760409009, "runtime": 2.0597671060822904}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-057"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 277, "makespan": 34, "avg_agents_density": 0.06631378732094374, "runtime": 2.212097858544439}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-058"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 286, "makespan": 30, "avg_agents_density": 0.0654389855552866, "runtime": 2.001384182833135}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-059"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 234, "makespan": 26, "avg_agents_density": 0.0655062989964595, "runtime": 1.7545319409109652}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-060"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 270, "makespan": 31, "avg_agents_density": 0.06511354875420075, "runtime": 2.133310471661389}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-061"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 290, "makespan": 30, "avg_agents_density": 0.0472649860089482, "runtime": 2.0342843485996127}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-062"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 402, "makespan": 42, "avg_agents_density": 0.06373920414679096, "runtime": 2.739260935690254}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-063"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 225, "makespan": 27, "avg_agents_density": 0.05387527770212495, "runtime": 1.7048311866819859}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-064"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 260, "makespan": 32, "avg_agents_density": 0.06081218897183729, "runtime": 2.0912046278826892}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-065"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 295, "makespan": 36, "avg_agents_density": 0.04547812977474975, "runtime": 2.173016998451203}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-066"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 241, "makespan": 28, "avg_agents_density": 0.0474952019303665, "runtime": 1.8706125575117767}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-067"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 429, "makespan": 54, "avg_agents_density": 0.060612223530651294, "runtime": 3.4680547434836626}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-068"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 316, "makespan": 36, "avg_agents_density": 0.07641168682070408, "runtime": 2.388288354501128}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-069"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 276, "makespan": 36, "avg_agents_density": 0.061558321897829504, "runtime": 2.2858981103636324}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-070"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 262, "makespan": 36, "avg_agents_density": 0.05336179089419222, "runtime": 2.1301316134631634}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-071"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 264, "makespan": 30, "avg_agents_density": 0.03952969159861673, "runtime": 1.9998071766458452}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-072"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 254, "makespan": 29, "avg_agents_density": 0.04522953378334898, "runtime": 1.9670052118599415}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-073"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 304, "makespan": 32, "avg_agents_density": 0.052060815739346566, "runtime": 1.9825536543503404}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-074"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 269, "makespan": 43, "avg_agents_density": 0.05032364875478887, "runtime": 1.7746103736571968}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-075"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 311, "makespan": 37, "avg_agents_density": 0.060888914108832695, "runtime": 2.2664844542741776}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-076"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 279, "makespan": 42, "avg_agents_density": 0.05991319068136247, "runtime": 2.570342100225389}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-077"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 299, "makespan": 34, "avg_agents_density": 0.06221072716066786, "runtime": 2.085821708664298}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-078"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 215, "makespan": 26, "avg_agents_density": 0.05738767743189124, "runtime": 1.1625116299837828}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-079"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 242, "makespan": 32, "avg_agents_density": 0.05414186335243676, "runtime": 2.1519602881744504}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-080"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 214, "makespan": 22, "avg_agents_density": 0.060018781201072895, "runtime": 1.49035819247365}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-081"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 382, "makespan": 49, "avg_agents_density": 0.043855100132027786, "runtime": 1.8682526131160557}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-082"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 278, "makespan": 27, "avg_agents_density": 0.05673220095980736, "runtime": 1.3288382370956242}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-083"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 301, "makespan": 40, "avg_agents_density": 0.0514349991140407, "runtime": 2.5674452506937087}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-084"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 243, "makespan": 27, "avg_agents_density": 0.06973679044499195, "runtime": 1.4959827000275254}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-085"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 246, "makespan": 35, "avg_agents_density": 0.04388661755630793, "runtime": 1.4327965662814677}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-086"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 329, "makespan": 36, "avg_agents_density": 0.06665068036755649, "runtime": 2.1920240190811455}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-087"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 348, "makespan": 46, "avg_agents_density": 0.06169379913632648, "runtime": 2.8895932929590344}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-088"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 492, "makespan": 65, "avg_agents_density": 0.05419368629561487, "runtime": 3.9709232104942203}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-089"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 328, "makespan": 47, "avg_agents_density": 0.06489784574234957, "runtime": 2.813167216256261}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-090"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 300, "makespan": 43, "avg_agents_density": 0.06102897943393131, "runtime": 1.6526665543206036}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-091"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 215, "makespan": 27, "avg_agents_density": 0.05377475021821971, "runtime": 1.6644549327902496}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-092"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 304, "makespan": 46, "avg_agents_density": 0.05896178747432726, "runtime": 2.907578108366579}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-093"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 276, "makespan": 41, "avg_agents_density": 0.06370441727109759, "runtime": 2.4087065886706114}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-094"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 433, "makespan": 42, "avg_agents_density": 0.07969618913363243, "runtime": 2.7770224646665156}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-095"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 274, "makespan": 41, "avg_agents_density": 0.052822050564985644, "runtime": 2.3685554922558367}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-096"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 308, "makespan": 34, "avg_agents_density": 0.057483416249228474, "runtime": 2.1549016502685845}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-097"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 360, "makespan": 37, "avg_agents_density": 0.06965348426260899, "runtime": 2.412231443449855}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-098"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 271, "makespan": 33, "avg_agents_density": 0.06092262061006586, "runtime": 2.271331643220037}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-099"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 266, "makespan": 30, "avg_agents_density": 0.04334542151685067, "runtime": 1.8710253634490073}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-100"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 214, "makespan": 24, "avg_agents_density": 0.054712145369055935, "runtime": 1.5707854786887765}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-101"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 299, "makespan": 31, "avg_agents_density": 0.0737813235826149, "runtime": 2.0776554495096207}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-102"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 266, "makespan": 29, "avg_agents_density": 0.0538405492503832, "runtime": 1.8195155756548047}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-103"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 377, "makespan": 39, "avg_agents_density": 0.05079084920104848, "runtime": 2.430290710180998}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-104"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 419, "makespan": 49, "avg_agents_density": 0.06161767535522745, "runtime": 3.04850592976436}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-105"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 251, "makespan": 27, "avg_agents_density": 0.04497039891949966, "runtime": 1.7250183117575943}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-106"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 246, "makespan": 25, "avg_agents_density": 0.06440926502306368, "runtime": 1.6917683477513492}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-107"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 239, "makespan": 32, "avg_agents_density": 0.07367088073886242, "runtime": 2.111710004042834}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-108"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 222, "makespan": 28, "avg_agents_density": 0.05209299172003896, "runtime": 1.7731393473222852}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-109"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 300, "makespan": 34, "avg_agents_density": 0.05405761234765939, "runtime": 2.0699647055007517}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-110"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 211, "makespan": 25, "avg_agents_density": 0.06698244439956197, "runtime": 1.8232111004181206}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-111"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 280, "makespan": 36, "avg_agents_density": 0.06298933233880742, "runtime": 2.2845242228358984}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-112"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 248, "makespan": 26, "avg_agents_density": 0.06291250200443198, "runtime": 1.6391815771348774}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-113"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 218, "makespan": 25, "avg_agents_density": 0.0701647629044302, "runtime": 1.565186240710318}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-114"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 307, "makespan": 27, "avg_agents_density": 0.06014415445421621, "runtime": 1.853690548799932}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-115"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 303, "makespan": 32, "avg_agents_density": 0.06651604603344505, "runtime": 2.0926107885316014}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-116"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 251, "makespan": 32, "avg_agents_density": 0.06927999248992706, "runtime": 2.0014511346817017}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-117"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 379, "makespan": 53, "avg_agents_density": 0.06215784821087699, "runtime": 3.192797315772623}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-118"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 275, "makespan": 32, "avg_agents_density": 0.05881699932725262, "runtime": 2.007149946410209}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-119"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 224, "makespan": 35, "avg_agents_density": 0.049253091413727974, "runtime": 2.1738292295485735}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-120"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 262, "makespan": 29, "avg_agents_density": 0.05221410644298205, "runtime": 1.8328666714951396}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-121"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 301, "makespan": 41, "avg_agents_density": 0.046047439630391956, "runtime": 2.4491987410001457}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-122"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 288, "makespan": 29, "avg_agents_density": 0.0549575505945866, "runtime": 1.8732345830649137}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-123"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 314, "makespan": 32, "avg_agents_density": 0.054485379300757385, "runtime": 1.956984075717628}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-124"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 257, "makespan": 35, "avg_agents_density": 0.04716795542729806, "runtime": 2.2426506099291146}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-125"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 321, "makespan": 38, "avg_agents_density": 0.07613456468007082, "runtime": 2.2181782932020724}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-126"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 225, "makespan": 23, "avg_agents_density": 0.06158117539285509, "runtime": 1.383631077595055}, "env_grid_search": {"num_agents": 16, "map_name": "validation-random-seed-127"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 401, "makespan": 32, "avg_agents_density": 0.061569023315100745, "runtime": 3.131037624552846}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-000"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 570, "makespan": 41, "avg_agents_density": 0.09048909554069783, "runtime": 3.8389353463426232}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-001"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 354, "makespan": 34, "avg_agents_density": 0.07583255793673316, "runtime": 3.0568783497437835}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-002"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 386, "makespan": 29, "avg_agents_density": 0.07350493606799467, "runtime": 2.9437012085691094}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-003"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 367, "makespan": 36, "avg_agents_density": 0.06402670447183892, "runtime": 3.0877710678614676}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-004"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 599, "makespan": 44, "avg_agents_density": 0.08331056935710042, "runtime": 4.187843877356499}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-005"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 339, "makespan": 29, "avg_agents_density": 0.07229087134466453, "runtime": 2.7134072557091713}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-006"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 460, "makespan": 43, "avg_agents_density": 0.08275574956238141, "runtime": 3.797979644499719}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-007"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 626, "makespan": 44, "avg_agents_density": 0.09487202401396976, "runtime": 4.6431705807335675}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-008"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 396, "makespan": 39, "avg_agents_density": 0.07313959110002119, "runtime": 3.7156101148575544}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-009"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 400, "makespan": 37, "avg_agents_density": 0.0712768195178211, "runtime": 3.4931662008166313}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-010"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 403, "makespan": 26, "avg_agents_density": 0.12489832335481833, "runtime": 2.551954963710159}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-011"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 673, "makespan": 47, "avg_agents_density": 0.09797277989440563, "runtime": 4.48426343081519}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-012"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 535, "makespan": 36, "avg_agents_density": 0.07811624930777548, "runtime": 3.2992069628089666}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-013"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 456, "makespan": 30, "avg_agents_density": 0.08969964807414116, "runtime": 2.947671540081501}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-014"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 639, "makespan": 48, "avg_agents_density": 0.08724058943264394, "runtime": 4.666633882559836}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-015"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 327, "makespan": 34, "avg_agents_density": 0.07341177667239109, "runtime": 3.477380459662527}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-016"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 413, "makespan": 28, "avg_agents_density": 0.07083399740122633, "runtime": 2.637979825027287}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-017"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 392, "makespan": 32, "avg_agents_density": 0.0661894265141265, "runtime": 3.026768235489726}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-018"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 550, "makespan": 47, "avg_agents_density": 0.09798367754995203, "runtime": 4.429194303229451}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-019"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 408, "makespan": 35, "avg_agents_density": 0.08108847465193139, "runtime": 3.3190612765029073}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-020"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 584, "makespan": 51, "avg_agents_density": 0.08737798335438493, "runtime": 4.737094617448747}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-021"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 424, "makespan": 34, "avg_agents_density": 0.07599217452402145, "runtime": 3.3176088966429234}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-022"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 418, "makespan": 39, "avg_agents_density": 0.09332354314113271, "runtime": 3.794281213544309}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-023"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 427, "makespan": 34, "avg_agents_density": 0.07856600086674637, "runtime": 3.4405729812569916}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-024"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 328, "makespan": 27, "avg_agents_density": 0.08497461462807364, "runtime": 2.617982337716967}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-025"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 375, "makespan": 36, "avg_agents_density": 0.06278354643628387, "runtime": 3.426172189414501}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-026"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 421, "makespan": 32, "avg_agents_density": 0.09436634867569288, "runtime": 3.058794056996703}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-027"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 538, "makespan": 41, "avg_agents_density": 0.06830668166705328, "runtime": 3.812617890071124}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-028"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 448, "makespan": 36, "avg_agents_density": 0.07374154109841806, "runtime": 3.3727798513136804}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-029"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 393, "makespan": 29, "avg_agents_density": 0.08707673423562463, "runtime": 2.7768719508312643}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-030"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 391, "makespan": 32, "avg_agents_density": 0.07369207500830438, "runtime": 3.034431658219546}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-031"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 356, "makespan": 26, "avg_agents_density": 0.07454096951370348, "runtime": 2.686572976410389}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-032"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 418, "makespan": 36, "avg_agents_density": 0.0765866637937575, "runtime": 3.3550057210959494}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-033"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 476, "makespan": 41, "avg_agents_density": 0.09590771478699954, "runtime": 3.8415083992294967}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-034"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 369, "makespan": 25, "avg_agents_density": 0.09245291922282944, "runtime": 2.3314183414913714}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-035"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 392, "makespan": 30, "avg_agents_density": 0.10522062291220821, "runtime": 2.6905112667009234}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-036"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 403, "makespan": 34, "avg_agents_density": 0.06942107007408782, "runtime": 3.0442579914815724}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-037"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 373, "makespan": 25, "avg_agents_density": 0.0731039063127698, "runtime": 2.5618434664793313}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-038"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 393, "makespan": 29, "avg_agents_density": 0.06935477413688566, "runtime": 2.831605754327029}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-039"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 384, "makespan": 29, "avg_agents_density": 0.0837957882188309, "runtime": 2.7843453716486692}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-040"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 529, "makespan": 36, "avg_agents_density": 0.07658407147472057, "runtime": 3.4246632158756256}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-041"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 445, "makespan": 34, "avg_agents_density": 0.07594774165181577, "runtime": 3.256257917266339}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-042"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 326, "makespan": 24, "avg_agents_density": 0.07176484667126473, "runtime": 2.457578382920474}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-043"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 333, "makespan": 27, "avg_agents_density": 0.08412133167856005, "runtime": 2.4196409969590604}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-044"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 397, "makespan": 32, "avg_agents_density": 0.07541812802080844, "runtime": 3.3136835414916277}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-045"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 407, "makespan": 31, "avg_agents_density": 0.06766612239159601, "runtime": 2.849446665495634}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-046"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 484, "makespan": 48, "avg_agents_density": 0.10644114940418385, "runtime": 4.582146822940558}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-047"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 537, "makespan": 45, "avg_agents_density": 0.09084842153237613, "runtime": 4.327074348926544}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-048"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 566, "makespan": 39, "avg_agents_density": 0.09480297961218065, "runtime": 3.838435080368072}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-049"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 407, "makespan": 36, "avg_agents_density": 0.07558961098597583, "runtime": 3.2970672585070133}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-050"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 404, "makespan": 31, "avg_agents_density": 0.0747478044483332, "runtime": 2.82469263067469}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-051"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 478, "makespan": 39, "avg_agents_density": 0.07119335117371894, "runtime": 3.760050698183477}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-052"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 409, "makespan": 32, "avg_agents_density": 0.09793102639842992, "runtime": 3.0348280034959316}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-053"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 512, "makespan": 50, "avg_agents_density": 0.07451976626947118, "runtime": 4.915389721747488}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-054"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 588, "makespan": 47, "avg_agents_density": 0.07071703933057241, "runtime": 4.296384639106691}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-055"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 391, "makespan": 31, "avg_agents_density": 0.07047834908010402, "runtime": 3.0873122978955507}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-056"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 326, "makespan": 29, "avg_agents_density": 0.08910990685345138, "runtime": 2.8141892394050956}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-057"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 491, "makespan": 37, "avg_agents_density": 0.10075072687363872, "runtime": 3.4676298769190907}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-058"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 482, "makespan": 43, "avg_agents_density": 0.0939440219435291, "runtime": 3.791571599431336}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-059"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 449, "makespan": 37, "avg_agents_density": 0.0871156928430227, "runtime": 3.391734056174755}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-060"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 365, "makespan": 33, "avg_agents_density": 0.08905095293763769, "runtime": 3.2274953885935247}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-061"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 643, "makespan": 44, "avg_agents_density": 0.0740359348525606, "runtime": 4.031451610382646}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-062"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 819, "makespan": 61, "avg_agents_density": 0.08633299970566335, "runtime": 5.721349007915705}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-063"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 442, "makespan": 41, "avg_agents_density": 0.08406673218847625, "runtime": 3.757659644354135}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-064"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 456, "makespan": 35, "avg_agents_density": 0.08649435506945853, "runtime": 3.3295706468634307}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-065"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 455, "makespan": 31, "avg_agents_density": 0.06518973028937995, "runtime": 2.870008401107043}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-066"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 355, "makespan": 29, "avg_agents_density": 0.06679137790296275, "runtime": 2.6999854831956327}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-067"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 726, "makespan": 46, "avg_agents_density": 0.08610003295814289, "runtime": 4.389035901520401}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-068"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 538, "makespan": 42, "avg_agents_density": 0.11075949586400125, "runtime": 4.118279485031962}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-069"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 504, "makespan": 36, "avg_agents_density": 0.08694929400276526, "runtime": 3.4600219363346696}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-070"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 452, "makespan": 41, "avg_agents_density": 0.071065359889225, "runtime": 3.8611654308624566}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-071"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 377, "makespan": 25, "avg_agents_density": 0.05906607321230717, "runtime": 2.3834837884642184}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-072"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 429, "makespan": 31, "avg_agents_density": 0.0688140155170313, "runtime": 3.0326096802018583}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-073"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 453, "makespan": 34, "avg_agents_density": 0.08129989564706536, "runtime": 3.1552120693959296}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-074"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 420, "makespan": 41, "avg_agents_density": 0.07720330980327088, "runtime": 3.7143497178331017}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-075"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 523, "makespan": 47, "avg_agents_density": 0.07966104352923221, "runtime": 4.453225813806057}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-076"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 384, "makespan": 34, "avg_agents_density": 0.09546047448902219, "runtime": 3.1767284185625613}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-077"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 599, "makespan": 44, "avg_agents_density": 0.08662244984666376, "runtime": 4.1230683284811676}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-078"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 335, "makespan": 29, "avg_agents_density": 0.07974081819866287, "runtime": 2.6407103459350765}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-079"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 380, "makespan": 31, "avg_agents_density": 0.07559161816640078, "runtime": 2.854545585811138}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-080"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 331, "makespan": 27, "avg_agents_density": 0.08358357151495269, "runtime": 2.386502350214869}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-081"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 490, "makespan": 40, "avg_agents_density": 0.07255445820973441, "runtime": 3.812337695620954}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-082"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 433, "makespan": 29, "avg_agents_density": 0.08169197513665402, "runtime": 2.9561963859014213}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-083"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 490, "makespan": 42, "avg_agents_density": 0.07225655450931244, "runtime": 3.7163873887620866}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-084"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 435, "makespan": 29, "avg_agents_density": 0.09227783307597962, "runtime": 2.398209397215396}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-085"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 388, "makespan": 40, "avg_agents_density": 0.07079768061131948, "runtime": 3.5642084176652133}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-086"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 504, "makespan": 39, "avg_agents_density": 0.07763214074357756, "runtime": 3.5046835872344673}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-087"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 425, "makespan": 39, "avg_agents_density": 0.08241204245584359, "runtime": 3.626792373601347}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-088"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 646, "makespan": 62, "avg_agents_density": 0.07625172373338614, "runtime": 5.294536354020238}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-089"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 577, "makespan": 48, "avg_agents_density": 0.092871534588949, "runtime": 4.358354101888835}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-090"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 755, "makespan": 65, "avg_agents_density": 0.09650094504277804, "runtime": 6.07306102802977}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-091"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 321, "makespan": 30, "avg_agents_density": 0.07197766097406959, "runtime": 2.7617126889526844}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-092"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 445, "makespan": 35, "avg_agents_density": 0.08032950240715228, "runtime": 3.392681470606476}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-093"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 514, "makespan": 45, "avg_agents_density": 0.0939174835119072, "runtime": 4.2760439636185765}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-094"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 977, "makespan": 74, "avg_agents_density": 0.11480325972620402, "runtime": 7.052655457984656}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-095"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 521, "makespan": 47, "avg_agents_density": 0.08119207407238617, "runtime": 4.334290526807308}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-096"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 407, "makespan": 33, "avg_agents_density": 0.07745736838842356, "runtime": 3.1491406173445284}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-097"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 640, "makespan": 38, "avg_agents_density": 0.08999968284033816, "runtime": 3.6561836623586714}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-098"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 449, "makespan": 37, "avg_agents_density": 0.0897631160441518, "runtime": 3.595797559246421}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-099"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 387, "makespan": 33, "avg_agents_density": 0.07118870712116969, "runtime": 3.0486473510973155}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-100"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 360, "makespan": 27, "avg_agents_density": 0.08231803398693949, "runtime": 2.7074658013880253}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-101"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 476, "makespan": 34, "avg_agents_density": 0.09622919819234095, "runtime": 3.250545769929886}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-102"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 398, "makespan": 30, "avg_agents_density": 0.07834979543357472, "runtime": 3.000225427094847}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-103"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 491, "makespan": 36, "avg_agents_density": 0.07219399755074699, "runtime": 3.4395125452429056}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-104"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 651, "makespan": 45, "avg_agents_density": 0.0853544638198459, "runtime": 4.132146625313908}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-105"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 463, "makespan": 36, "avg_agents_density": 0.06385215326996127, "runtime": 3.3787789111956954}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-106"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 445, "makespan": 31, "avg_agents_density": 0.09249836946840485, "runtime": 3.032789905089885}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-107"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 373, "makespan": 28, "avg_agents_density": 0.08876901284121787, "runtime": 2.72507500462234}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-108"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 505, "makespan": 37, "avg_agents_density": 0.08543721586670795, "runtime": 3.394336987286806}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-109"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 436, "makespan": 33, "avg_agents_density": 0.06884019197124826, "runtime": 3.044537720736116}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-110"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 421, "makespan": 34, "avg_agents_density": 0.08624230293012751, "runtime": 3.1872650859877467}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-111"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 484, "makespan": 53, "avg_agents_density": 0.08573038083400268, "runtime": 4.83262303378433}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-112"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 344, "makespan": 27, "avg_agents_density": 0.09528593724425367, "runtime": 2.4859401173889637}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-113"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 376, "makespan": 31, "avg_agents_density": 0.09847350854826345, "runtime": 2.9544227104634047}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-114"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 513, "makespan": 36, "avg_agents_density": 0.0961627158375354, "runtime": 3.5132819013670087}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-115"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 549, "makespan": 33, "avg_agents_density": 0.09265826282745432, "runtime": 3.0271321278996766}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-116"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 415, "makespan": 32, "avg_agents_density": 0.0910272361282077, "runtime": 2.983599049039185}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-117"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 505, "makespan": 42, "avg_agents_density": 0.09012510902930583, "runtime": 3.979075262323022}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-118"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 464, "makespan": 34, "avg_agents_density": 0.0879930092334684, "runtime": 3.309550079051405}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-119"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 356, "makespan": 34, "avg_agents_density": 0.07230672126619637, "runtime": 3.0114721599966288}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-120"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 457, "makespan": 40, "avg_agents_density": 0.07341429798982202, "runtime": 3.6539374124258757}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-121"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 514, "makespan": 40, "avg_agents_density": 0.06596581922427676, "runtime": 3.6151039386168122}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-122"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 404, "makespan": 33, "avg_agents_density": 0.0814088876479434, "runtime": 3.0421944563277066}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-123"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 563, "makespan": 35, "avg_agents_density": 0.08076036873969274, "runtime": 3.3579617412760854}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-124"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 430, "makespan": 36, "avg_agents_density": 0.07748225810973076, "runtime": 3.5043565342202783}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-125"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 515, "makespan": 32, "avg_agents_density": 0.10123901027805683, "runtime": 3.0224928352981806}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-126"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 400, "makespan": 32, "avg_agents_density": 0.08608579528749963, "runtime": 3.099661330226809}, "env_grid_search": {"num_agents": 24, "map_name": "validation-random-seed-127"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 542, "makespan": 29, "avg_agents_density": 0.09176323367591271, "runtime": 3.8866492910310626}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-000"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1041, "makespan": 64, "avg_agents_density": 0.13713819187803614, "runtime": 8.099456039723009}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-001"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 539, "makespan": 36, "avg_agents_density": 0.08978529616736862, "runtime": 4.342439281288534}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-002"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 558, "makespan": 32, "avg_agents_density": 0.09121501173916892, "runtime": 3.9640500391833484}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-003"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 480, "makespan": 42, "avg_agents_density": 0.07985078145454003, "runtime": 5.591838522348553}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-004"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 744, "makespan": 43, "avg_agents_density": 0.10847357342818859, "runtime": 5.563219049014151}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-005"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 524, "makespan": 38, "avg_agents_density": 0.09714474665828199, "runtime": 4.866568460129201}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-006"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 636, "makespan": 42, "avg_agents_density": 0.09976928974893946, "runtime": 4.970063221175224}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-007"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1049, "makespan": 58, "avg_agents_density": 0.11584570537877766, "runtime": 7.483295486774296}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-008"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 482, "makespan": 32, "avg_agents_density": 0.09504948175362335, "runtime": 4.039262838661671}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-009"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 656, "makespan": 38, "avg_agents_density": 0.0978236053872948, "runtime": 4.861126865725964}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-010"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 580, "makespan": 33, "avg_agents_density": 0.15492587995031423, "runtime": 4.231487025041133}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-011"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 1293, "makespan": 86, "avg_agents_density": 0.12786643436909143, "runtime": 10.758221233729273}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-012"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 705, "makespan": 37, "avg_agents_density": 0.09686503319704824, "runtime": 4.798916056752205}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-013"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 493, "makespan": 31, "avg_agents_density": 0.11420846438856484, "runtime": 4.068562272470444}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-014"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 864, "makespan": 56, "avg_agents_density": 0.10044315369670873, "runtime": 7.032317359000444}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-015"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 491, "makespan": 36, "avg_agents_density": 0.09974289477759694, "runtime": 4.453552194405347}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-016"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 664, "makespan": 39, "avg_agents_density": 0.09070970668805556, "runtime": 4.8223926718346775}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-017"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 709, "makespan": 56, "avg_agents_density": 0.09054741456152154, "runtime": 6.947721632663161}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-018"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 978, "makespan": 54, "avg_agents_density": 0.12941659781659146, "runtime": 6.68212246755138}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-019"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 608, "makespan": 36, "avg_agents_density": 0.09843108242236115, "runtime": 4.4700191779993474}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-020"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 807, "makespan": 44, "avg_agents_density": 0.10729170114718804, "runtime": 5.463461084757}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-021"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 558, "makespan": 34, "avg_agents_density": 0.10106972009207227, "runtime": 4.393859508447349}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-022"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 567, "makespan": 37, "avg_agents_density": 0.12152833686433129, "runtime": 4.616958517581224}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-023"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 652, "makespan": 31, "avg_agents_density": 0.10703718842257459, "runtime": 3.8900609193369746}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-024"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 567, "makespan": 39, "avg_agents_density": 0.10128392975279776, "runtime": 4.736655484884977}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-025"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 564, "makespan": 44, "avg_agents_density": 0.0806101483237014, "runtime": 5.332301606424153}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-026"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 598, "makespan": 37, "avg_agents_density": 0.1132935218970429, "runtime": 4.591975510586053}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-027"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 854, "makespan": 47, "avg_agents_density": 0.09660957519504926, "runtime": 5.858644561842084}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-028"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 603, "makespan": 36, "avg_agents_density": 0.09280097725279082, "runtime": 4.595485657453537}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-029"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 566, "makespan": 35, "avg_agents_density": 0.10193029412948283, "runtime": 4.295879894867539}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-030"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 720, "makespan": 42, "avg_agents_density": 0.10112851862314669, "runtime": 5.103608365636319}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-031"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 575, "makespan": 49, "avg_agents_density": 0.0940590451729021, "runtime": 6.383289373014122}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-032"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 731, "makespan": 52, "avg_agents_density": 0.09595361974450689, "runtime": 6.375399575103074}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-033"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 743, "makespan": 39, "avg_agents_density": 0.13492894921695867, "runtime": 5.2170393308624625}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-034"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 580, "makespan": 34, "avg_agents_density": 0.12754276175514953, "runtime": 3.680528714787215}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-035"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 692, "makespan": 38, "avg_agents_density": 0.13892941078366258, "runtime": 5.768806350417435}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-036"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 653, "makespan": 43, "avg_agents_density": 0.09861119535052722, "runtime": 5.77929848479107}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-037"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 617, "makespan": 43, "avg_agents_density": 0.09137071763469681, "runtime": 5.499928554985672}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-038"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 581, "makespan": 46, "avg_agents_density": 0.0842367578744476, "runtime": 5.094271170441061}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-039"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 724, "makespan": 40, "avg_agents_density": 0.10186580248912061, "runtime": 5.343429894652218}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-040"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 815, "makespan": 45, "avg_agents_density": 0.09363170494887611, "runtime": 5.949061868712306}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-041"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 698, "makespan": 43, "avg_agents_density": 0.10123103107557427, "runtime": 5.878887894097716}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-042"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 477, "makespan": 28, "avg_agents_density": 0.1024349948465226, "runtime": 3.404568545985967}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-043"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 515, "makespan": 33, "avg_agents_density": 0.10015192336401432, "runtime": 4.55896175513044}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-044"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 551, "makespan": 32, "avg_agents_density": 0.09169401345097028, "runtime": 4.0348113174550235}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-045"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 497, "makespan": 29, "avg_agents_density": 0.09119873772669039, "runtime": 3.7099308408796787}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-046"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 829, "makespan": 54, "avg_agents_density": 0.1342168855520531, "runtime": 7.360567712690681}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-047"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 668, "makespan": 35, "avg_agents_density": 0.11815292034434581, "runtime": 4.534134155604988}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-048"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 731, "makespan": 42, "avg_agents_density": 0.11956328003900829, "runtime": 5.3818994029425085}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-049"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 733, "makespan": 49, "avg_agents_density": 0.09863433590313297, "runtime": 5.034118615556508}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-050"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 572, "makespan": 29, "avg_agents_density": 0.09672307702060813, "runtime": 3.752983702812344}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-051"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 615, "makespan": 38, "avg_agents_density": 0.09385176629400731, "runtime": 4.731717944610864}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-052"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 789, "makespan": 44, "avg_agents_density": 0.13487639104363783, "runtime": 5.431527859065682}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-053"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 669, "makespan": 33, "avg_agents_density": 0.10695267652648924, "runtime": 4.171067479532212}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-054"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 745, "makespan": 43, "avg_agents_density": 0.08628588604289639, "runtime": 5.564993779640645}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-055"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 500, "makespan": 29, "avg_agents_density": 0.10138260803350356, "runtime": 3.802360509056598}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-056"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 625, "makespan": 36, "avg_agents_density": 0.1163980661418285, "runtime": 4.437080828938633}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-057"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 905, "makespan": 60, "avg_agents_density": 0.1213407647110108, "runtime": 8.967639508191496}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-058"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 659, "makespan": 39, "avg_agents_density": 0.10764773701638579, "runtime": 4.72068230016157}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-059"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 496, "makespan": 28, "avg_agents_density": 0.12276742093856634, "runtime": 3.6325225424952805}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-060"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 571, "makespan": 35, "avg_agents_density": 0.12375776773850139, "runtime": 4.311330169439316}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-061"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 844, "makespan": 52, "avg_agents_density": 0.08688325359129144, "runtime": 6.3163282559253275}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-062"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 876, "makespan": 45, "avg_agents_density": 0.10949562573030415, "runtime": 5.73453153623268}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-063"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 494, "makespan": 27, "avg_agents_density": 0.10270725916656401, "runtime": 3.447145069949329}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-064"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 586, "makespan": 30, "avg_agents_density": 0.11914366674183538, "runtime": 3.9394299499690533}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-065"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 669, "makespan": 49, "avg_agents_density": 0.08912682392353705, "runtime": 5.959997335914522}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-066"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 481, "makespan": 28, "avg_agents_density": 0.08701952033775955, "runtime": 3.5952702183276415}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-067"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1121, "makespan": 64, "avg_agents_density": 0.10492484084533003, "runtime": 7.6540701747871935}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-068"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 858, "makespan": 48, "avg_agents_density": 0.1381597271263355, "runtime": 5.830505118705332}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-069"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 699, "makespan": 44, "avg_agents_density": 0.10089269793203595, "runtime": 5.840855231042951}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-070"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 578, "makespan": 44, "avg_agents_density": 0.09789923229509476, "runtime": 5.318015143275261}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-071"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 472, "makespan": 27, "avg_agents_density": 0.07249370762438138, "runtime": 3.5079884016886353}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-072"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 558, "makespan": 34, "avg_agents_density": 0.08424199064916046, "runtime": 4.360867539886385}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-073"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 715, "makespan": 42, "avg_agents_density": 0.11109315933885139, "runtime": 4.874715264420956}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-074"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 659, "makespan": 47, "avg_agents_density": 0.09430757096844282, "runtime": 5.966537758242339}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-075"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 944, "makespan": 59, "avg_agents_density": 0.10387877125279177, "runtime": 7.134622399229556}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-076"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 659, "makespan": 41, "avg_agents_density": 0.11821823519657275, "runtime": 5.344685095362365}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-077"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 739, "makespan": 43, "avg_agents_density": 0.114333811437806, "runtime": 5.537674376741052}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-078"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 582, "makespan": 30, "avg_agents_density": 0.10215290076487751, "runtime": 3.747264032717794}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-079"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 560, "makespan": 31, "avg_agents_density": 0.10331187150306684, "runtime": 3.866967577021569}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-080"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 576, "makespan": 32, "avg_agents_density": 0.11439108758833798, "runtime": 4.071775801479816}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-081"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 893, "makespan": 87, "avg_agents_density": 0.08545267989719287, "runtime": 9.899797984864563}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-082"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 561, "makespan": 33, "avg_agents_density": 0.09038159549479007, "runtime": 4.304922106675804}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-083"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1003, "makespan": 62, "avg_agents_density": 0.10718047786343197, "runtime": 7.509649766609073}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-084"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 726, "makespan": 41, "avg_agents_density": 0.1213706745322517, "runtime": 4.846562170423567}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-085"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 585, "makespan": 37, "avg_agents_density": 0.08422474415282731, "runtime": 4.774184858892113}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-086"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 940, "makespan": 53, "avg_agents_density": 0.1023254545739176, "runtime": 6.6029863129369915}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-087"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 608, "makespan": 32, "avg_agents_density": 0.11441169872839216, "runtime": 4.1888297740370035}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-088"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1103, "makespan": 61, "avg_agents_density": 0.10981222299024182, "runtime": 7.766852308996022}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-089"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1134, "makespan": 59, "avg_agents_density": 0.12109047618522219, "runtime": 6.992631141562015}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-090"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1165, "makespan": 71, "avg_agents_density": 0.1300955766100255, "runtime": 8.597235849592835}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-091"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 500, "makespan": 37, "avg_agents_density": 0.0832067285822089, "runtime": 4.762770397122949}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-092"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 625, "makespan": 34, "avg_agents_density": 0.10228674833117857, "runtime": 4.6119807828217745}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-093"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1000, "makespan": 59, "avg_agents_density": 0.12973064720809943, "runtime": 7.206210009288043}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-094"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 116, "SoC": 2194, "makespan": 117, "avg_agents_density": 0.1455395577464107, "runtime": 14.466011050157249}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-095"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 652, "makespan": 40, "avg_agents_density": 0.09551254172399011, "runtime": 5.16413423512131}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-096"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 589, "makespan": 40, "avg_agents_density": 0.09494333323150606, "runtime": 5.134436571970582}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-097"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 899, "makespan": 54, "avg_agents_density": 0.10799999673832375, "runtime": 6.763171618338674}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-098"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 836, "makespan": 47, "avg_agents_density": 0.11693030521884291, "runtime": 5.801481031347066}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-099"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 642, "makespan": 37, "avg_agents_density": 0.10209125952532173, "runtime": 4.747644877526909}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-100"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 483, "makespan": 25, "avg_agents_density": 0.09998035953743255, "runtime": 3.2284102654084563}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-101"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 690, "makespan": 41, "avg_agents_density": 0.12002354606838225, "runtime": 5.244370257481933}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-102"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 576, "makespan": 30, "avg_agents_density": 0.10527645702602194, "runtime": 3.8307218230329454}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-103"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 672, "makespan": 39, "avg_agents_density": 0.09012040828044042, "runtime": 5.153002330567688}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-104"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 1170, "makespan": 75, "avg_agents_density": 0.11400931407503219, "runtime": 9.344740197062492}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-105"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 576, "makespan": 33, "avg_agents_density": 0.08356101055355526, "runtime": 4.186672692652792}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-106"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 752, "makespan": 42, "avg_agents_density": 0.11819820968902399, "runtime": 5.627890619914979}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-107"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 596, "makespan": 32, "avg_agents_density": 0.11919818550306426, "runtime": 4.18655308522284}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-108"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 653, "makespan": 37, "avg_agents_density": 0.10450579357504254, "runtime": 4.553253578487784}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-109"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 597, "makespan": 32, "avg_agents_density": 0.09188341334805562, "runtime": 4.159725837875158}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-110"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 514, "makespan": 31, "avg_agents_density": 0.10727153856501365, "runtime": 3.8336085621267557}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-111"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 901, "makespan": 55, "avg_agents_density": 0.12160729252780185, "runtime": 6.6513022650033236}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-112"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 547, "makespan": 27, "avg_agents_density": 0.11809009506592363, "runtime": 3.4418713855557144}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-113"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 619, "makespan": 38, "avg_agents_density": 0.11502656337016667, "runtime": 4.897654123604298}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-114"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 613, "makespan": 33, "avg_agents_density": 0.11765623108641382, "runtime": 4.057374711148441}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-115"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 818, "makespan": 37, "avg_agents_density": 0.12856950838619222, "runtime": 4.609294857364148}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-116"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 594, "makespan": 36, "avg_agents_density": 0.11283047998097612, "runtime": 4.375918389763683}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-117"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 837, "makespan": 64, "avg_agents_density": 0.09739745496891555, "runtime": 7.779896977357566}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-118"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 919, "makespan": 51, "avg_agents_density": 0.11237564804807762, "runtime": 6.43033814849332}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-119"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 573, "makespan": 38, "avg_agents_density": 0.09038085201559716, "runtime": 4.7079892084002495}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-120"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 599, "makespan": 41, "avg_agents_density": 0.09244103968472935, "runtime": 4.948992469348013}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-121"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 739, "makespan": 53, "avg_agents_density": 0.0754389539505498, "runtime": 6.938359996303916}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-122"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 538, "makespan": 43, "avg_agents_density": 0.10084464752472329, "runtime": 5.603683597408235}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-123"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 840, "makespan": 51, "avg_agents_density": 0.11299019931896842, "runtime": 6.144865403417498}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-124"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 591, "makespan": 38, "avg_agents_density": 0.09126561321486273, "runtime": 4.74776069726795}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-125"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 968, "makespan": 52, "avg_agents_density": 0.14374426182083347, "runtime": 6.651580237783492}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-126"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 611, "makespan": 31, "avg_agents_density": 0.11102069674133688, "runtime": 3.923395036254078}, "env_grid_search": {"num_agents": 32, "map_name": "validation-random-seed-127"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 927, "makespan": 39, "avg_agents_density": 0.12864716161638906, "runtime": 7.790975101292133}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-000"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1762, "makespan": 58, "avg_agents_density": 0.17705947272711628, "runtime": 11.002250225748867}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-001"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 829, "makespan": 38, "avg_agents_density": 0.14418398889065717, "runtime": 7.395180125720799}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-002"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 913, "makespan": 34, "avg_agents_density": 0.13366352633053435, "runtime": 6.765860870946199}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-003"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1036, "makespan": 50, "avg_agents_density": 0.12132400779193635, "runtime": 9.801084922626615}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-004"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1311, "makespan": 44, "avg_agents_density": 0.143540402703259, "runtime": 8.633712934795767}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-005"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1009, "makespan": 39, "avg_agents_density": 0.13872787122442234, "runtime": 6.8529182956554}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-006"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1339, "makespan": 68, "avg_agents_density": 0.14224059768380104, "runtime": 12.710862560197711}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-007"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 2241, "makespan": 82, "avg_agents_density": 0.17884715419128158, "runtime": 15.911929422523826}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-008"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 800, "makespan": 38, "avg_agents_density": 0.12801257929084703, "runtime": 7.1662957752123475}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-009"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1077, "makespan": 42, "avg_agents_density": 0.12980433764778995, "runtime": 8.153692573774606}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-010"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 1016, "makespan": 36, "avg_agents_density": 0.19923123757932226, "runtime": 6.985182108357549}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-011"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 3119, "makespan": 128, "avg_agents_density": 0.2042019103517899, "runtime": 24.14178004860878}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-012"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1644, "makespan": 62, "avg_agents_density": 0.13311285477572157, "runtime": 12.18915005447343}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-013"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 886, "makespan": 37, "avg_agents_density": 0.15808423772696392, "runtime": 7.084113609045744}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-014"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 2510, "makespan": 88, "avg_agents_density": 0.18564956509669475, "runtime": 17.115337701980025}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-015"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 988, "makespan": 39, "avg_agents_density": 0.15885120089131946, "runtime": 7.698987496085465}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-016"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 1019, "makespan": 38, "avg_agents_density": 0.11679654550068776, "runtime": 7.72090629953891}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-017"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1394, "makespan": 62, "avg_agents_density": 0.14871401642407056, "runtime": 11.353148606605828}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-018"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2005, "makespan": 86, "avg_agents_density": 0.1595991765026426, "runtime": 15.882094976492226}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-019"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 987, "makespan": 39, "avg_agents_density": 0.14083910323598212, "runtime": 7.552489180583507}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-020"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1222, "makespan": 48, "avg_agents_density": 0.14438419328698832, "runtime": 9.512811969965696}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-021"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1027, "makespan": 48, "avg_agents_density": 0.14975105680593517, "runtime": 8.981441041920334}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-022"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1319, "makespan": 44, "avg_agents_density": 0.1782569912105146, "runtime": 8.991161180194467}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-023"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 1117, "makespan": 36, "avg_agents_density": 0.14550318098237988, "runtime": 6.973719430156052}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-024"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1031, "makespan": 39, "avg_agents_density": 0.14694834093821918, "runtime": 7.297343864105642}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-025"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 976, "makespan": 45, "avg_agents_density": 0.12708022989221868, "runtime": 8.582339452113956}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-026"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1036, "makespan": 41, "avg_agents_density": 0.1575674322063107, "runtime": 7.972422108519822}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-027"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1711, "makespan": 69, "avg_agents_density": 0.13378579085179182, "runtime": 13.093113937880844}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-028"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1050, "makespan": 46, "avg_agents_density": 0.14402507203771922, "runtime": 9.076229470781982}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-029"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1339, "makespan": 46, "avg_agents_density": 0.16149023071464688, "runtime": 8.757362256757915}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-030"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 953, "makespan": 35, "avg_agents_density": 0.13411505701230997, "runtime": 6.963999483734369}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-031"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1198, "makespan": 51, "avg_agents_density": 0.16071848922110193, "runtime": 9.790192369371653}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-032"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1226, "makespan": 51, "avg_agents_density": 0.13808237719319225, "runtime": 9.845361935440451}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-033"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 117, "SoC": 3012, "makespan": 118, "avg_agents_density": 0.20408514902910108, "runtime": 23.474004392512143}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-034"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 1059, "makespan": 38, "avg_agents_density": 0.17953425136976256, "runtime": 7.4327958058565855}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-035"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1147, "makespan": 43, "avg_agents_density": 0.18609427457256728, "runtime": 8.247711639851332}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-036"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1604, "makespan": 54, "avg_agents_density": 0.15306100201733025, "runtime": 10.41044946666807}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-037"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1051, "makespan": 39, "avg_agents_density": 0.15038417556908992, "runtime": 7.691186940297484}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-038"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1107, "makespan": 44, "avg_agents_density": 0.1290506706699087, "runtime": 8.305263252463192}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-039"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1285, "makespan": 51, "avg_agents_density": 0.14930118044502447, "runtime": 10.032790345139802}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-040"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1355, "makespan": 54, "avg_agents_density": 0.14110050800042853, "runtime": 10.731649996247143}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-041"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1515, "makespan": 56, "avg_agents_density": 0.16288940690030904, "runtime": 10.851110477000475}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-042"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 863, "makespan": 34, "avg_agents_density": 0.1407872718194725, "runtime": 6.242667657788843}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-043"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1138, "makespan": 46, "avg_agents_density": 0.15171682061212696, "runtime": 7.237652773503214}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-044"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1003, "makespan": 40, "avg_agents_density": 0.13687207284629507, "runtime": 8.271816710475832}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-045"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 1297, "makespan": 128, "avg_agents_density": 0.10948588553758759, "runtime": 23.636136478278786}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-046"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1428, "makespan": 55, "avg_agents_density": 0.1832068703936877, "runtime": 10.626200708094984}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-047"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1442, "makespan": 58, "avg_agents_density": 0.16879998731940782, "runtime": 11.184568499680609}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-048"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1435, "makespan": 44, "avg_agents_density": 0.18845692319735272, "runtime": 9.498884631320834}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-049"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1335, "makespan": 46, "avg_agents_density": 0.1351166828619889, "runtime": 8.542963203042746}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-050"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1209, "makespan": 42, "avg_agents_density": 0.13997357228531343, "runtime": 8.329022608231753}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-051"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1224, "makespan": 45, "avg_agents_density": 0.13378320119204287, "runtime": 9.111401148606092}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-052"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1299, "makespan": 40, "avg_agents_density": 0.17955290304213617, "runtime": 7.696607165969908}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-053"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1464, "makespan": 54, "avg_agents_density": 0.17576543252850135, "runtime": 10.706237361766398}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-054"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 2461, "makespan": 128, "avg_agents_density": 0.13167211482160673, "runtime": 24.434969945810735}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-055"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 981, "makespan": 38, "avg_agents_density": 0.14071699419361502, "runtime": 7.504497557412833}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-056"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1303, "makespan": 61, "avg_agents_density": 0.15286490267828498, "runtime": 11.657797954045236}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-057"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1615, "makespan": 62, "avg_agents_density": 0.19803826780395828, "runtime": 11.582681945059448}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-058"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1252, "makespan": 44, "avg_agents_density": 0.1587886040308695, "runtime": 8.711128911934793}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-059"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1005, "makespan": 43, "avg_agents_density": 0.1616569853626969, "runtime": 8.320876558776945}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-060"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1237, "makespan": 51, "avg_agents_density": 0.18903894380881991, "runtime": 8.61234289733693}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-061"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1525, "makespan": 65, "avg_agents_density": 0.12988938992431937, "runtime": 12.474989737384021}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-062"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1790, "makespan": 58, "avg_agents_density": 0.16792236660379337, "runtime": 11.768213321920484}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-063"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1010, "makespan": 49, "avg_agents_density": 0.1439195122661703, "runtime": 9.344967922195792}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-064"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1215, "makespan": 40, "avg_agents_density": 0.171053766019313, "runtime": 7.605306989978999}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-065"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1113, "makespan": 44, "avg_agents_density": 0.13450304701506685, "runtime": 8.610766507685184}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-066"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 956, "makespan": 44, "avg_agents_density": 0.1283328951522349, "runtime": 8.597485959529877}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-067"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 87, "SoC": 2175, "makespan": 88, "avg_agents_density": 0.1524399927349981, "runtime": 17.00954842660576}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-068"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.6458333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 4769, "makespan": 128, "avg_agents_density": 0.2851803683628039, "runtime": 24.54067640332505}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-069"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1585, "makespan": 59, "avg_agents_density": 0.1731998530602594, "runtime": 11.214316015597433}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-070"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1217, "makespan": 49, "avg_agents_density": 0.1444304219804375, "runtime": 9.765607006847858}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-071"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 870, "makespan": 32, "avg_agents_density": 0.10662727364387288, "runtime": 6.359868763945997}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-072"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1032, "makespan": 42, "avg_agents_density": 0.13099219388528494, "runtime": 8.409779368899763}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-073"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1614, "makespan": 55, "avg_agents_density": 0.17410619290126844, "runtime": 11.189390690997243}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-074"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 933, "makespan": 38, "avg_agents_density": 0.14506418896298806, "runtime": 7.263846536632627}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-075"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 1748, "makespan": 79, "avg_agents_density": 0.14876604370463808, "runtime": 15.552826720289886}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-076"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1405, "makespan": 55, "avg_agents_density": 0.16464807608880422, "runtime": 10.413216614630073}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-077"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1565, "makespan": 47, "avg_agents_density": 0.1683683668181213, "runtime": 9.239854954648763}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-078"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 999, "makespan": 38, "avg_agents_density": 0.14574587849381532, "runtime": 7.28384343534708}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-079"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 905, "makespan": 36, "avg_agents_density": 0.13285342598250843, "runtime": 7.171833633910865}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-080"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1157, "makespan": 45, "avg_agents_density": 0.15763696341796649, "runtime": 8.87280792137608}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-081"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1421, "makespan": 59, "avg_agents_density": 0.1324747090003114, "runtime": 11.496813961770386}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-082"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 1059, "makespan": 37, "avg_agents_density": 0.13209936727021346, "runtime": 5.989003161434084}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-083"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 109, "SoC": 2183, "makespan": 110, "avg_agents_density": 0.14836257901776462, "runtime": 20.553461695089936}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-084"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1412, "makespan": 56, "avg_agents_density": 0.16331493547763457, "runtime": 10.97564828209579}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-085"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 940, "makespan": 44, "avg_agents_density": 0.1095530067217669, "runtime": 8.469518178608268}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-086"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 111, "SoC": 1724, "makespan": 112, "avg_agents_density": 0.14590704626871576, "runtime": 21.17041686689481}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-087"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1314, "makespan": 51, "avg_agents_density": 0.17352001037295495, "runtime": 10.037888236809522}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-088"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 95, "SoC": 2236, "makespan": 96, "avg_agents_density": 0.15068955663043068, "runtime": 15.178609448485076}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-089"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 1476, "makespan": 83, "avg_agents_density": 0.16414870088934239, "runtime": 15.370496504474431}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-090"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.6041666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 4127, "makespan": 128, "avg_agents_density": 0.2538620532531178, "runtime": 24.620754197705537}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-091"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 916, "makespan": 46, "avg_agents_density": 0.13165681052189296, "runtime": 8.907244205940515}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-092"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1301, "makespan": 61, "avg_agents_density": 0.13728932356314608, "runtime": 10.5116802835837}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-093"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.9791666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 2287, "makespan": 128, "avg_agents_density": 0.17236235877042227, "runtime": 24.719180655665696}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-094"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 119, "SoC": 3199, "makespan": 120, "avg_agents_density": 0.17329897935605745, "runtime": 21.89324452029541}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-095"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 1570, "makespan": 74, "avg_agents_density": 0.13355260254484486, "runtime": 14.267877522390336}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-096"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1314, "makespan": 57, "avg_agents_density": 0.14945132315753973, "runtime": 10.858085384592414}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-097"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1665, "makespan": 63, "avg_agents_density": 0.16186554622376897, "runtime": 12.51954809203744}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-098"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1255, "makespan": 54, "avg_agents_density": 0.16540309763288044, "runtime": 10.373147598933429}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-099"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1369, "makespan": 45, "avg_agents_density": 0.15693577812765638, "runtime": 8.883996004238725}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-100"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 1085, "makespan": 37, "avg_agents_density": 0.141578836083842, "runtime": 6.995158056728542}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-101"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1090, "makespan": 40, "avg_agents_density": 0.1654586396881061, "runtime": 7.620813039131463}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-102"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 993, "makespan": 35, "avg_agents_density": 0.1443870620126706, "runtime": 7.004422809928656}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-103"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 1494, "makespan": 72, "avg_agents_density": 0.12358940115408197, "runtime": 13.347030811011791}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-104"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1516, "makespan": 52, "avg_agents_density": 0.17710283796532408, "runtime": 9.675657347310334}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-105"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1006, "makespan": 45, "avg_agents_density": 0.1228604611128555, "runtime": 8.663452149368823}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-106"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1092, "makespan": 39, "avg_agents_density": 0.1677080977754353, "runtime": 7.6271647764369845}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-107"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1084, "makespan": 50, "avg_agents_density": 0.15408887358364307, "runtime": 9.355053493753076}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-108"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1329, "makespan": 57, "avg_agents_density": 0.15268573298689153, "runtime": 10.645080328918993}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-109"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1171, "makespan": 50, "avg_agents_density": 0.13953549422336445, "runtime": 9.43692369479686}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-110"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 1100, "makespan": 38, "avg_agents_density": 0.1649597208314006, "runtime": 7.424793526530266}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-111"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1528, "makespan": 52, "avg_agents_density": 0.1888056849476069, "runtime": 9.89151171874255}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-112"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 894, "makespan": 36, "avg_agents_density": 0.16288461138856178, "runtime": 7.080016262829304}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-113"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 854, "makespan": 34, "avg_agents_density": 0.15544422004022151, "runtime": 6.563224494922906}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-114"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1376, "makespan": 58, "avg_agents_density": 0.16823741461157207, "runtime": 11.45103613100946}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-115"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 106, "SoC": 2359, "makespan": 107, "avg_agents_density": 0.17740740790540707, "runtime": 20.695014270953834}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-116"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1010, "makespan": 39, "avg_agents_density": 0.14459155957152448, "runtime": 7.790029250085354}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-117"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1211, "makespan": 52, "avg_agents_density": 0.1572542598049934, "runtime": 9.551686129998416}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-118"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1359, "makespan": 49, "avg_agents_density": 0.14339547692688392, "runtime": 9.053513729479164}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-119"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 930, "makespan": 38, "avg_agents_density": 0.12862387646600584, "runtime": 7.295321190264076}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-120"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1120, "makespan": 45, "avg_agents_density": 0.14184559650354675, "runtime": 8.497283809818327}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-121"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 1526, "makespan": 102, "avg_agents_density": 0.10565304093744536, "runtime": 19.34977604728192}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-122"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 992, "makespan": 47, "avg_agents_density": 0.14435141112156216, "runtime": 9.04563386598602}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-123"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 1744, "makespan": 74, "avg_agents_density": 0.14399351609899688, "runtime": 14.09116777870804}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-124"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1150, "makespan": 49, "avg_agents_density": 0.13478516118565836, "runtime": 9.285747539252043}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-125"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.7291666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 3558, "makespan": 128, "avg_agents_density": 0.23595355285124792, "runtime": 24.173001564107835}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-126"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 1022, "makespan": 37, "avg_agents_density": 0.15310563195010107, "runtime": 6.573388087563217}, "env_grid_search": {"num_agents": 48, "map_name": "validation-random-seed-127"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1653, "makespan": 49, "avg_agents_density": 0.16884337334585836, "runtime": 12.217747584916651}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-000"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 3689, "makespan": 100, "avg_agents_density": 0.23340680884506915, "runtime": 25.87233541160822}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-001"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1584, "makespan": 42, "avg_agents_density": 0.18081152432802317, "runtime": 10.013915846589953}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-002"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1745, "makespan": 52, "avg_agents_density": 0.1792052613138871, "runtime": 13.346726570278406}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-003"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 2404, "makespan": 95, "avg_agents_density": 0.1690521873499732, "runtime": 23.370525944046676}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-004"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 2063, "makespan": 60, "avg_agents_density": 0.1820180553553596, "runtime": 15.62353735929355}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-005"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1752, "makespan": 64, "avg_agents_density": 0.17780159881049193, "runtime": 15.941640479490161}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-006"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2505, "makespan": 71, "avg_agents_density": 0.21507209601226474, "runtime": 18.110374220181257}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-007"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.78125, "CSR": 0.0, "ep_length": 127, "SoC": 5353, "makespan": 128, "avg_agents_density": 0.22946179893810392, "runtime": 32.416035116650164}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-008"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 1196, "makespan": 34, "avg_agents_density": 0.17232781453999554, "runtime": 8.590587136335671}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-009"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1593, "makespan": 50, "avg_agents_density": 0.17197039707120085, "runtime": 12.833667371887714}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-010"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2447, "makespan": 68, "avg_agents_density": 0.2534812318309521, "runtime": 17.95046530244872}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-011"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 97, "SoC": 4037, "makespan": 98, "avg_agents_density": 0.2466562733789262, "runtime": 25.32302690623328}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-012"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 2522, "makespan": 78, "avg_agents_density": 0.17303425888854004, "runtime": 18.630639950279146}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-013"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1429, "makespan": 43, "avg_agents_density": 0.20020949873058294, "runtime": 11.206355435308069}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-014"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 127, "SoC": 4254, "makespan": 128, "avg_agents_density": 0.2139384302429702, "runtime": 32.11759241158143}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-015"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1602, "makespan": 47, "avg_agents_density": 0.19621220956255717, "runtime": 11.902780242729932}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-016"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1555, "makespan": 48, "avg_agents_density": 0.1550190495819994, "runtime": 12.923615153878927}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-017"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 2538, "makespan": 78, "avg_agents_density": 0.20076054243446936, "runtime": 19.990020273718983}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-018"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 4577, "makespan": 128, "avg_agents_density": 0.23145624875623994, "runtime": 32.662561643868685}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-019"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1796, "makespan": 55, "avg_agents_density": 0.1864808268109707, "runtime": 14.203675443306565}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-020"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 2012, "makespan": 60, "avg_agents_density": 0.19886923985561764, "runtime": 15.098013807088137}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-021"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1663, "makespan": 46, "avg_agents_density": 0.2037457460888326, "runtime": 11.883528107777238}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-022"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 2256, "makespan": 67, "avg_agents_density": 0.22299813927721673, "runtime": 18.109570405911654}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-023"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 2265, "makespan": 56, "avg_agents_density": 0.19638328956295906, "runtime": 14.43684529978782}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-024"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1502, "makespan": 51, "avg_agents_density": 0.1835066030626676, "runtime": 13.0083905919455}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-025"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1787, "makespan": 73, "avg_agents_density": 0.15687504644298805, "runtime": 18.615571750793606}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-026"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1812, "makespan": 48, "avg_agents_density": 0.21037446364971482, "runtime": 12.454316615127027}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-027"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 2396, "makespan": 59, "avg_agents_density": 0.18464232805335198, "runtime": 15.006365096662194}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-028"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1973, "makespan": 55, "avg_agents_density": 0.20607617605763634, "runtime": 14.697657257318497}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-029"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 2158, "makespan": 63, "avg_agents_density": 0.20625704160784755, "runtime": 15.864716231822968}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-030"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1538, "makespan": 41, "avg_agents_density": 0.16521722942941924, "runtime": 11.135150441434234}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-031"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 2794, "makespan": 94, "avg_agents_density": 0.21471891815950195, "runtime": 24.384674589149654}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-032"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 2077, "makespan": 80, "avg_agents_density": 0.17181213057072023, "runtime": 20.530751092359424}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-033"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.453125, "CSR": 0.0, "ep_length": 127, "SoC": 6680, "makespan": 128, "avg_agents_density": 0.33814683624583985, "runtime": 33.27130060410127}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-034"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 2480, "makespan": 65, "avg_agents_density": 0.24917792854784745, "runtime": 16.923399980179965}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-035"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2102, "makespan": 68, "avg_agents_density": 0.2296331302043447, "runtime": 17.098490091972053}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-036"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 2989, "makespan": 128, "avg_agents_density": 0.18392883802084817, "runtime": 33.04234279645607}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-037"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1475, "makespan": 43, "avg_agents_density": 0.1846005091195823, "runtime": 11.3192946924828}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-038"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2006, "makespan": 71, "avg_agents_density": 0.16483175748620466, "runtime": 17.437959713395685}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-039"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 97, "SoC": 2475, "makespan": 98, "avg_agents_density": 0.19974801603648273, "runtime": 24.818311469629407}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-040"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 2901, "makespan": 103, "avg_agents_density": 0.18203198621908834, "runtime": 26.73457213724032}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-041"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 2282, "makespan": 63, "avg_agents_density": 0.21192587212512287, "runtime": 16.59594921534881}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-042"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 1869, "makespan": 81, "avg_agents_density": 0.17151536355538324, "runtime": 20.874674652237445}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-043"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1779, "makespan": 52, "avg_agents_density": 0.19433877020506415, "runtime": 13.29265412548557}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-044"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 112, "SoC": 2019, "makespan": 113, "avg_agents_density": 0.1604655987682869, "runtime": 28.778722133953124}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-045"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1533, "makespan": 46, "avg_agents_density": 0.16151542367740007, "runtime": 11.735684972256422}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-046"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 4442, "makespan": 128, "avg_agents_density": 0.24588544203505555, "runtime": 32.74151919130236}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-047"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 95, "SoC": 3316, "makespan": 96, "avg_agents_density": 0.2269628239804627, "runtime": 23.057926550973207}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-048"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 2514, "makespan": 77, "avg_agents_density": 0.21376477833894933, "runtime": 20.007298910990357}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-049"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 3436, "makespan": 100, "avg_agents_density": 0.19444667998185464, "runtime": 26.036817378364503}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-050"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1768, "makespan": 52, "avg_agents_density": 0.1877909680484211, "runtime": 13.400641029234976}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-051"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 2213, "makespan": 71, "avg_agents_density": 0.18330742695491978, "runtime": 18.901547139510512}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-052"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 119, "SoC": 4270, "makespan": 120, "avg_agents_density": 0.2555573483798037, "runtime": 30.964203799609095}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-053"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 2058, "makespan": 58, "avg_agents_density": 0.2088560102013101, "runtime": 15.290114019531757}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-054"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.796875, "CSR": 0.0, "ep_length": 127, "SoC": 3919, "makespan": 128, "avg_agents_density": 0.20152116168541584, "runtime": 32.9777489034459}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-055"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 1336, "makespan": 38, "avg_agents_density": 0.17347923498845597, "runtime": 9.557187986560166}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-056"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1833, "makespan": 55, "avg_agents_density": 0.19062633218765418, "runtime": 14.621054510120302}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-057"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 127, "SoC": 5733, "makespan": 128, "avg_agents_density": 0.306910678617438, "runtime": 33.312297138385475}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-058"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 2651, "makespan": 70, "avg_agents_density": 0.18436132959244358, "runtime": 18.283855734393}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-059"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1488, "makespan": 43, "avg_agents_density": 0.2146689323571627, "runtime": 11.070352234411985}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-060"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 90, "SoC": 3331, "makespan": 91, "avg_agents_density": 0.24880922216550505, "runtime": 23.84762249700725}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-061"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 3560, "makespan": 102, "avg_agents_density": 0.19349624833451617, "runtime": 26.005717223044485}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-062"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 3273, "makespan": 92, "avg_agents_density": 0.21496809295186603, "runtime": 23.888368726707995}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-063"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1679, "makespan": 45, "avg_agents_density": 0.19100585614666848, "runtime": 11.843267659191042}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-064"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 2362, "makespan": 74, "avg_agents_density": 0.2229723753659745, "runtime": 19.019279774744064}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-065"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 2713, "makespan": 128, "avg_agents_density": 0.1636431759758682, "runtime": 31.61129803583026}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-066"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1435, "makespan": 44, "avg_agents_density": 0.17666178322955753, "runtime": 11.945859273895621}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-067"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 117, "SoC": 5031, "makespan": 118, "avg_agents_density": 0.22136435194303392, "runtime": 30.639252268709242}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-068"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.359375, "CSR": 0.0, "ep_length": 127, "SoC": 6348, "makespan": 128, "avg_agents_density": 0.3677330056071675, "runtime": 33.178393580019474}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-069"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 116, "SoC": 3941, "makespan": 117, "avg_agents_density": 0.22639970582382982, "runtime": 29.192337253596634}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-070"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 2358, "makespan": 74, "avg_agents_density": 0.1925211604439588, "runtime": 19.16231289645657}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-071"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1300, "makespan": 40, "avg_agents_density": 0.1365393710749152, "runtime": 10.801905416883528}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-072"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1620, "makespan": 52, "avg_agents_density": 0.16750996785559288, "runtime": 13.724747677799314}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-073"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 127, "SoC": 3441, "makespan": 128, "avg_agents_density": 0.1953928708028645, "runtime": 32.09595207776874}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-074"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1486, "makespan": 43, "avg_agents_density": 0.1830326962125273, "runtime": 10.868352863006294}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-075"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 2896, "makespan": 79, "avg_agents_density": 0.20622903896918152, "runtime": 19.996296611614525}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-076"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 3110, "makespan": 87, "avg_agents_density": 0.22737962268648565, "runtime": 22.793681348674}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-077"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 99, "SoC": 3837, "makespan": 100, "avg_agents_density": 0.23564132898966247, "runtime": 25.617575442418456}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-078"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 1465, "makespan": 38, "avg_agents_density": 0.1856341382589958, "runtime": 9.820171392057091}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-079"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1548, "makespan": 43, "avg_agents_density": 0.18373678133416488, "runtime": 11.096599235665053}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-080"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 2134, "makespan": 65, "avg_agents_density": 0.2112575241480115, "runtime": 16.68544994853437}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-081"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 3226, "makespan": 85, "avg_agents_density": 0.16803203519443555, "runtime": 22.224993446841836}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-082"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1473, "makespan": 39, "avg_agents_density": 0.17270033993014552, "runtime": 10.547718300949782}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-083"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 127, "SoC": 4473, "makespan": 128, "avg_agents_density": 0.22989115213394962, "runtime": 33.06748195877299}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-084"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 117, "SoC": 3423, "makespan": 118, "avg_agents_density": 0.20056476290527497, "runtime": 28.972199818119407}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-085"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1214, "makespan": 41, "avg_agents_density": 0.14419300899304288, "runtime": 10.842547905631363}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-086"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 115, "SoC": 3820, "makespan": 116, "avg_agents_density": 0.22815094739082795, "runtime": 28.971010038629174}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-087"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 95, "SoC": 2855, "makespan": 96, "avg_agents_density": 0.22048658740173893, "runtime": 24.558583707083017}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-088"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 125, "SoC": 3887, "makespan": 126, "avg_agents_density": 0.20488604825505644, "runtime": 31.68002786161378}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-089"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 116, "SoC": 2970, "makespan": 117, "avg_agents_density": 0.20703675035159105, "runtime": 28.716537446714938}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-090"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.5, "CSR": 0.0, "ep_length": 127, "SoC": 5170, "makespan": 128, "avg_agents_density": 0.3141281744199618, "runtime": 32.355198805220425}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-091"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1513, "makespan": 62, "avg_agents_density": 0.171357020963172, "runtime": 14.566473679617047}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-092"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 2005, "makespan": 59, "avg_agents_density": 0.1803299919535689, "runtime": 14.99421599181369}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-093"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.5625, "CSR": 0.0, "ep_length": 127, "SoC": 5353, "makespan": 128, "avg_agents_density": 0.3013823420933264, "runtime": 33.65059130033478}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-094"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.34375, "CSR": 0.0, "ep_length": 127, "SoC": 6705, "makespan": 128, "avg_agents_density": 0.35818024793266817, "runtime": 33.42666722042486}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-095"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 3530, "makespan": 128, "avg_agents_density": 0.18508828847448935, "runtime": 33.11590954149142}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-096"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1908, "makespan": 59, "avg_agents_density": 0.1967839648125302, "runtime": 14.43905340693891}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-097"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.78125, "CSR": 0.0, "ep_length": 127, "SoC": 4456, "makespan": 128, "avg_agents_density": 0.23748347799363878, "runtime": 32.551476831082255}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-098"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 2616, "makespan": 92, "avg_agents_density": 0.20777134105612988, "runtime": 23.155344842467457}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-099"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 88, "SoC": 2577, "makespan": 89, "avg_agents_density": 0.19203908476549716, "runtime": 22.70470890821889}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-100"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1854, "makespan": 68, "avg_agents_density": 0.18722198929255895, "runtime": 17.34998488612473}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-101"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 2792, "makespan": 85, "avg_agents_density": 0.22828012107689605, "runtime": 22.453049707226455}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-102"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1673, "makespan": 67, "avg_agents_density": 0.1850165741822877, "runtime": 16.230775620788336}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-103"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 2922, "makespan": 83, "avg_agents_density": 0.18495293844282149, "runtime": 20.97526667965576}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-104"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.78125, "CSR": 0.0, "ep_length": 127, "SoC": 4738, "makespan": 128, "avg_agents_density": 0.24941277240377863, "runtime": 32.43628648342565}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-105"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1430, "makespan": 41, "avg_agents_density": 0.16351501484221784, "runtime": 10.790066150482744}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-106"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 2136, "makespan": 54, "avg_agents_density": 0.22502380749059678, "runtime": 14.086005263030529}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-107"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 2514, "makespan": 84, "avg_agents_density": 0.21530551387223265, "runtime": 21.919790929649025}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-108"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 111, "SoC": 3619, "makespan": 112, "avg_agents_density": 0.22244272047983923, "runtime": 27.863867938518524}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-109"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 104, "SoC": 2410, "makespan": 105, "avg_agents_density": 0.17197199100180055, "runtime": 26.449687275569886}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-110"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2293, "makespan": 68, "avg_agents_density": 0.2118381459699306, "runtime": 17.228975837584585}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-111"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.765625, "CSR": 0.0, "ep_length": 127, "SoC": 4628, "makespan": 128, "avg_agents_density": 0.24756327184846105, "runtime": 32.9316130252555}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-112"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1547, "makespan": 42, "avg_agents_density": 0.21263120017880915, "runtime": 10.867993793915957}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-113"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1383, "makespan": 39, "avg_agents_density": 0.20702135363185836, "runtime": 10.162694275379181}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-114"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1965, "makespan": 59, "avg_agents_density": 0.2067983040000068, "runtime": 15.834719898644835}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-115"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 127, "SoC": 4787, "makespan": 128, "avg_agents_density": 0.26663099220217074, "runtime": 32.430772612802684}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-116"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1589, "makespan": 42, "avg_agents_density": 0.1797890159059986, "runtime": 11.28091630525887}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-117"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 88, "SoC": 2839, "makespan": 89, "avg_agents_density": 0.20213237900071948, "runtime": 22.736878677271307}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-118"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 2543, "makespan": 70, "avg_agents_density": 0.19318716962155946, "runtime": 18.30748381698504}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-119"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 1362, "makespan": 35, "avg_agents_density": 0.1827359429060233, "runtime": 8.734520947095007}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-120"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1705, "makespan": 49, "avg_agents_density": 0.18290236168886362, "runtime": 12.797867770772427}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-121"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1686, "makespan": 54, "avg_agents_density": 0.14589285133063218, "runtime": 13.677468209527433}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-122"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1591, "makespan": 43, "avg_agents_density": 0.19751887478347, "runtime": 11.225190551951528}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-123"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 126, "SoC": 4485, "makespan": 127, "avg_agents_density": 0.22441941779091173, "runtime": 32.67540813330561}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-124"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 127, "SoC": 2584, "makespan": 128, "avg_agents_density": 0.16407155705606102, "runtime": 31.813044520560652}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-125"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 0.640625, "CSR": 0.0, "ep_length": 127, "SoC": 6100, "makespan": 128, "avg_agents_density": 0.31886966404481554, "runtime": 33.290773532819}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-126"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1608, "makespan": 42, "avg_agents_density": 0.20440978885369374, "runtime": 11.14870660752058}, "env_grid_search": {"num_agents": 64, "map_name": "validation-random-seed-127"}, "algorithm": "MAPF-GPT-6M-multiaction-predictaction-2actions"}]