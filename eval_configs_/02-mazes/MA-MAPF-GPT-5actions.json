[{"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 148, "makespan": 24, "avg_agents_density": 0.027806724274969833, "runtime": 0.4140647021122277}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-000"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 158, "makespan": 32, "avg_agents_density": 0.03981445817241464, "runtime": 1.0731073329225183}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-001"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 99, "makespan": 27, "avg_agents_density": 0.02834222004026179, "runtime": 0.7339356001466513}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-002"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 131, "makespan": 24, "avg_agents_density": 0.033798890565440304, "runtime": 0.607635133434087}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-003"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 219, "makespan": 51, "avg_agents_density": 0.027142776121208943, "runtime": 0.43351979786530137}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-004"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 181, "makespan": 26, "avg_agents_density": 0.03909662088049865, "runtime": 0.9792290753684938}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-005"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 137, "makespan": 31, "avg_agents_density": 0.031167698169473908, "runtime": 0.87405487569049}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-006"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 159, "makespan": 28, "avg_agents_density": 0.03233796234735758, "runtime": 0.714760163333267}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-007"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 150, "makespan": 34, "avg_agents_density": 0.04275868878093222, "runtime": 0.2924633049406111}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-008"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 123, "makespan": 29, "avg_agents_density": 0.03245862837164274, "runtime": 0.9635262838564813}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-009"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 204, "makespan": 31, "avg_agents_density": 0.0300374830838911, "runtime": 0.8686322239227593}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-010"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 125, "makespan": 26, "avg_agents_density": 0.05187476751706047, "runtime": 0.6574168233200908}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-011"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 17, "SoC": 113, "makespan": 18, "avg_agents_density": 0.028187064914710118, "runtime": 0.15429914370179176}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-012"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 15, "SoC": 100, "makespan": 16, "avg_agents_density": 0.040946634984989266, "runtime": 0.595309232827276}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-013"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 134, "makespan": 28, "avg_agents_density": 0.04654955634992913, "runtime": 0.7191929402761161}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-014"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 204, "makespan": 36, "avg_agents_density": 0.023412494092187378, "runtime": 0.9557707305066288}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-015"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 131, "makespan": 35, "avg_agents_density": 0.031832127223901385, "runtime": 0.2968815597705543}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-016"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 171, "makespan": 33, "avg_agents_density": 0.03504252857424363, "runtime": 1.185994319152087}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-017"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 175, "makespan": 30, "avg_agents_density": 0.03750390293665237, "runtime": 1.0621186392381787}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-018"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 137, "makespan": 32, "avg_agents_density": 0.031220792039331795, "runtime": 0.8229625895619392}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-019"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 151, "makespan": 26, "avg_agents_density": 0.026460230895966833, "runtime": 0.7235215744003654}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-020"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 142, "makespan": 30, "avg_agents_density": 0.031741610660572336, "runtime": 0.25951957097277045}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-021"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 125, "makespan": 25, "avg_agents_density": 0.03319942134273349, "runtime": 0.8698009815998375}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-022"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 151, "makespan": 27, "avg_agents_density": 0.04946845850907403, "runtime": 0.7578002172522247}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-023"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 167, "makespan": 39, "avg_agents_density": 0.02841206835726486, "runtime": 1.1057239179499447}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-024"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 15, "SoC": 82, "makespan": 16, "avg_agents_density": 0.029105472273224936, "runtime": 0.13725886214524508}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-025"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 145, "makespan": 28, "avg_agents_density": 0.03468564824838092, "runtime": 0.9112724410369992}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-026"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 140, "makespan": 26, "avg_agents_density": 0.03299057323613941, "runtime": 0.7822248972952366}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-027"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 148, "makespan": 26, "avg_agents_density": 0.02579756279317533, "runtime": 0.6580239627510309}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-028"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 143, "makespan": 25, "avg_agents_density": 0.030784965496103114, "runtime": 0.21702882694080472}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-029"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 157, "makespan": 32, "avg_agents_density": 0.03829372711182772, "runtime": 0.8020041338168085}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-030"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 109, "makespan": 23, "avg_agents_density": 0.037291290400170714, "runtime": 0.5951983146369457}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-031"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 142, "makespan": 30, "avg_agents_density": 0.03234900974791845, "runtime": 0.7375052021816373}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-032"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 200, "makespan": 38, "avg_agents_density": 0.044069309297141125, "runtime": 0.9553534933365881}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-033"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 139, "makespan": 28, "avg_agents_density": 0.05558371285372278, "runtime": 0.48083010502159595}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-034"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 127, "makespan": 24, "avg_agents_density": 0.029524765325256257, "runtime": 0.7779441894963384}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-035"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 116, "makespan": 21, "avg_agents_density": 0.030958469166313698, "runtime": 0.3556175692938268}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-036"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 144, "makespan": 26, "avg_agents_density": 0.03878407626219468, "runtime": 0.6578705864958465}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-037"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 112, "makespan": 32, "avg_agents_density": 0.043274613196602085, "runtime": 0.8466264079324901}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-038"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 158, "makespan": 28, "avg_agents_density": 0.03161598808974148, "runtime": 0.9367650845088065}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-039"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 222, "makespan": 44, "avg_agents_density": 0.03347011928676286, "runtime": 1.1250880118459463}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-040"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 149, "makespan": 29, "avg_agents_density": 0.04649916270618891, "runtime": 0.7247949494048953}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-041"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 144, "makespan": 31, "avg_agents_density": 0.03499800138184703, "runtime": 0.8120637098327279}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-042"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 123, "makespan": 33, "avg_agents_density": 0.021772139044486244, "runtime": 1.1050380761735141}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-043"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 144, "makespan": 30, "avg_agents_density": 0.026654817943191567, "runtime": 0.508582784794271}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-044"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 157, "makespan": 32, "avg_agents_density": 0.025694341838252404, "runtime": 0.5308975162915885}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-045"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 168, "makespan": 34, "avg_agents_density": 0.03169586082564784, "runtime": 0.924625021405518}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-046"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 133, "makespan": 30, "avg_agents_density": 0.03563199964937065, "runtime": 0.9059604741632938}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-047"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 17, "SoC": 93, "makespan": 18, "avg_agents_density": 0.02815198634868274, "runtime": 0.3993256725370884}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-048"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 19, "SoC": 119, "makespan": 20, "avg_agents_density": 0.05110297582018643, "runtime": 0.4671260635368526}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-049"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 179, "makespan": 30, "avg_agents_density": 0.03727605794381733, "runtime": 1.1893904856406152}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-050"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 149, "makespan": 30, "avg_agents_density": 0.03050164589731986, "runtime": 0.7740793572738767}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-051"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 119, "makespan": 32, "avg_agents_density": 0.02206922623010023, "runtime": 1.029154579155147}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-052"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 213, "makespan": 48, "avg_agents_density": 0.036391870762308966, "runtime": 1.06104954238981}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-053"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 127, "makespan": 28, "avg_agents_density": 0.026784582506326954, "runtime": 0.4649379621259868}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-054"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 126, "makespan": 28, "avg_agents_density": 0.02788443798501582, "runtime": 0.9744245312176645}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-055"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 160, "makespan": 32, "avg_agents_density": 0.028736599847122044, "runtime": 0.9036180931143463}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-056"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 162, "makespan": 37, "avg_agents_density": 0.03050104703513811, "runtime": 0.9799564839340746}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-057"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 165, "makespan": 35, "avg_agents_density": 0.041047962377456865, "runtime": 0.38566283136606216}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-058"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 150, "makespan": 30, "avg_agents_density": 0.02982703558996145, "runtime": 1.0560236764140427}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-059"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 112, "makespan": 25, "avg_agents_density": 0.026738968822631642, "runtime": 0.6660591480322182}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-060"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 143, "makespan": 28, "avg_agents_density": 0.031068058828581494, "runtime": 0.23908039461821318}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-061"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 190, "makespan": 44, "avg_agents_density": 0.028047539436828948, "runtime": 1.4322719969786704}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-062"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 224, "makespan": 56, "avg_agents_density": 0.0338027241992465, "runtime": 0.46900720754638314}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-063"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 147, "makespan": 33, "avg_agents_density": 0.05419162706938445, "runtime": 0.9135638256557286}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-064"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 20, "SoC": 136, "makespan": 21, "avg_agents_density": 0.04809603284390082, "runtime": 0.17852484248578548}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-065"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 155, "makespan": 28, "avg_agents_density": 0.025509243821186814, "runtime": 0.4994317898526788}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-066"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 134, "makespan": 36, "avg_agents_density": 0.032875023361152035, "runtime": 0.8580861915834248}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-067"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 129, "makespan": 31, "avg_agents_density": 0.0268854161998019, "runtime": 0.2608933071605861}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-068"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 176, "makespan": 49, "avg_agents_density": 0.03526873638191368, "runtime": 1.6341105406172574}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-069"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 155, "makespan": 28, "avg_agents_density": 0.046007819331260774, "runtime": 0.5185359944589436}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-070"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 182, "makespan": 42, "avg_agents_density": 0.037454524665233246, "runtime": 1.0939514408819377}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-071"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 109, "makespan": 23, "avg_agents_density": 0.027107741279507134, "runtime": 0.20183602394536138}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-072"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 134, "makespan": 34, "avg_agents_density": 0.04351050185529771, "runtime": 1.169215516652912}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-073"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 149, "makespan": 29, "avg_agents_density": 0.04288890950762376, "runtime": 0.4905440299771726}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-074"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 151, "makespan": 36, "avg_agents_density": 0.027971801922042943, "runtime": 0.9950162987224758}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-075"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 120, "makespan": 36, "avg_agents_density": 0.0376605524502452, "runtime": 0.3064866713248193}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-076"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 142, "makespan": 23, "avg_agents_density": 0.03364636595174127, "runtime": 0.7767110355198383}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-077"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 146, "makespan": 24, "avg_agents_density": 0.03860768354128254, "runtime": 0.41092066280543804}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-078"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 110, "makespan": 19, "avg_agents_density": 0.03292053723734634, "runtime": 0.7027095127850771}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-079"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 115, "makespan": 23, "avg_agents_density": 0.02478392524393948, "runtime": 0.6674045994877815}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-080"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 137, "makespan": 30, "avg_agents_density": 0.028833548749568932, "runtime": 1.0349016413092613}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-081"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 129, "makespan": 34, "avg_agents_density": 0.03239358447402556, "runtime": 0.5739077520556748}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-082"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 80, "makespan": 24, "avg_agents_density": 0.02254747728049248, "runtime": 0.600015991833061}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-083"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 186, "makespan": 34, "avg_agents_density": 0.03470430589282985, "runtime": 0.28835146175697446}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-084"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 224, "makespan": 51, "avg_agents_density": 0.03660274418364637, "runtime": 1.7559087430126965}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-085"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 119, "makespan": 26, "avg_agents_density": 0.03491452911189753, "runtime": 0.3201506887562573}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-086"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 153, "makespan": 35, "avg_agents_density": 0.02912201522989715, "runtime": 0.9700414715334773}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-087"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 132, "makespan": 38, "avg_agents_density": 0.02860520906869918, "runtime": 0.32168660312891006}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-088"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 109, "makespan": 22, "avg_agents_density": 0.03215895024098764, "runtime": 0.751214409712702}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-089"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 199, "makespan": 31, "avg_agents_density": 0.034523326055121234, "runtime": 0.5371316047385335}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-090"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 134, "makespan": 28, "avg_agents_density": 0.04646216460425243, "runtime": 0.7250958974473178}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-091"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 98, "makespan": 23, "avg_agents_density": 0.026656755872587822, "runtime": 0.3307472220622003}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-092"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 139, "makespan": 31, "avg_agents_density": 0.03463198363967105, "runtime": 1.0271776686422527}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-093"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 191, "makespan": 34, "avg_agents_density": 0.039821591835409904, "runtime": 0.2867126688361168}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-094"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 142, "makespan": 23, "avg_agents_density": 0.038500125854395044, "runtime": 0.6084985206834972}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-095"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 134, "makespan": 27, "avg_agents_density": 0.030902277122021517, "runtime": 0.2337089334614575}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-096"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 158, "makespan": 42, "avg_agents_density": 0.030859293203781963, "runtime": 1.174575929529965}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-097"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 157, "makespan": 48, "avg_agents_density": 0.032443522907771034, "runtime": 0.8029565652832389}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-098"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 129, "makespan": 27, "avg_agents_density": 0.03365593892359051, "runtime": 0.9592984234914184}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-099"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 115, "makespan": 24, "avg_agents_density": 0.03593960111035015, "runtime": 0.7528670178726315}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-100"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 116, "makespan": 30, "avg_agents_density": 0.03151803575425089, "runtime": 0.7952174465171993}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-101"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 150, "makespan": 29, "avg_agents_density": 0.037257143049514684, "runtime": 0.24939734255895019}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-102"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 91, "makespan": 19, "avg_agents_density": 0.03280670058390299, "runtime": 0.7106305831111968}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-103"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 223, "makespan": 35, "avg_agents_density": 0.032498579587825045, "runtime": 0.9488674774765968}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-104"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 235, "makespan": 38, "avg_agents_density": 0.028104965916714325, "runtime": 1.024567156098783}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-105"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 19, "SoC": 112, "makespan": 20, "avg_agents_density": 0.02609903154037129, "runtime": 0.173444417770952}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-106"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 144, "makespan": 35, "avg_agents_density": 0.03178130241015766, "runtime": 1.2652206979691982}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-107"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 150, "makespan": 35, "avg_agents_density": 0.03332582599890269, "runtime": 0.9840195751748979}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-108"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 139, "makespan": 31, "avg_agents_density": 0.03643703875101746, "runtime": 0.8776832120493054}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-109"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 182, "makespan": 35, "avg_agents_density": 0.044131120679950134, "runtime": 0.29832471488043666}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-110"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 114, "makespan": 25, "avg_agents_density": 0.041639485865928506, "runtime": 0.9512290093116462}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-111"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 117, "makespan": 25, "avg_agents_density": 0.03329241501475248, "runtime": 0.714698348660022}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-112"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 132, "makespan": 26, "avg_agents_density": 0.03057091796776608, "runtime": 0.7299596043303609}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-113"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 128, "makespan": 26, "avg_agents_density": 0.029259355624275264, "runtime": 0.225608023814857}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-114"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 117, "makespan": 24, "avg_agents_density": 0.04156100432005624, "runtime": 0.8181069251149893}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-115"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 167, "makespan": 30, "avg_agents_density": 0.037188495783748075, "runtime": 0.7399646393023431}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-116"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 117, "makespan": 26, "avg_agents_density": 0.031190637659135663, "runtime": 0.6612031240947545}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-117"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 116, "makespan": 27, "avg_agents_density": 0.031746143044744, "runtime": 0.2311713364906609}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-118"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 133, "makespan": 26, "avg_agents_density": 0.031048326840273283, "runtime": 0.9126349273137748}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-119"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 107, "makespan": 27, "avg_agents_density": 0.02271900612071517, "runtime": 0.7710429457947612}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-120"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 204, "makespan": 38, "avg_agents_density": 0.03836275649897157, "runtime": 1.0449707130901515}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-121"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 160, "makespan": 41, "avg_agents_density": 0.028444515623380868, "runtime": 0.34732737578451633}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-122"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 110, "makespan": 22, "avg_agents_density": 0.03065528469106159, "runtime": 0.8636666270904243}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-123"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 300, "makespan": 50, "avg_agents_density": 0.03983193573678442, "runtime": 1.0779546089470387}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-124"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 18, "SoC": 117, "makespan": 19, "avg_agents_density": 0.03198240776213653, "runtime": 0.705277900211513}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-125"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 312, "makespan": 67, "avg_agents_density": 0.03384199797000933, "runtime": 0.5614241384901106}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-126"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 21, "SoC": 127, "makespan": 22, "avg_agents_density": 0.03007434379346178, "runtime": 0.8185358997434378}, "env_grid_search": {"num_agents": 8, "map_name": "validation-mazes-seed-127"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 300, "makespan": 35, "avg_agents_density": 0.05344056352384082, "runtime": 2.280467140953988}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-000"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 284, "makespan": 33, "avg_agents_density": 0.061526419778141814, "runtime": 1.7505601015873253}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-001"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 345, "makespan": 40, "avg_agents_density": 0.047124818014388066, "runtime": 2.5490674041211605}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-002"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 265, "makespan": 26, "avg_agents_density": 0.07133180694365102, "runtime": 1.8146468102931976}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-003"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 442, "makespan": 44, "avg_agents_density": 0.05346524820870232, "runtime": 2.902787745464593}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-004"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 449, "makespan": 43, "avg_agents_density": 0.0610646426268957, "runtime": 2.6936929714865983}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-005"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 314, "makespan": 33, "avg_agents_density": 0.04942328653933337, "runtime": 2.101767143700272}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-006"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 86, "SoC": 570, "makespan": 87, "avg_agents_density": 0.04817660009380253, "runtime": 5.60839979397133}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-007"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 367, "makespan": 37, "avg_agents_density": 0.060538248236903285, "runtime": 2.432964213192463}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-008"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 267, "makespan": 32, "avg_agents_density": 0.06059339405830044, "runtime": 1.668690176680684}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-009"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 345, "makespan": 36, "avg_agents_density": 0.041587248831629106, "runtime": 2.5907421028241515}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-010"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 352, "makespan": 44, "avg_agents_density": 0.09148372693815333, "runtime": 2.809993764385581}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-011"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 305, "makespan": 36, "avg_agents_density": 0.05729263985719641, "runtime": 2.3151087537407875}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-012"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 227, "makespan": 26, "avg_agents_density": 0.060443829174677124, "runtime": 1.6539842411875725}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-013"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 328, "makespan": 34, "avg_agents_density": 0.06572241613894711, "runtime": 2.1708061369135976}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-014"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 333, "makespan": 39, "avg_agents_density": 0.045728482134727785, "runtime": 2.5113887558691204}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-015"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 365, "makespan": 52, "avg_agents_density": 0.05079988026153796, "runtime": 2.808428199030459}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-016"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 282, "makespan": 40, "avg_agents_density": 0.05070077484581204, "runtime": 2.4508101199753582}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-017"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 359, "makespan": 34, "avg_agents_density": 0.0599617733325846, "runtime": 2.114498556125909}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-018"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 333, "makespan": 28, "avg_agents_density": 0.06455874180581377, "runtime": 1.9427467049099505}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-019"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 350, "makespan": 34, "avg_agents_density": 0.05436285435390465, "runtime": 1.640004972461611}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-020"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 350, "makespan": 42, "avg_agents_density": 0.06776767647963287, "runtime": 2.701228782068938}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-021"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 305, "makespan": 32, "avg_agents_density": 0.04878260323502897, "runtime": 2.1326869861222804}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-022"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 330, "makespan": 31, "avg_agents_density": 0.07225036515604794, "runtime": 2.0191758922301233}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-023"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 330, "makespan": 41, "avg_agents_density": 0.06599926128058155, "runtime": 1.9384288019500673}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-024"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 199, "makespan": 27, "avg_agents_density": 0.04567362242501838, "runtime": 1.9020310384221375}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-025"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 318, "makespan": 31, "avg_agents_density": 0.048264365525102604, "runtime": 2.0138539387844503}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-026"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 366, "makespan": 38, "avg_agents_density": 0.05384092426017173, "runtime": 2.448681280016899}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-027"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 400, "makespan": 39, "avg_agents_density": 0.05331989398448115, "runtime": 1.8477315274067223}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-028"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 289, "makespan": 27, "avg_agents_density": 0.053856144477796054, "runtime": 1.7560135405510664}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-029"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 300, "makespan": 27, "avg_agents_density": 0.06742620937133867, "runtime": 1.9007663768716156}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-030"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 232, "makespan": 23, "avg_agents_density": 0.059997602640986296, "runtime": 1.5276187686249614}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-031"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 331, "makespan": 38, "avg_agents_density": 0.055466303152712136, "runtime": 2.502640448976308}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-032"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 471, "makespan": 41, "avg_agents_density": 0.0769256449449182, "runtime": 2.778915051370859}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-033"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 323, "makespan": 37, "avg_agents_density": 0.093392147369528, "runtime": 2.3650852032005787}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-034"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 301, "makespan": 34, "avg_agents_density": 0.05998352045796251, "runtime": 2.1140769734047353}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-035"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 297, "makespan": 30, "avg_agents_density": 0.052273419346869784, "runtime": 1.9075718228705227}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-036"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 322, "makespan": 34, "avg_agents_density": 0.06861256383547708, "runtime": 2.1373157701455057}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-037"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 323, "makespan": 54, "avg_agents_density": 0.05802040239473912, "runtime": 3.305358285084367}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-038"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 424, "makespan": 40, "avg_agents_density": 0.06191184875981152, "runtime": 2.705707303714007}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-039"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 487, "makespan": 47, "avg_agents_density": 0.06272438835570585, "runtime": 2.8580482276156545}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-040"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 506, "makespan": 47, "avg_agents_density": 0.05809401944614826, "runtime": 3.3902886058203876}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-041"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 352, "makespan": 36, "avg_agents_density": 0.0723023008570172, "runtime": 2.5458742873743176}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-042"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 212, "makespan": 29, "avg_agents_density": 0.03494391012334654, "runtime": 1.7427210467867553}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-043"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 264, "makespan": 34, "avg_agents_density": 0.05413743127268409, "runtime": 2.188522564712912}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-044"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 471, "makespan": 58, "avg_agents_density": 0.05552810045740463, "runtime": 3.6686913445591927}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-045"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 359, "makespan": 34, "avg_agents_density": 0.0536441393137516, "runtime": 2.1622633999213576}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-046"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 310, "makespan": 30, "avg_agents_density": 0.06387184421300314, "runtime": 2.117180810775608}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-047"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 229, "makespan": 33, "avg_agents_density": 0.054540649726007064, "runtime": 2.1598612554371357}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-048"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 332, "makespan": 39, "avg_agents_density": 0.0753390772604414, "runtime": 2.2848650021478534}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-049"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 472, "makespan": 57, "avg_agents_density": 0.06392351226334718, "runtime": 3.6958397063426673}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-050"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 303, "makespan": 34, "avg_agents_density": 0.056393466902638315, "runtime": 2.154747575055808}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-051"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 278, "makespan": 38, "avg_agents_density": 0.05478528218887712, "runtime": 2.200678011868149}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-052"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 570, "makespan": 63, "avg_agents_density": 0.07991560095136942, "runtime": 4.061696182470769}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-053"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 326, "makespan": 32, "avg_agents_density": 0.05023609417655844, "runtime": 2.2092509432695806}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-054"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 397, "makespan": 48, "avg_agents_density": 0.055684224896139875, "runtime": 3.15446514217183}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-055"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 424, "makespan": 46, "avg_agents_density": 0.04030734912094841, "runtime": 3.3119619889184833}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-056"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 352, "makespan": 42, "avg_agents_density": 0.06334750373647842, "runtime": 2.574940116610378}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-057"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 486, "makespan": 46, "avg_agents_density": 0.07395719256366022, "runtime": 2.7960713021457195}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-058"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 403, "makespan": 36, "avg_agents_density": 0.06047222857243238, "runtime": 2.508242909796536}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-059"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 187, "makespan": 25, "avg_agents_density": 0.053694779007839664, "runtime": 1.6119484398514032}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-060"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 332, "makespan": 42, "avg_agents_density": 0.05892534056642207, "runtime": 2.5297151072882116}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-061"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 412, "makespan": 46, "avg_agents_density": 0.055714148034336414, "runtime": 3.354084468446672}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-062"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 330, "makespan": 30, "avg_agents_density": 0.06581237349553948, "runtime": 1.859461614396423}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-063"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 431, "makespan": 43, "avg_agents_density": 0.07412155988948232, "runtime": 2.904922437854111}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-064"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 371, "makespan": 37, "avg_agents_density": 0.07205403235132242, "runtime": 2.3169993623159826}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-065"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 401, "makespan": 50, "avg_agents_density": 0.0490671121703139, "runtime": 1.9549805889837444}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-066"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 259, "makespan": 37, "avg_agents_density": 0.04772805857650944, "runtime": 2.2463487898930907}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-067"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 292, "makespan": 35, "avg_agents_density": 0.04932812139044082, "runtime": 1.2909919312223792}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-068"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 519, "makespan": 58, "avg_agents_density": 0.07922560207233824, "runtime": 3.8941579717211425}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-069"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 440, "makespan": 41, "avg_agents_density": 0.07365999721366412, "runtime": 2.331972687970847}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-070"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 437, "makespan": 40, "avg_agents_density": 0.05267592729097122, "runtime": 2.496566299814731}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-071"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 231, "makespan": 23, "avg_agents_density": 0.036487088553127205, "runtime": 0.8281169109977782}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-072"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 388, "makespan": 39, "avg_agents_density": 0.07156914552727489, "runtime": 2.705918751191348}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-073"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 468, "makespan": 52, "avg_agents_density": 0.07561376323024423, "runtime": 2.517236788291484}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-074"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 261, "makespan": 34, "avg_agents_density": 0.04672208722212165, "runtime": 2.0826886324211955}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-075"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 431, "makespan": 52, "avg_agents_density": 0.05568932495043482, "runtime": 2.161682470701635}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-076"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 337, "makespan": 35, "avg_agents_density": 0.0586601536323509, "runtime": 2.0607260735705495}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-077"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 352, "makespan": 39, "avg_agents_density": 0.06850685388327102, "runtime": 1.9138075085356832}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-078"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 22, "SoC": 218, "makespan": 23, "avg_agents_density": 0.051132053823529734, "runtime": 1.4804751677438617}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-079"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 247, "makespan": 32, "avg_agents_density": 0.0450227460405496, "runtime": 1.9958587903529406}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-080"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 317, "makespan": 38, "avg_agents_density": 0.062154807557676564, "runtime": 2.3296125223860145}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-081"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 367, "makespan": 51, "avg_agents_density": 0.05279458010975781, "runtime": 3.192513989750296}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-082"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 238, "makespan": 34, "avg_agents_density": 0.04223416179758538, "runtime": 1.6403277097269893}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-083"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 385, "makespan": 38, "avg_agents_density": 0.05378517420577437, "runtime": 2.4771053581498563}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-084"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 421, "makespan": 51, "avg_agents_density": 0.06189048617126628, "runtime": 1.5563204539939761}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-085"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 260, "makespan": 37, "avg_agents_density": 0.050194468262858914, "runtime": 1.8348103542812169}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-086"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 446, "makespan": 36, "avg_agents_density": 0.06915788139068893, "runtime": 1.8093237839639187}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-087"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 339, "makespan": 37, "avg_agents_density": 0.053368353163839574, "runtime": 2.339972277637571}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-088"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 258, "makespan": 26, "avg_agents_density": 0.052887973862105635, "runtime": 1.2824990674853325}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-089"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 362, "makespan": 30, "avg_agents_density": 0.0706773347025321, "runtime": 1.1425241529941559}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-090"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 320, "makespan": 40, "avg_agents_density": 0.07131927532652155, "runtime": 2.332348925527185}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-091"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 259, "makespan": 25, "avg_agents_density": 0.04575220122435413, "runtime": 1.3230483932420611}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-092"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 271, "makespan": 31, "avg_agents_density": 0.05517904739534077, "runtime": 2.178596954792738}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-093"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 386, "makespan": 37, "avg_agents_density": 0.06580861099455594, "runtime": 1.5489030228927732}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-094"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 352, "makespan": 36, "avg_agents_density": 0.052781758284935885, "runtime": 2.3208835534751415}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-095"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 322, "makespan": 31, "avg_agents_density": 0.04875998020874447, "runtime": 1.35261034918949}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-096"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 330, "makespan": 33, "avg_agents_density": 0.047682553931972106, "runtime": 1.639144434593618}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-097"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 390, "makespan": 43, "avg_agents_density": 0.05980688785215919, "runtime": 2.6708850082941353}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-098"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 309, "makespan": 28, "avg_agents_density": 0.0650200365285765, "runtime": 1.8547856817021966}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-099"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 19, "SoC": 221, "makespan": 20, "avg_agents_density": 0.06441359254582228, "runtime": 1.3217599489726126}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-100"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 310, "makespan": 34, "avg_agents_density": 0.06126296198207095, "runtime": 2.2323918021284044}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-101"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 364, "makespan": 33, "avg_agents_density": 0.08316593927699047, "runtime": 1.5608075042255223}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-102"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 263, "makespan": 30, "avg_agents_density": 0.056008486129335434, "runtime": 1.8746087048202753}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-103"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 401, "makespan": 35, "avg_agents_density": 0.05877487177394553, "runtime": 2.295999606605619}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-104"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 521, "makespan": 68, "avg_agents_density": 0.04275171859521145, "runtime": 4.132412523031235}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-105"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 294, "makespan": 35, "avg_agents_density": 0.044725541201837554, "runtime": 1.6514711142517626}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-106"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 446, "makespan": 40, "avg_agents_density": 0.062026196244744466, "runtime": 2.7387821953743696}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-107"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 335, "makespan": 39, "avg_agents_density": 0.06545161055260616, "runtime": 2.3567132740281522}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-108"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 275, "makespan": 34, "avg_agents_density": 0.06185955050171722, "runtime": 2.160880021750927}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-109"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 461, "makespan": 48, "avg_agents_density": 0.0745204714832692, "runtime": 2.0239370986819267}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-110"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 227, "makespan": 26, "avg_agents_density": 0.06221312829608068, "runtime": 1.6454412187449634}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-111"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 262, "makespan": 25, "avg_agents_density": 0.06960616137229061, "runtime": 1.6216734508052468}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-112"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 220, "makespan": 26, "avg_agents_density": 0.04831474006318403, "runtime": 1.6321733901277184}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-113"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 276, "makespan": 31, "avg_agents_density": 0.05010877675472787, "runtime": 1.1339861042797565}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-114"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 257, "makespan": 28, "avg_agents_density": 0.060946391882016615, "runtime": 1.7202088385820389}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-115"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 284, "makespan": 41, "avg_agents_density": 0.057147408609944286, "runtime": 2.660412037279457}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-116"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 269, "makespan": 30, "avg_agents_density": 0.055426819680887224, "runtime": 1.9253751463256776}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-117"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 350, "makespan": 39, "avg_agents_density": 0.05177889396574673, "runtime": 1.6189658497460186}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-118"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 360, "makespan": 48, "avg_agents_density": 0.05002490647204961, "runtime": 3.3364984849467874}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-119"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 277, "makespan": 30, "avg_agents_density": 0.041339916490418585, "runtime": 1.7878648466430604}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-120"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 338, "makespan": 37, "avg_agents_density": 0.06083284899414319, "runtime": 2.417348307557404}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-121"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 376, "makespan": 42, "avg_agents_density": 0.05189274549576508, "runtime": 1.770568499341607}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-122"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 24, "SoC": 243, "makespan": 25, "avg_agents_density": 0.04802010792781068, "runtime": 1.607055884320289}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-123"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 450, "makespan": 42, "avg_agents_density": 0.06099890085047672, "runtime": 2.7261984483338892}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-124"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 296, "makespan": 33, "avg_agents_density": 0.053824176993655444, "runtime": 2.1109389467164874}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-125"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 371, "makespan": 45, "avg_agents_density": 0.06293679030184547, "runtime": 1.7263892348855734}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-126"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 240, "makespan": 29, "avg_agents_density": 0.04691909671277881, "runtime": 1.688127904664725}, "env_grid_search": {"num_agents": 16, "map_name": "validation-mazes-seed-127"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 481, "makespan": 28, "avg_agents_density": 0.06447615931807468, "runtime": 2.986348161008209}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-000"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 521, "makespan": 33, "avg_agents_density": 0.09816497274261168, "runtime": 3.2080411724746227}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-001"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 744, "makespan": 90, "avg_agents_density": 0.062236979326059406, "runtime": 8.054885135497898}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-002"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 442, "makespan": 45, "avg_agents_density": 0.07929592988504405, "runtime": 4.301881659310311}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-003"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 653, "makespan": 50, "avg_agents_density": 0.07549215743167444, "runtime": 4.89630455058068}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-004"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 823, "makespan": 52, "avg_agents_density": 0.08163927994705518, "runtime": 5.0764587302692235}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-005"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 751, "makespan": 58, "avg_agents_density": 0.08641055016899782, "runtime": 5.583550239913166}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-006"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 871, "makespan": 58, "avg_agents_density": 0.08485160663884077, "runtime": 5.767992201726884}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-007"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 564, "makespan": 37, "avg_agents_density": 0.09479328605758637, "runtime": 3.667008795309812}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-008"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 560, "makespan": 43, "avg_agents_density": 0.09370045361121689, "runtime": 3.853860439732671}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-009"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 605, "makespan": 41, "avg_agents_density": 0.062050308035991784, "runtime": 4.087438106071204}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-010"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 490, "makespan": 32, "avg_agents_density": 0.11451479811556804, "runtime": 3.140832500066608}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-011"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 491, "makespan": 41, "avg_agents_density": 0.08089222736376488, "runtime": 3.9514501374214888}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-012"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 362, "makespan": 39, "avg_agents_density": 0.07998554020978314, "runtime": 3.5922285919077694}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-013"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 573, "makespan": 36, "avg_agents_density": 0.08890357537770037, "runtime": 3.529128408525139}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-014"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 584, "makespan": 43, "avg_agents_density": 0.0754931823332378, "runtime": 4.053779510781169}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-015"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 652, "makespan": 52, "avg_agents_density": 0.08573353441883144, "runtime": 5.054307571146637}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-016"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 524, "makespan": 43, "avg_agents_density": 0.06245210834328081, "runtime": 4.080142442137003}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-017"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 554, "makespan": 43, "avg_agents_density": 0.08484795042228509, "runtime": 4.077599281445146}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-018"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 769, "makespan": 52, "avg_agents_density": 0.08001925361407596, "runtime": 4.899628459010273}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-019"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 646, "makespan": 50, "avg_agents_density": 0.07076916644337222, "runtime": 4.795570839662105}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-020"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 549, "makespan": 40, "avg_agents_density": 0.08996486868291872, "runtime": 4.064918614458293}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-021"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 478, "makespan": 37, "avg_agents_density": 0.07185285995054719, "runtime": 3.6023859600536525}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-022"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 491, "makespan": 35, "avg_agents_density": 0.08855974248674153, "runtime": 3.2776211011223495}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-023"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 576, "makespan": 44, "avg_agents_density": 0.08170706673383415, "runtime": 4.114280838984996}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-024"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 309, "makespan": 36, "avg_agents_density": 0.06729507444268983, "runtime": 3.220021744724363}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-025"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 588, "makespan": 38, "avg_agents_density": 0.08121158922557993, "runtime": 3.868231049273163}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-026"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 552, "makespan": 39, "avg_agents_density": 0.06938757342398565, "runtime": 3.9509895890951157}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-027"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 685, "makespan": 58, "avg_agents_density": 0.06641530975355239, "runtime": 5.645620895549655}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-028"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 599, "makespan": 47, "avg_agents_density": 0.07576588015756759, "runtime": 4.404516173060983}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-029"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 413, "makespan": 28, "avg_agents_density": 0.09904576739211537, "runtime": 2.790143087040633}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-030"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 427, "makespan": 30, "avg_agents_density": 0.08818829091210428, "runtime": 2.8695429819636047}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-031"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 621, "makespan": 44, "avg_agents_density": 0.09277511169267566, "runtime": 4.348337869625539}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-032"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 802, "makespan": 50, "avg_agents_density": 0.11040500234036424, "runtime": 5.248098634649068}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-033"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 564, "makespan": 49, "avg_agents_density": 0.12314698762028675, "runtime": 4.85154468473047}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-034"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 403, "makespan": 30, "avg_agents_density": 0.09572019635564341, "runtime": 2.8622703785076737}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-035"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 423, "makespan": 35, "avg_agents_density": 0.08794686238236481, "runtime": 3.407491024117917}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-036"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 899, "makespan": 102, "avg_agents_density": 0.08429176805234803, "runtime": 9.026473931968212}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-037"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 509, "makespan": 49, "avg_agents_density": 0.08232920591179377, "runtime": 4.510693607386202}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-038"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 762, "makespan": 54, "avg_agents_density": 0.08699276560206362, "runtime": 5.287387295626104}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-039"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 916, "makespan": 64, "avg_agents_density": 0.08678656873041342, "runtime": 6.740709457080811}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-040"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 857, "makespan": 59, "avg_agents_density": 0.08125288985847004, "runtime": 5.756732563022524}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-041"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 587, "makespan": 40, "avg_agents_density": 0.08897788723898653, "runtime": 4.341777694411576}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-042"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 356, "makespan": 35, "avg_agents_density": 0.05901377686544898, "runtime": 3.15767431166023}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-043"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 347, "makespan": 29, "avg_agents_density": 0.0863431499089835, "runtime": 2.6010134662501514}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-044"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 969, "makespan": 65, "avg_agents_density": 0.07757693834719441, "runtime": 6.386969737242907}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-045"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 514, "makespan": 39, "avg_agents_density": 0.0717543514918968, "runtime": 3.7064675339497626}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-046"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 621, "makespan": 62, "avg_agents_density": 0.07857804606096194, "runtime": 5.521438494790345}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-047"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 506, "makespan": 42, "avg_agents_density": 0.07817092608884835, "runtime": 3.8428524006158113}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-048"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 443, "makespan": 29, "avg_agents_density": 0.0881736495064968, "runtime": 2.82145485188812}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-049"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 119, "SoC": 1271, "makespan": 120, "avg_agents_density": 0.0850019063017787, "runtime": 10.862474672496319}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-050"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 506, "makespan": 35, "avg_agents_density": 0.08813943577976231, "runtime": 3.3742233109660447}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-051"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 746, "makespan": 57, "avg_agents_density": 0.069956289124503, "runtime": 5.3537945109419525}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-052"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 913, "makespan": 55, "avg_agents_density": 0.09601241160524639, "runtime": 5.074417293537408}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-053"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 461, "makespan": 30, "avg_agents_density": 0.07878856806650893, "runtime": 2.9507893309928477}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-054"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 620, "makespan": 44, "avg_agents_density": 0.08268941191798514, "runtime": 4.754225310869515}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-055"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 426, "makespan": 30, "avg_agents_density": 0.07446516808887742, "runtime": 2.922484876587987}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-056"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 616, "makespan": 44, "avg_agents_density": 0.08839712688957595, "runtime": 4.251568851061165}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-057"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 1070, "makespan": 80, "avg_agents_density": 0.09104863878206913, "runtime": 7.343648379668593}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-058"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 720, "makespan": 48, "avg_agents_density": 0.07507291036873007, "runtime": 5.133795440196991}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-059"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 25, "SoC": 325, "makespan": 26, "avg_agents_density": 0.07618509377125668, "runtime": 2.481968558393419}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-060"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 572, "makespan": 43, "avg_agents_density": 0.08518776679833479, "runtime": 4.217741654720157}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-061"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 642, "makespan": 45, "avg_agents_density": 0.07794925631669923, "runtime": 4.456028833054006}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-062"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 550, "makespan": 40, "avg_agents_density": 0.0864433217230793, "runtime": 3.94347977777943}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-063"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 678, "makespan": 47, "avg_agents_density": 0.097868719165368, "runtime": 4.5242837951518595}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-064"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 695, "makespan": 58, "avg_agents_density": 0.10541194955560376, "runtime": 5.310155866667628}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-065"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 79, "SoC": 864, "makespan": 80, "avg_agents_density": 0.06857635514212662, "runtime": 7.071525254752487}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-066"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 394, "makespan": 32, "avg_agents_density": 0.06734508366162667, "runtime": 2.909903094638139}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-067"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 610, "makespan": 46, "avg_agents_density": 0.07015791220317366, "runtime": 4.380377069115639}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-068"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 690, "makespan": 53, "avg_agents_density": 0.09535928727777787, "runtime": 5.20564942015335}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-069"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 762, "makespan": 48, "avg_agents_density": 0.09027165845794, "runtime": 4.614788230042905}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-070"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 669, "makespan": 39, "avg_agents_density": 0.08149885312331491, "runtime": 3.7988241650164127}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-071"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 367, "makespan": 29, "avg_agents_density": 0.05338527644536869, "runtime": 2.9139699772931635}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-072"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 481, "makespan": 35, "avg_agents_density": 0.1127927798897781, "runtime": 3.2187256435863674}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-073"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 105, "SoC": 925, "makespan": 106, "avg_agents_density": 0.07459153828243628, "runtime": 9.445429346058518}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-074"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 481, "makespan": 47, "avg_agents_density": 0.05890041298776022, "runtime": 4.029634876176715}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-075"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 690, "makespan": 51, "avg_agents_density": 0.08669327538526496, "runtime": 4.940465279854834}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-076"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 740, "makespan": 48, "avg_agents_density": 0.07088950863699502, "runtime": 4.713784320279956}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-077"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 536, "makespan": 40, "avg_agents_density": 0.09527023780666444, "runtime": 3.8292105654254556}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-078"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 403, "makespan": 31, "avg_agents_density": 0.06787017122545871, "runtime": 2.996701914817095}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-079"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 373, "makespan": 32, "avg_agents_density": 0.05846897472968511, "runtime": 3.209435050841421}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-080"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 467, "makespan": 38, "avg_agents_density": 0.0897468282926316, "runtime": 3.7726485449820757}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-081"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 611, "makespan": 44, "avg_agents_density": 0.0690673059851963, "runtime": 4.19848974654451}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-082"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 27, "SoC": 414, "makespan": 28, "avg_agents_density": 0.06203650145894604, "runtime": 2.6565194418653846}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-083"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 625, "makespan": 43, "avg_agents_density": 0.07807124412841104, "runtime": 3.95011352840811}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-084"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 909, "makespan": 67, "avg_agents_density": 0.0959550830942669, "runtime": 6.269047474022955}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-085"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 391, "makespan": 33, "avg_agents_density": 0.06439806006763753, "runtime": 3.009953841101378}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-086"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 858, "makespan": 86, "avg_agents_density": 0.07687321352676765, "runtime": 7.409214402548969}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-087"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 635, "makespan": 51, "avg_agents_density": 0.0722598617800805, "runtime": 4.284261539578438}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-088"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 433, "makespan": 32, "avg_agents_density": 0.07410321439240855, "runtime": 3.3787470450624824}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-089"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 605, "makespan": 41, "avg_agents_density": 0.08723855609910063, "runtime": 3.7611922207288444}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-090"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 502, "makespan": 37, "avg_agents_density": 0.09790454138360713, "runtime": 3.5140514755621552}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-091"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 440, "makespan": 29, "avg_agents_density": 0.058354652608860455, "runtime": 2.8704425203613937}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-092"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 487, "makespan": 42, "avg_agents_density": 0.06997933174896477, "runtime": 4.00985314976424}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-093"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 677, "makespan": 42, "avg_agents_density": 0.10466661407116488, "runtime": 4.100863591302186}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-094"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 559, "makespan": 39, "avg_agents_density": 0.06963844664337267, "runtime": 3.740414960309863}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-095"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 631, "makespan": 44, "avg_agents_density": 0.07239540991565278, "runtime": 4.1891411929391325}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-096"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 474, "makespan": 34, "avg_agents_density": 0.07900642703115922, "runtime": 3.3666819729842246}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-097"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 650, "makespan": 38, "avg_agents_density": 0.09213574561339455, "runtime": 3.7472990569658577}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-098"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 600, "makespan": 43, "avg_agents_density": 0.0806050314801961, "runtime": 3.9092454477213323}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-099"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 417, "makespan": 35, "avg_agents_density": 0.07961878438631204, "runtime": 3.419872801285237}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-100"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 581, "makespan": 43, "avg_agents_density": 0.0799612361848182, "runtime": 4.346365842036903}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-101"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 469, "makespan": 43, "avg_agents_density": 0.09616833184337362, "runtime": 3.921672247350216}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-102"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 418, "makespan": 32, "avg_agents_density": 0.06926864013618134, "runtime": 2.8065150631591678}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-103"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 603, "makespan": 43, "avg_agents_density": 0.07145195744807477, "runtime": 4.138584962114692}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-104"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 760, "makespan": 51, "avg_agents_density": 0.07166589777358862, "runtime": 4.828075777739286}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-105"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 412, "makespan": 33, "avg_agents_density": 0.06564167345356944, "runtime": 3.0635543721728027}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-106"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 621, "makespan": 47, "avg_agents_density": 0.08354693969030445, "runtime": 4.51800388423726}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-107"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 651, "makespan": 43, "avg_agents_density": 0.09524285401629716, "runtime": 4.311939283274114}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-108"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 546, "makespan": 41, "avg_agents_density": 0.08629855815341399, "runtime": 4.025027655530721}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-109"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 727, "makespan": 50, "avg_agents_density": 0.09082135217840666, "runtime": 4.55907334620133}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-110"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 432, "makespan": 29, "avg_agents_density": 0.07504506622256195, "runtime": 2.6647441359236836}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-111"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 691, "makespan": 54, "avg_agents_density": 0.0949748699936321, "runtime": 5.027845229022205}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-112"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 376, "makespan": 31, "avg_agents_density": 0.07545774023582268, "runtime": 2.8487944840453565}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-113"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 28, "SoC": 402, "makespan": 29, "avg_agents_density": 0.06928568443747057, "runtime": 2.857149296440184}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-114"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 537, "makespan": 46, "avg_agents_density": 0.08101067019793332, "runtime": 4.167208211030811}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-115"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 482, "makespan": 32, "avg_agents_density": 0.09005547846646134, "runtime": 3.094039958436042}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-116"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 459, "makespan": 41, "avg_agents_density": 0.0829848807272812, "runtime": 4.057550718542188}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-117"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 89, "SoC": 789, "makespan": 90, "avg_agents_density": 0.07128316641599758, "runtime": 8.022574225440621}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-118"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 659, "makespan": 66, "avg_agents_density": 0.07284324303018791, "runtime": 5.935062221251428}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-119"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 402, "makespan": 32, "avg_agents_density": 0.059355206152303934, "runtime": 2.7956495732069016}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-120"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 536, "makespan": 37, "avg_agents_density": 0.0827207791123889, "runtime": 3.852040606085211}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-121"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 443, "makespan": 34, "avg_agents_density": 0.07323781625005307, "runtime": 3.30183959659189}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-122"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 23, "SoC": 318, "makespan": 24, "avg_agents_density": 0.06655981279741356, "runtime": 2.237570912577212}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-123"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1026, "makespan": 64, "avg_agents_density": 0.08651308298127562, "runtime": 6.039511478040367}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-124"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 505, "makespan": 37, "avg_agents_density": 0.06907757746176775, "runtime": 3.498814148362726}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-125"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 858, "makespan": 51, "avg_agents_density": 0.08029330360625164, "runtime": 5.14512528013438}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-126"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 415, "makespan": 33, "avg_agents_density": 0.07052857362796652, "runtime": 3.1098817489109933}, "env_grid_search": {"num_agents": 24, "map_name": "validation-mazes-seed-127"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 785, "makespan": 40, "avg_agents_density": 0.10327905377044098, "runtime": 5.563180581200868}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-000"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1023, "makespan": 62, "avg_agents_density": 0.12067475930809476, "runtime": 7.8417475814931095}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-001"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 774, "makespan": 53, "avg_agents_density": 0.08683966262176869, "runtime": 6.486006869468838}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-002"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 833, "makespan": 49, "avg_agents_density": 0.11095907852330197, "runtime": 6.187858146615326}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-003"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 969, "makespan": 57, "avg_agents_density": 0.09981348473868064, "runtime": 7.112688438035548}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-004"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 969, "makespan": 50, "avg_agents_density": 0.10956414472251998, "runtime": 6.412064271047711}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-005"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 857, "makespan": 54, "avg_agents_density": 0.09896439650823688, "runtime": 6.690413870848715}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-006"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1159, "makespan": 51, "avg_agents_density": 0.10770675897329185, "runtime": 6.67900440748781}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-007"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 912, "makespan": 45, "avg_agents_density": 0.11987570208853343, "runtime": 6.094171253964305}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-008"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 778, "makespan": 46, "avg_agents_density": 0.12270825240779093, "runtime": 5.752534305676818}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-009"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 781, "makespan": 41, "avg_agents_density": 0.08315826926035647, "runtime": 5.26286688959226}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-010"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 930, "makespan": 46, "avg_agents_density": 0.1342712273612101, "runtime": 5.742386127822101}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-011"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 704, "makespan": 42, "avg_agents_density": 0.10956328018594598, "runtime": 5.401806830428541}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-012"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 574, "makespan": 43, "avg_agents_density": 0.10207777962590049, "runtime": 5.167200649622828}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-013"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 742, "makespan": 36, "avg_agents_density": 0.11811939012838031, "runtime": 4.541052397340536}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-014"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1101, "makespan": 54, "avg_agents_density": 0.11410073264620144, "runtime": 6.903235677629709}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-015"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 892, "makespan": 47, "avg_agents_density": 0.10182637825289192, "runtime": 6.08556047687307}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-016"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 708, "makespan": 43, "avg_agents_density": 0.0887517909070804, "runtime": 5.326024568174034}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-017"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1118, "makespan": 51, "avg_agents_density": 0.12861905762754616, "runtime": 6.627000014297664}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-018"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1093, "makespan": 53, "avg_agents_density": 0.11097946909478075, "runtime": 6.905841655097902}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-019"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 1140, "makespan": 75, "avg_agents_density": 0.09268314196168168, "runtime": 9.321420623455197}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-020"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 892, "makespan": 44, "avg_agents_density": 0.10225883992977579, "runtime": 5.673902628477663}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-021"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 712, "makespan": 40, "avg_agents_density": 0.09579475627848925, "runtime": 4.920112818013877}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-022"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 811, "makespan": 44, "avg_agents_density": 0.11345772326868614, "runtime": 5.464256167411804}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-023"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 966, "makespan": 48, "avg_agents_density": 0.09687574856597876, "runtime": 6.251967171672732}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-024"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 432, "makespan": 31, "avg_agents_density": 0.09139386876017405, "runtime": 3.872308003716171}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-025"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 714, "makespan": 40, "avg_agents_density": 0.09043686990841729, "runtime": 4.947762476745993}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-026"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1063, "makespan": 56, "avg_agents_density": 0.08558214153994115, "runtime": 6.951772594824433}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-027"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1130, "makespan": 59, "avg_agents_density": 0.0898059170253568, "runtime": 7.68171227350831}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-028"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 959, "makespan": 55, "avg_agents_density": 0.10366672836318176, "runtime": 6.921726411674172}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-029"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 686, "makespan": 30, "avg_agents_density": 0.1151589710930515, "runtime": 3.9098873799666762}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-030"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 631, "makespan": 31, "avg_agents_density": 0.1150881671274104, "runtime": 3.954903758596629}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-031"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 930, "makespan": 53, "avg_agents_density": 0.12427092839856399, "runtime": 6.72282832255587}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-032"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1182, "makespan": 60, "avg_agents_density": 0.12607194538429015, "runtime": 7.219526534900069}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-033"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 807, "makespan": 45, "avg_agents_density": 0.14271247977260035, "runtime": 5.548827243503183}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-034"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 769, "makespan": 47, "avg_agents_density": 0.12252696049462236, "runtime": 4.870948237832636}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-035"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 641, "makespan": 39, "avg_agents_density": 0.11550577938241213, "runtime": 5.513385320082307}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-036"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 987, "makespan": 51, "avg_agents_density": 0.1259244659284229, "runtime": 6.521248779725283}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-037"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 659, "makespan": 53, "avg_agents_density": 0.09126787115866997, "runtime": 6.190114552620798}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-038"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 1024, "makespan": 47, "avg_agents_density": 0.1245694574353103, "runtime": 5.237148224841803}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-039"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1184, "makespan": 64, "avg_agents_density": 0.10278579024125395, "runtime": 8.210134369786829}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-040"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1197, "makespan": 67, "avg_agents_density": 0.09308633190190108, "runtime": 9.086740083061159}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-041"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 756, "makespan": 37, "avg_agents_density": 0.11895220738306686, "runtime": 4.746785279829055}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-042"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 466, "makespan": 31, "avg_agents_density": 0.08213856472601075, "runtime": 3.5005863243713975}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-043"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 637, "makespan": 49, "avg_agents_density": 0.11433284795986016, "runtime": 6.261237164027989}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-044"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1015, "makespan": 57, "avg_agents_density": 0.09436738041320968, "runtime": 7.401381126604974}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-045"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 34, "SoC": 680, "makespan": 35, "avg_agents_density": 0.08706779075779629, "runtime": 4.96113372920081}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-046"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1026, "makespan": 58, "avg_agents_density": 0.10906394453969816, "runtime": 6.946241643279791}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-047"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 833, "makespan": 49, "avg_agents_density": 0.11113752641531705, "runtime": 6.575916154310107}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-048"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 741, "makespan": 51, "avg_agents_density": 0.10520686061800268, "runtime": 6.18600940797478}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-049"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1073, "makespan": 69, "avg_agents_density": 0.10143630856007133, "runtime": 7.716541100759059}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-050"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 679, "makespan": 41, "avg_agents_density": 0.1063137822081752, "runtime": 5.131502264644951}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-051"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 891, "makespan": 49, "avg_agents_density": 0.0979382289721737, "runtime": 5.984731558710337}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-052"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 1674, "makespan": 95, "avg_agents_density": 0.14398448337384512, "runtime": 11.71943946974352}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-053"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 921, "makespan": 48, "avg_agents_density": 0.10259566482090977, "runtime": 6.232592437416315}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-054"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 963, "makespan": 58, "avg_agents_density": 0.11078985118796136, "runtime": 7.042055417317897}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-055"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 601, "makespan": 41, "avg_agents_density": 0.08035863210690389, "runtime": 5.0685980967246}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-056"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1049, "makespan": 70, "avg_agents_density": 0.1112263058704261, "runtime": 8.484958673361689}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-057"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 2160, "makespan": 128, "avg_agents_density": 0.10521839532117777, "runtime": 16.22184139955789}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-058"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1045, "makespan": 51, "avg_agents_density": 0.10028051507629229, "runtime": 6.61777011025697}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-059"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 535, "makespan": 34, "avg_agents_density": 0.10627374172545218, "runtime": 4.334297196939588}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-060"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1002, "makespan": 49, "avg_agents_density": 0.10531210927705999, "runtime": 6.221291888970882}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-061"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 63, "SoC": 1192, "makespan": 64, "avg_agents_density": 0.09992700694353948, "runtime": 8.066112735308707}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-062"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 1658, "makespan": 128, "avg_agents_density": 0.10799580543135523, "runtime": 15.370438007637858}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-063"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1003, "makespan": 44, "avg_agents_density": 0.11113529750566688, "runtime": 5.806325591169298}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-064"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1131, "makespan": 54, "avg_agents_density": 0.1464214358001647, "runtime": 6.832689163275063}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-065"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1253, "makespan": 62, "avg_agents_density": 0.09443978234001615, "runtime": 7.241175136063248}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-066"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 607, "makespan": 37, "avg_agents_density": 0.082003663934913, "runtime": 4.530486727133393}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-067"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 870, "makespan": 50, "avg_agents_density": 0.10098235141634919, "runtime": 6.01511052204296}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-068"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 1177, "makespan": 66, "avg_agents_density": 0.1221511576000058, "runtime": 8.08892247080803}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-069"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1235, "makespan": 59, "avg_agents_density": 0.12874001939306354, "runtime": 7.35299355443567}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-070"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1127, "makespan": 54, "avg_agents_density": 0.11495882126229105, "runtime": 7.029542324133217}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-071"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 482, "makespan": 39, "avg_agents_density": 0.06559725283291792, "runtime": 4.766747703310102}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-072"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 853, "makespan": 65, "avg_agents_density": 0.13516929357918853, "runtime": 8.203959957696497}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-073"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1059, "makespan": 55, "avg_agents_density": 0.10011695423220965, "runtime": 7.236656585242599}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-074"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 732, "makespan": 53, "avg_agents_density": 0.08074395933922106, "runtime": 6.501466504763812}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-075"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 114, "SoC": 1545, "makespan": 115, "avg_agents_density": 0.1063544167639994, "runtime": 13.8106220071204}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-076"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 1794, "makespan": 128, "avg_agents_density": 0.09786287685375661, "runtime": 15.31087909732014}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-077"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 942, "makespan": 60, "avg_agents_density": 0.1109839091771734, "runtime": 7.005855505820364}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-078"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 662, "makespan": 42, "avg_agents_density": 0.09152567679032195, "runtime": 5.102834491059184}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-079"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 556, "makespan": 34, "avg_agents_density": 0.07068126082683682, "runtime": 4.217786820605397}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-080"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 654, "makespan": 49, "avg_agents_density": 0.11236493639128914, "runtime": 5.937956755515188}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-081"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 109, "SoC": 1225, "makespan": 110, "avg_agents_density": 0.08181328882291575, "runtime": 12.87343620089814}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-082"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 567, "makespan": 32, "avg_agents_density": 0.08107914526221394, "runtime": 4.162914663087577}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-083"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1204, "makespan": 55, "avg_agents_density": 0.08969345179666223, "runtime": 6.817041675560176}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-084"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 1303, "makespan": 78, "avg_agents_density": 0.11924967452168764, "runtime": 9.429965432733297}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-085"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 535, "makespan": 33, "avg_agents_density": 0.08582354334696803, "runtime": 4.087819071486592}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-086"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1015, "makespan": 54, "avg_agents_density": 0.09917296385463914, "runtime": 7.023819532711059}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-087"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 864, "makespan": 52, "avg_agents_density": 0.1064029455650885, "runtime": 5.745290399063379}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-088"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 719, "makespan": 52, "avg_agents_density": 0.10482186235666387, "runtime": 6.379233587067574}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-089"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 842, "makespan": 41, "avg_agents_density": 0.11171057961672486, "runtime": 5.268714707810432}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-090"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 1073, "makespan": 78, "avg_agents_density": 0.1017497345948063, "runtime": 8.89313904196024}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-091"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 649, "makespan": 34, "avg_agents_density": 0.08738089846742494, "runtime": 4.3024520399048924}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-092"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 936, "makespan": 57, "avg_agents_density": 0.09889271118418398, "runtime": 7.1273083672858775}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-093"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 1261, "makespan": 75, "avg_agents_density": 0.1342433722566994, "runtime": 9.20555875170976}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-094"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 77, "SoC": 1148, "makespan": 78, "avg_agents_density": 0.09099011324215793, "runtime": 9.789251539856195}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-095"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 804, "makespan": 52, "avg_agents_density": 0.09595686549981985, "runtime": 6.624311537016183}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-096"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 799, "makespan": 52, "avg_agents_density": 0.10111939261558683, "runtime": 6.429602124728262}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-097"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1020, "makespan": 48, "avg_agents_density": 0.11993571993084333, "runtime": 5.998436543624848}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-098"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1032, "makespan": 55, "avg_agents_density": 0.10665041108812383, "runtime": 6.753508226014674}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-099"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 897, "makespan": 46, "avg_agents_density": 0.102012486619084, "runtime": 5.530790297780186}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-100"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 973, "makespan": 50, "avg_agents_density": 0.11094817584373064, "runtime": 6.145222429651767}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-101"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 845, "makespan": 46, "avg_agents_density": 0.13176587211395024, "runtime": 5.91866422444582}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-102"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 702, "makespan": 44, "avg_agents_density": 0.08697010972089604, "runtime": 5.68074272479862}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-103"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 1231, "makespan": 92, "avg_agents_density": 0.10699670301505973, "runtime": 11.542740646749735}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-104"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 1417, "makespan": 86, "avg_agents_density": 0.09244272273646663, "runtime": 10.719652101863176}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-105"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 529, "makespan": 36, "avg_agents_density": 0.08891313936056047, "runtime": 4.502014462836087}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-106"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1181, "makespan": 70, "avg_agents_density": 0.10986303287911525, "runtime": 8.534489651210606}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-107"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 962, "makespan": 50, "avg_agents_density": 0.1259678918462355, "runtime": 6.582934063859284}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-108"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 813, "makespan": 46, "avg_agents_density": 0.11036794248382849, "runtime": 5.933301875367761}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-109"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1050, "makespan": 51, "avg_agents_density": 0.1172834110612227, "runtime": 6.596210232935846}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-110"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 31, "SoC": 669, "makespan": 32, "avg_agents_density": 0.1074225391570584, "runtime": 4.183808641973883}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-111"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 983, "makespan": 66, "avg_agents_density": 0.13417890720278378, "runtime": 8.105468450579792}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-112"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 26, "SoC": 499, "makespan": 27, "avg_agents_density": 0.09873810879546037, "runtime": 3.570102144498378}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-113"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 29, "SoC": 563, "makespan": 30, "avg_agents_density": 0.08806775113917689, "runtime": 3.8662239238619804}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-114"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 733, "makespan": 52, "avg_agents_density": 0.09553317773079578, "runtime": 6.486325888894498}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-115"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 807, "makespan": 51, "avg_agents_density": 0.1183544427591859, "runtime": 6.297341962810606}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-116"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 586, "makespan": 42, "avg_agents_density": 0.10069615386369457, "runtime": 5.1802637269720435}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-117"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 751, "makespan": 40, "avg_agents_density": 0.10278644447171292, "runtime": 5.1473114839755}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-118"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 1174, "makespan": 74, "avg_agents_density": 0.10060887454780033, "runtime": 9.25162223726511}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-119"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 612, "makespan": 33, "avg_agents_density": 0.0746698479026337, "runtime": 4.080262162722647}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-120"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 46, "SoC": 852, "makespan": 47, "avg_agents_density": 0.10668723309648447, "runtime": 5.980815547518432}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-121"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 752, "makespan": 45, "avg_agents_density": 0.08870368062666709, "runtime": 5.677418514620513}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-122"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 459, "makespan": 31, "avg_agents_density": 0.08777650907441842, "runtime": 3.806109038181603}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-123"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1190, "makespan": 69, "avg_agents_density": 0.09608664052070703, "runtime": 8.516828823834658}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-124"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 795, "makespan": 38, "avg_agents_density": 0.09885152015899872, "runtime": 5.079813301563263}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-125"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 116, "SoC": 1786, "makespan": 117, "avg_agents_density": 0.11464924302663794, "runtime": 14.89535560272634}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-126"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 632, "makespan": 42, "avg_agents_density": 0.0975832609771361, "runtime": 5.3529077102430165}, "env_grid_search": {"num_agents": 32, "map_name": "validation-mazes-seed-127"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1376, "makespan": 48, "avg_agents_density": 0.146339534645627, "runtime": 9.115957230329514}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-000"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1520, "makespan": 50, "avg_agents_density": 0.15543929311601543, "runtime": 9.64745049411431}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-001"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 54, "SoC": 1425, "makespan": 55, "avg_agents_density": 0.13927597743005257, "runtime": 10.32417321857065}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-002"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1382, "makespan": 48, "avg_agents_density": 0.15354540525884236, "runtime": 9.191968816332519}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-003"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1602, "makespan": 58, "avg_agents_density": 0.1422932311246311, "runtime": 11.166121424175799}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-004"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 3249, "makespan": 128, "avg_agents_density": 0.1521204910419356, "runtime": 24.856256775092334}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-005"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1079, "makespan": 39, "avg_agents_density": 0.13848955122935164, "runtime": 7.53245932655409}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-006"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.8958333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 3703, "makespan": 128, "avg_agents_density": 0.162979053452202, "runtime": 24.18939678184688}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-007"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1747, "makespan": 68, "avg_agents_density": 0.17062244197996393, "runtime": 13.185740939341486}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-008"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1457, "makespan": 58, "avg_agents_density": 0.17147640004693382, "runtime": 11.123505558818579}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-009"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1238, "makespan": 45, "avg_agents_density": 0.12574834399856027, "runtime": 9.124591645319015}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-010"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 2976, "makespan": 128, "avg_agents_density": 0.19916160454415724, "runtime": 24.597048026509583}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-011"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1258, "makespan": 41, "avg_agents_density": 0.16916323184258775, "runtime": 8.29044866701588}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-012"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1247, "makespan": 56, "avg_agents_density": 0.14768682406345093, "runtime": 10.942374750040472}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-013"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 1642, "makespan": 85, "avg_agents_density": 0.176583018589358, "runtime": 16.060790453106165}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-014"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1676, "makespan": 57, "avg_agents_density": 0.15006397723068512, "runtime": 11.176730890292674}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-015"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 2005, "makespan": 73, "avg_agents_density": 0.14927819290322247, "runtime": 14.409501432441175}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-016"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 60, "SoC": 1334, "makespan": 61, "avg_agents_density": 0.12526419567580205, "runtime": 12.028760550078005}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-017"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 73, "SoC": 2391, "makespan": 74, "avg_agents_density": 0.15294730922546276, "runtime": 14.651983656920493}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-018"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 3138, "makespan": 128, "avg_agents_density": 0.17578580664047783, "runtime": 23.522566272411495}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-019"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1632, "makespan": 62, "avg_agents_density": 0.14576925482803813, "runtime": 12.174736310727894}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-020"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 2020, "makespan": 102, "avg_agents_density": 0.1634811208943499, "runtime": 19.88062932435423}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-021"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1156, "makespan": 42, "avg_agents_density": 0.13806515829594612, "runtime": 7.973453243263066}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-022"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1944, "makespan": 65, "avg_agents_density": 0.16181802631605954, "runtime": 12.79568829992786}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-023"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1881, "makespan": 69, "avg_agents_density": 0.15715358962231887, "runtime": 13.743439093232155}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-024"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 30, "SoC": 652, "makespan": 31, "avg_agents_density": 0.12989867909479985, "runtime": 6.100114077795297}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-025"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1180, "makespan": 43, "avg_agents_density": 0.12883543936748276, "runtime": 8.564965870697051}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-026"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 1919, "makespan": 70, "avg_agents_density": 0.13255440388710077, "runtime": 13.791799594182521}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-027"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 109, "SoC": 3060, "makespan": 110, "avg_agents_density": 0.15089889384615932, "runtime": 21.38481283839792}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-028"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 2063, "makespan": 92, "avg_agents_density": 0.15261911886103469, "runtime": 18.2748446688056}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-029"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1378, "makespan": 52, "avg_agents_density": 0.17838768739220326, "runtime": 9.956946880556643}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-030"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 36, "SoC": 943, "makespan": 37, "avg_agents_density": 0.14494207245542204, "runtime": 7.428578356746584}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-031"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1585, "makespan": 63, "avg_agents_density": 0.15698613838759218, "runtime": 13.120064313989133}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-032"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.8958333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 4106, "makespan": 128, "avg_agents_density": 0.20363085228024277, "runtime": 25.062860056757927}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-033"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2318, "makespan": 86, "avg_agents_density": 0.211736590562848, "runtime": 13.58147602295503}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-034"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1148, "makespan": 54, "avg_agents_density": 0.176317506988072, "runtime": 10.386250832583755}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-035"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 70, "SoC": 1675, "makespan": 71, "avg_agents_density": 0.16830581644754974, "runtime": 13.776695147156715}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-036"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 2560, "makespan": 128, "avg_agents_density": 0.1733962171710987, "runtime": 23.86423500115052}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-037"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1266, "makespan": 54, "avg_agents_density": 0.14202147586917208, "runtime": 11.164850777480751}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-038"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 3814, "makespan": 128, "avg_agents_density": 0.1893775624898933, "runtime": 24.91363334096968}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-039"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 2157, "makespan": 69, "avg_agents_density": 0.16064157922807634, "runtime": 15.450933461543173}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-040"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.8541666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 3138, "makespan": 128, "avg_agents_density": 0.1447733387910915, "runtime": 25.360208845697343}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-041"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 1576, "makespan": 65, "avg_agents_density": 0.16029219886882282, "runtime": 12.50251642940566}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-042"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1046, "makespan": 53, "avg_agents_density": 0.1145471899007393, "runtime": 10.185078974813223}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-043"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1146, "makespan": 49, "avg_agents_density": 0.15129238451100332, "runtime": 8.534380985889584}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-044"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 2006, "makespan": 73, "avg_agents_density": 0.15303508525962795, "runtime": 15.116551540791988}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-045"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1123, "makespan": 54, "avg_agents_density": 0.1203216884082984, "runtime": 10.902237409260124}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-046"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 65, "SoC": 2224, "makespan": 66, "avg_agents_density": 0.1454254818843162, "runtime": 13.036678505595773}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-047"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 1836, "makespan": 76, "avg_agents_density": 0.16038322139945357, "runtime": 14.694422085769475}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-048"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 57, "SoC": 1681, "makespan": 58, "avg_agents_density": 0.17333091235439813, "runtime": 9.687596428208053}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-049"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 94, "SoC": 2354, "makespan": 95, "avg_agents_density": 0.14042573337450584, "runtime": 18.570353199262172}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-050"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1387, "makespan": 40, "avg_agents_density": 0.14138138573894646, "runtime": 7.895812927279621}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-051"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.9166666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 2435, "makespan": 128, "avg_agents_density": 0.12660523543446062, "runtime": 25.05927692865953}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-052"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 4287, "makespan": 128, "avg_agents_density": 0.21720771012120715, "runtime": 24.716115191113204}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-053"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 2257, "makespan": 73, "avg_agents_density": 0.16042925898387042, "runtime": 14.190668831579387}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-054"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1750, "makespan": 63, "avg_agents_density": 0.16284995835540472, "runtime": 12.34745850134641}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-055"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 929, "makespan": 39, "avg_agents_density": 0.11819838243183249, "runtime": 7.821318379137665}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-056"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 97, "SoC": 2157, "makespan": 98, "avg_agents_density": 0.155062030949485, "runtime": 19.151756157632917}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-057"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.5416666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 5374, "makespan": 128, "avg_agents_density": 0.22869261170977287, "runtime": 27.86221482884139}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-058"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 2158, "makespan": 76, "avg_agents_density": 0.16323599307386946, "runtime": 14.570740392431617}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-059"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 780, "makespan": 33, "avg_agents_density": 0.14203841136808212, "runtime": 6.592508737929165}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-060"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 88, "SoC": 2080, "makespan": 89, "avg_agents_density": 0.14444868052908916, "runtime": 15.548020009882748}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-061"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 4148, "makespan": 128, "avg_agents_density": 0.20963290389063824, "runtime": 24.85863034101203}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-062"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 122, "SoC": 3092, "makespan": 123, "avg_agents_density": 0.1594210055427758, "runtime": 23.8297381112352}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-063"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 82, "SoC": 1977, "makespan": 83, "avg_agents_density": 0.18330680152826948, "runtime": 15.929703599773347}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-064"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 110, "SoC": 3606, "makespan": 111, "avg_agents_density": 0.20935415128756255, "runtime": 21.881982501596212}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-065"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 105, "SoC": 2480, "makespan": 106, "avg_agents_density": 0.14709490538746048, "runtime": 20.671257293317467}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-066"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 58, "SoC": 1240, "makespan": 59, "avg_agents_density": 0.11893009161220404, "runtime": 11.007805586792529}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-067"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 1926, "makespan": 92, "avg_agents_density": 0.1449354567020183, "runtime": 18.045742868911475}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-068"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 2730, "makespan": 102, "avg_agents_density": 0.18245470456015295, "runtime": 20.05621103523299}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-069"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 120, "SoC": 2602, "makespan": 121, "avg_agents_density": 0.1637278350352466, "runtime": 23.631326396018267}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-070"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2619, "makespan": 86, "avg_agents_density": 0.1738617571554218, "runtime": 16.36368614155799}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-071"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 781, "makespan": 40, "avg_agents_density": 0.09413066915441608, "runtime": 7.778115285094827}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-072"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 1634, "makespan": 69, "avg_agents_density": 0.16941875299123202, "runtime": 13.381522548384964}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-073"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.9583333333333334, "CSR": 0.0, "ep_length": 127, "SoC": 2278, "makespan": 128, "avg_agents_density": 0.14233300241160593, "runtime": 24.445555775426328}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-074"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1074, "makespan": 52, "avg_agents_density": 0.11076622994963951, "runtime": 10.362681315280497}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-075"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1923, "makespan": 62, "avg_agents_density": 0.1608289695944419, "runtime": 12.185917642898858}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-076"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 3971, "makespan": 128, "avg_agents_density": 0.14026339547124278, "runtime": 25.152362056076527}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-077"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1574, "makespan": 62, "avg_agents_density": 0.16153668149719008, "runtime": 12.237733030691743}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-078"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 45, "SoC": 1104, "makespan": 46, "avg_agents_density": 0.13292781247716237, "runtime": 9.062818686943501}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-079"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 824, "makespan": 34, "avg_agents_density": 0.10485548208470023, "runtime": 6.390109841711819}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-080"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1421, "makespan": 49, "avg_agents_density": 0.18112695291326253, "runtime": 9.403221934102476}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-081"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 104, "SoC": 2494, "makespan": 105, "avg_agents_density": 0.13456777470675957, "runtime": 20.311625483445823}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-082"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 936, "makespan": 40, "avg_agents_density": 0.12204745279897566, "runtime": 7.624509871471673}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-083"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 110, "SoC": 2519, "makespan": 111, "avg_agents_density": 0.13770583653166799, "runtime": 20.078829882200807}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-084"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 2675, "makespan": 128, "avg_agents_density": 0.15226295039593077, "runtime": 24.62038177298382}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-085"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1021, "makespan": 40, "avg_agents_density": 0.13514586600279685, "runtime": 7.8901288216002285}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-086"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 2193, "makespan": 82, "avg_agents_density": 0.15935067192986688, "runtime": 16.23469988349825}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-087"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 3861, "makespan": 128, "avg_agents_density": 0.17147745357760372, "runtime": 24.708659276366234}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-088"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1282, "makespan": 41, "avg_agents_density": 0.1534527518749537, "runtime": 7.961826470680535}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-089"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 2145, "makespan": 77, "avg_agents_density": 0.1616187606617606, "runtime": 14.213089924771339}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-090"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1321, "makespan": 48, "avg_agents_density": 0.1523028889593957, "runtime": 9.315991261042655}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-091"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 37, "SoC": 1054, "makespan": 38, "avg_agents_density": 0.1238507467709594, "runtime": 7.913716904819012}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-092"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 95, "SoC": 2723, "makespan": 96, "avg_agents_density": 0.16337472277857681, "runtime": 19.10818480933085}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-093"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 100, "SoC": 2616, "makespan": 101, "avg_agents_density": 0.17880263046244002, "runtime": 18.977299439255148}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-094"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 110, "SoC": 2476, "makespan": 111, "avg_agents_density": 0.13604849523014612, "runtime": 19.591845993418247}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-095"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 56, "SoC": 1689, "makespan": 57, "avg_agents_density": 0.1495453145911126, "runtime": 10.944013038650155}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-096"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 1771, "makespan": 68, "avg_agents_density": 0.16730182553816944, "runtime": 13.074326753150672}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-097"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 96, "SoC": 1942, "makespan": 97, "avg_agents_density": 0.16214212766639044, "runtime": 18.382405387237668}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-098"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 1977, "makespan": 63, "avg_agents_density": 0.17336453330093723, "runtime": 12.151551212649792}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-099"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1266, "makespan": 43, "avg_agents_density": 0.15412007386148618, "runtime": 8.519641411490738}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-100"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1534, "makespan": 62, "avg_agents_density": 0.16791998048947984, "runtime": 12.26858687074855}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-101"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 49, "SoC": 1381, "makespan": 50, "avg_agents_density": 0.17873645190959783, "runtime": 9.808551284018904}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-102"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 59, "SoC": 1731, "makespan": 60, "avg_agents_density": 0.14567681219211795, "runtime": 11.604057593271136}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-103"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 2257, "makespan": 93, "avg_agents_density": 0.14057381340917458, "runtime": 18.36645077401772}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-104"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 4320, "makespan": 128, "avg_agents_density": 0.14492782419903627, "runtime": 24.556514465715736}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-105"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1041, "makespan": 45, "avg_agents_density": 0.126447533116433, "runtime": 8.966922748368233}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-106"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 3433, "makespan": 128, "avg_agents_density": 0.1727840670690653, "runtime": 25.17201614845544}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-107"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 118, "SoC": 2682, "makespan": 119, "avg_agents_density": 0.1857356932016615, "runtime": 23.30600580573082}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-108"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2216, "makespan": 86, "avg_agents_density": 0.15588670472943209, "runtime": 16.867416825611144}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-109"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 107, "SoC": 2713, "makespan": 108, "avg_agents_density": 0.1681008441764526, "runtime": 21.294971707277}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-110"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 1032, "makespan": 34, "avg_agents_density": 0.1559288150839113, "runtime": 6.814402722287923}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-111"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 2633, "makespan": 128, "avg_agents_density": 0.19619395633636727, "runtime": 24.77874263888225}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-112"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 832, "makespan": 33, "avg_agents_density": 0.1492070102287666, "runtime": 6.1764849200844765}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-113"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1079, "makespan": 49, "avg_agents_density": 0.14632695453893488, "runtime": 9.936945302411914}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-114"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1390, "makespan": 45, "avg_agents_density": 0.13455571068449085, "runtime": 8.998049114830792}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-115"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 92, "SoC": 1945, "makespan": 93, "avg_agents_density": 0.1670783393514857, "runtime": 18.021623560693115}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-116"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 52, "SoC": 1180, "makespan": 53, "avg_agents_density": 0.15046946547345305, "runtime": 10.506555386353284}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-117"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 120, "SoC": 2684, "makespan": 121, "avg_agents_density": 0.14193833534222067, "runtime": 23.317030069883913}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-118"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.8541666666666666, "CSR": 0.0, "ep_length": 127, "SoC": 2903, "makespan": 128, "avg_agents_density": 0.1430818927080046, "runtime": 24.85184513637796}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-119"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 33, "SoC": 936, "makespan": 34, "avg_agents_density": 0.10869306129429196, "runtime": 6.535039905458689}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-120"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 61, "SoC": 1784, "makespan": 62, "avg_agents_density": 0.17220324079213536, "runtime": 11.82556722825393}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-121"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1287, "makespan": 43, "avg_agents_density": 0.12964351739491006, "runtime": 8.479437077883631}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-122"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 35, "SoC": 856, "makespan": 36, "avg_agents_density": 0.13025645368382038, "runtime": 7.137870636768639}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-123"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 3281, "makespan": 128, "avg_agents_density": 0.1700937094362133, "runtime": 24.992180537898093}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-124"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 1527, "makespan": 73, "avg_agents_density": 0.1527673041302779, "runtime": 14.567972881253809}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-125"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 4210, "makespan": 128, "avg_agents_density": 0.16812665753907266, "runtime": 24.885386566165835}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-126"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 44, "SoC": 1350, "makespan": 45, "avg_agents_density": 0.15607456505094874, "runtime": 8.544871605932713}, "env_grid_search": {"num_agents": 48, "map_name": "validation-mazes-seed-127"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2745, "makespan": 86, "avg_agents_density": 0.1850446967980959, "runtime": 21.902120449580252}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-000"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 127, "SoC": 3867, "makespan": 128, "avg_agents_density": 0.2023519192360067, "runtime": 32.982963101007044}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-001"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 83, "SoC": 2952, "makespan": 84, "avg_agents_density": 0.2045151067416803, "runtime": 22.03141664993018}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-002"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 2427, "makespan": 63, "avg_agents_density": 0.20269525780005637, "runtime": 16.867613843176514}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-003"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 2681, "makespan": 73, "avg_agents_density": 0.2068707704193107, "runtime": 19.083470354788005}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-004"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.796875, "CSR": 0.0, "ep_length": 127, "SoC": 5553, "makespan": 128, "avg_agents_density": 0.20709100918528378, "runtime": 33.893712017685175}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-005"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.78125, "CSR": 0.0, "ep_length": 127, "SoC": 3993, "makespan": 128, "avg_agents_density": 0.20321831383553188, "runtime": 31.77013636706397}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-006"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.546875, "CSR": 0.0, "ep_length": 127, "SoC": 6006, "makespan": 128, "avg_agents_density": 0.2825511089678945, "runtime": 33.3856683219783}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-007"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 72, "SoC": 2797, "makespan": 73, "avg_agents_density": 0.20510503285461887, "runtime": 19.157274554949254}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-008"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 3696, "makespan": 103, "avg_agents_density": 0.23291157003192853, "runtime": 27.571684363298118}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-009"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 81, "SoC": 2642, "makespan": 82, "avg_agents_density": 0.17306651880047133, "runtime": 21.419991639442742}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-010"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.515625, "CSR": 0.0, "ep_length": 127, "SoC": 6819, "makespan": 128, "avg_agents_density": 0.3565305123226625, "runtime": 32.858820418361574}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-011"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 127, "SoC": 3213, "makespan": 128, "avg_agents_density": 0.202603460704428, "runtime": 31.373936402611434}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-012"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 93, "SoC": 2565, "makespan": 94, "avg_agents_density": 0.18824681881917335, "runtime": 22.538352807518095}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-013"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 2375, "makespan": 67, "avg_agents_density": 0.2143427149703918, "runtime": 16.64655001554638}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-014"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 4239, "makespan": 128, "avg_agents_density": 0.22245113415892645, "runtime": 32.54373838054016}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-015"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 127, "SoC": 4432, "makespan": 128, "avg_agents_density": 0.20315436181702035, "runtime": 32.48025579797104}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-016"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1747, "makespan": 56, "avg_agents_density": 0.15289601801096436, "runtime": 15.09259193111211}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-017"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.71875, "CSR": 0.0, "ep_length": 127, "SoC": 5265, "makespan": 128, "avg_agents_density": 0.1935524926947363, "runtime": 32.94833764154464}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-018"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 124, "SoC": 5173, "makespan": 125, "avg_agents_density": 0.19338916326281055, "runtime": 32.31417704047635}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-019"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 115, "SoC": 3786, "makespan": 116, "avg_agents_density": 0.19543490969545857, "runtime": 29.086357816122472}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-020"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 74, "SoC": 2872, "makespan": 75, "avg_agents_density": 0.2036251004541388, "runtime": 19.613397009670734}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-021"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 66, "SoC": 1995, "makespan": 67, "avg_agents_density": 0.1692851784137977, "runtime": 17.27900403784588}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-022"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 127, "SoC": 4217, "makespan": 128, "avg_agents_density": 0.19802706283877647, "runtime": 31.574131408240646}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-023"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 121, "SoC": 3556, "makespan": 122, "avg_agents_density": 0.18774940487154654, "runtime": 30.743121733423322}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-024"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 985, "makespan": 33, "avg_agents_density": 0.17749657026420704, "runtime": 7.735370189882815}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-025"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 2214, "makespan": 63, "avg_agents_density": 0.17510380756742655, "runtime": 17.037713122554123}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-026"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 3942, "makespan": 128, "avg_agents_density": 0.1854849742381165, "runtime": 32.84267387771979}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-027"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 5547, "makespan": 128, "avg_agents_density": 0.23478042596677368, "runtime": 33.7667642980814}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-028"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 78, "SoC": 3174, "makespan": 79, "avg_agents_density": 0.22064569501996859, "runtime": 21.002719052135944}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-029"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 127, "SoC": 3984, "makespan": 128, "avg_agents_density": 0.21833349678953726, "runtime": 33.87410001736134}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-030"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 67, "SoC": 2041, "makespan": 68, "avg_agents_density": 0.20252672612790115, "runtime": 17.829518551472574}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-031"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 116, "SoC": 4097, "makespan": 117, "avg_agents_density": 0.21470415507514648, "runtime": 29.483557774685323}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-032"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 5837, "makespan": 128, "avg_agents_density": 0.2514925646404972, "runtime": 34.00858760718256}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-033"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 102, "SoC": 4161, "makespan": 103, "avg_agents_density": 0.2599066736379815, "runtime": 26.395661080256104}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-034"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 80, "SoC": 2612, "makespan": 81, "avg_agents_density": 0.24881730483594405, "runtime": 20.41899893572554}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-035"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 2740, "makespan": 85, "avg_agents_density": 0.21100361359479994, "runtime": 21.71291142795235}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-036"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 127, "SoC": 4598, "makespan": 128, "avg_agents_density": 0.2380463441488922, "runtime": 32.04324314184487}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-037"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 2144, "makespan": 54, "avg_agents_density": 0.18374049123990552, "runtime": 13.963127263356}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-038"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 113, "SoC": 4467, "makespan": 114, "avg_agents_density": 0.21295400046760776, "runtime": 29.774040361400694}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-039"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 127, "SoC": 5048, "makespan": 128, "avg_agents_density": 0.19714891966644, "runtime": 31.87713827053085}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-040"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.59375, "CSR": 0.0, "ep_length": 127, "SoC": 6133, "makespan": 128, "avg_agents_density": 0.23588016852928143, "runtime": 33.30945812584832}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-041"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 2998, "makespan": 77, "avg_agents_density": 0.2126875551925444, "runtime": 19.87053208425641}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-042"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1329, "makespan": 44, "avg_agents_density": 0.15037082606794677, "runtime": 10.715546248015016}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-043"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 68, "SoC": 2480, "makespan": 69, "avg_agents_density": 0.19931740659961045, "runtime": 18.070637778379023}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-044"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.703125, "CSR": 0.0, "ep_length": 127, "SoC": 5456, "makespan": 128, "avg_agents_density": 0.2403173527253057, "runtime": 32.747102375142276}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-045"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1891, "makespan": 51, "avg_agents_density": 0.16773503388029812, "runtime": 13.419632231350988}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-046"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.9375, "CSR": 0.0, "ep_length": 127, "SoC": 4630, "makespan": 128, "avg_agents_density": 0.20480454308588086, "runtime": 32.23982693627477}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-047"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 109, "SoC": 3619, "makespan": 110, "avg_agents_density": 0.19445811520173534, "runtime": 29.40657086763531}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-048"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 76, "SoC": 3122, "makespan": 77, "avg_agents_density": 0.22485877101189217, "runtime": 20.042316175997257}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-049"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 109, "SoC": 3663, "makespan": 110, "avg_agents_density": 0.19193796723877987, "runtime": 29.214989480096847}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-050"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 114, "SoC": 3944, "makespan": 115, "avg_agents_density": 0.2178496664992337, "runtime": 29.020901528187096}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-051"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 127, "SoC": 4452, "makespan": 128, "avg_agents_density": 0.17162497078045885, "runtime": 33.769226871896535}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-052"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.359375, "CSR": 0.0, "ep_length": 127, "SoC": 6673, "makespan": 128, "avg_agents_density": 0.3815031816117762, "runtime": 33.49893751274794}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-053"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 127, "SoC": 3547, "makespan": 128, "avg_agents_density": 0.19745344079768656, "runtime": 33.816613755654544}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-054"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 107, "SoC": 3887, "makespan": 108, "avg_agents_density": 0.19735008710274324, "runtime": 27.893648811616004}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-055"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1292, "makespan": 39, "avg_agents_density": 0.16185102312091387, "runtime": 9.854181856382638}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-056"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 127, "SoC": 5070, "makespan": 128, "avg_agents_density": 0.2293902203395769, "runtime": 32.81954869814217}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-057"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.484375, "CSR": 0.0, "ep_length": 127, "SoC": 7057, "makespan": 128, "avg_agents_density": 0.23773694274031495, "runtime": 33.891641923226416}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-058"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 127, "SoC": 4505, "makespan": 128, "avg_agents_density": 0.18667561942997343, "runtime": 32.325142595451325}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-059"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 41, "SoC": 1296, "makespan": 42, "avg_agents_density": 0.17705661571523376, "runtime": 10.769458311144263}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-060"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 5564, "makespan": 128, "avg_agents_density": 0.1995569164388958, "runtime": 32.425098065752536}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-061"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.859375, "CSR": 0.0, "ep_length": 127, "SoC": 5298, "makespan": 128, "avg_agents_density": 0.223912983593371, "runtime": 33.74332651589066}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-062"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.765625, "CSR": 0.0, "ep_length": 127, "SoC": 5825, "makespan": 128, "avg_agents_density": 0.2330030049814949, "runtime": 32.64255241909996}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-063"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 98, "SoC": 3991, "makespan": 99, "avg_agents_density": 0.2071465682164122, "runtime": 26.048722358886153}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-064"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 127, "SoC": 6222, "makespan": 128, "avg_agents_density": 0.2635476338106472, "runtime": 34.1743797454983}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-065"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 127, "SoC": 4240, "makespan": 128, "avg_agents_density": 0.19700053719029273, "runtime": 32.88923803484067}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-066"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 47, "SoC": 1830, "makespan": 48, "avg_agents_density": 0.162994250128885, "runtime": 12.708877665456384}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-067"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 127, "SoC": 4989, "makespan": 128, "avg_agents_density": 0.2006077165097871, "runtime": 33.05235410341993}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-068"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.875, "CSR": 0.0, "ep_length": 127, "SoC": 5876, "makespan": 128, "avg_agents_density": 0.25048455829670924, "runtime": 33.596387196332216}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-069"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 115, "SoC": 4278, "makespan": 116, "avg_agents_density": 0.21338834473613308, "runtime": 29.95901409117505}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-070"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 91, "SoC": 4032, "makespan": 92, "avg_agents_density": 0.21521745353091717, "runtime": 23.874492428731173}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-071"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 39, "SoC": 1167, "makespan": 40, "avg_agents_density": 0.13161074955092789, "runtime": 11.234496704302728}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-072"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 100, "SoC": 3087, "makespan": 101, "avg_agents_density": 0.22030544381839878, "runtime": 25.128803468309343}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-073"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.859375, "CSR": 0.0, "ep_length": 127, "SoC": 5185, "makespan": 128, "avg_agents_density": 0.19757391583695028, "runtime": 32.57660018000752}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-074"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 75, "SoC": 1812, "makespan": 76, "avg_agents_density": 0.1426399483802789, "runtime": 19.943340294528753}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-075"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.984375, "CSR": 0.0, "ep_length": 127, "SoC": 4249, "makespan": 128, "avg_agents_density": 0.2065307984111924, "runtime": 32.878559689968824}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-076"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.75, "CSR": 0.0, "ep_length": 127, "SoC": 5508, "makespan": 128, "avg_agents_density": 0.19134286212526752, "runtime": 33.156382326968014}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-077"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 84, "SoC": 2847, "makespan": 85, "avg_agents_density": 0.20049915414283503, "runtime": 21.481464317068458}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-078"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 43, "SoC": 1498, "makespan": 44, "avg_agents_density": 0.18021461154007087, "runtime": 11.047594986390322}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-079"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 32, "SoC": 1226, "makespan": 33, "avg_agents_density": 0.13260967232043022, "runtime": 8.911235604900867}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-080"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 69, "SoC": 2286, "makespan": 70, "avg_agents_density": 0.21623651377077419, "runtime": 18.75855900114402}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-081"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.828125, "CSR": 0.0, "ep_length": 127, "SoC": 5529, "makespan": 128, "avg_agents_density": 0.20654503761918475, "runtime": 28.335688338615}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-082"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 55, "SoC": 1475, "makespan": 56, "avg_agents_density": 0.16616875522368493, "runtime": 14.152978661470115}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-083"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 127, "SoC": 6150, "makespan": 128, "avg_agents_density": 0.19371163029824484, "runtime": 31.322220070287585}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-084"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.59375, "CSR": 0.0, "ep_length": 127, "SoC": 5504, "makespan": 128, "avg_agents_density": 0.2489381306203283, "runtime": 33.04665081668645}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-085"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 53, "SoC": 1720, "makespan": 54, "avg_agents_density": 0.18643680314552685, "runtime": 12.236276175361127}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-086"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 123, "SoC": 5345, "makespan": 124, "avg_agents_density": 0.21751425474121353, "runtime": 32.09955345932394}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-087"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.671875, "CSR": 0.0, "ep_length": 127, "SoC": 6947, "makespan": 128, "avg_agents_density": 0.22971366560252218, "runtime": 35.94792101159692}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-088"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 85, "SoC": 2700, "makespan": 86, "avg_agents_density": 0.19532015505330538, "runtime": 22.14070332655683}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-089"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 127, "SoC": 3451, "makespan": 128, "avg_agents_density": 0.2000627207979849, "runtime": 32.644160606432706}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-090"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 112, "SoC": 2816, "makespan": 113, "avg_agents_density": 0.19761889386457943, "runtime": 27.774533429648727}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-091"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 38, "SoC": 1422, "makespan": 39, "avg_agents_density": 0.16136490704698966, "runtime": 10.283760892692953}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-092"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 125, "SoC": 4405, "makespan": 126, "avg_agents_density": 0.20033265686156798, "runtime": 31.839290621690452}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-093"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.921875, "CSR": 0.0, "ep_length": 127, "SoC": 5390, "makespan": 128, "avg_agents_density": 0.21746256573929132, "runtime": 33.0455159265548}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-094"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 127, "SoC": 4974, "makespan": 128, "avg_agents_density": 0.19429689139895123, "runtime": 33.33619039459154}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-095"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 115, "SoC": 3438, "makespan": 116, "avg_agents_density": 0.18321950375262053, "runtime": 29.598034837283194}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-096"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 5011, "makespan": 128, "avg_agents_density": 0.2478799486458096, "runtime": 32.48461093241349}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-097"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.8125, "CSR": 0.0, "ep_length": 127, "SoC": 6104, "makespan": 128, "avg_agents_density": 0.2542789416494447, "runtime": 33.44429575512186}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-098"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.890625, "CSR": 0.0, "ep_length": 127, "SoC": 3742, "makespan": 128, "avg_agents_density": 0.2112454626532645, "runtime": 33.12418785877526}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-099"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 64, "SoC": 2453, "makespan": 65, "avg_agents_density": 0.19462850516438793, "runtime": 17.176790561527014}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-100"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 97, "SoC": 3576, "makespan": 98, "avg_agents_density": 0.2158696333072899, "runtime": 25.121979414485395}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-101"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.828125, "CSR": 0.0, "ep_length": 127, "SoC": 4420, "makespan": 128, "avg_agents_density": 0.24000868663382297, "runtime": 33.24465735303238}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-102"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 117, "SoC": 3941, "makespan": 118, "avg_agents_density": 0.1957047945670049, "runtime": 30.632080868352205}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-103"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.96875, "CSR": 0.0, "ep_length": 127, "SoC": 4071, "makespan": 128, "avg_agents_density": 0.18170049742877584, "runtime": 33.048829786945134}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-104"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.796875, "CSR": 0.0, "ep_length": 127, "SoC": 5669, "makespan": 128, "avg_agents_density": 0.18308594087058366, "runtime": 33.09112108219415}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-105"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 42, "SoC": 1356, "makespan": 43, "avg_agents_density": 0.16875498374658016, "runtime": 11.851952938828617}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-106"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.6875, "CSR": 0.0, "ep_length": 127, "SoC": 6181, "makespan": 128, "avg_agents_density": 0.2551469230002008, "runtime": 33.39504388626665}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-107"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 127, "SoC": 4277, "makespan": 128, "avg_agents_density": 0.2355170025329718, "runtime": 33.89856493473053}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-108"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.78125, "CSR": 0.0, "ep_length": 127, "SoC": 5596, "makespan": 128, "avg_agents_density": 0.22650730787773038, "runtime": 32.94071154203266}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-109"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 127, "SoC": 5031, "makespan": 128, "avg_agents_density": 0.24502929937009604, "runtime": 32.58183486852795}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-110"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 51, "SoC": 1668, "makespan": 52, "avg_agents_density": 0.1938864895892513, "runtime": 12.715779815334827}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-111"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.84375, "CSR": 0.0, "ep_length": 127, "SoC": 5200, "makespan": 128, "avg_agents_density": 0.24285063411337204, "runtime": 33.53450468741357}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-112"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1379, "makespan": 41, "avg_agents_density": 0.19964032486379324, "runtime": 10.628484057728201}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-113"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 1769, "makespan": 51, "avg_agents_density": 0.1971205525814008, "runtime": 13.053334559313953}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-114"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 101, "SoC": 3071, "makespan": 102, "avg_agents_density": 0.19080726528437114, "runtime": 25.896725811529905}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-115"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 109, "SoC": 4063, "makespan": 110, "avg_agents_density": 0.23689666823017588, "runtime": 27.99990488216281}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-116"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.953125, "CSR": 0.0, "ep_length": 127, "SoC": 2738, "makespan": 128, "avg_agents_density": 0.17878637182030324, "runtime": 31.74681732431054}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-117"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.90625, "CSR": 0.0, "ep_length": 127, "SoC": 5205, "makespan": 128, "avg_agents_density": 0.20755517587837988, "runtime": 32.77125518163666}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-118"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 123, "SoC": 5139, "makespan": 124, "avg_agents_density": 0.18088779160005652, "runtime": 31.82094729039818}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-119"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 40, "SoC": 1481, "makespan": 41, "avg_agents_density": 0.1476321064947752, "runtime": 10.723436690401286}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-120"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 90, "SoC": 2986, "makespan": 91, "avg_agents_density": 0.21886250068763374, "runtime": 22.13740394450724}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-121"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 50, "SoC": 2105, "makespan": 51, "avg_agents_density": 0.16941570794121277, "runtime": 13.200454343575984}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-122"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 48, "SoC": 1403, "makespan": 49, "avg_agents_density": 0.17900967568900567, "runtime": 12.949371081776917}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-123"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.53125, "CSR": 0.0, "ep_length": 127, "SoC": 5309, "makespan": 128, "avg_agents_density": 0.31221935322745814, "runtime": 33.786539936903864}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-124"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 71, "SoC": 3025, "makespan": 72, "avg_agents_density": 0.19520182480880527, "runtime": 18.576499215327203}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-125"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 0.40625, "CSR": 0.0, "ep_length": 127, "SoC": 6561, "makespan": 128, "avg_agents_density": 0.2688633478271245, "runtime": 33.95226761512458}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-126"}, "algorithm": "MA-MAPF-GPT-5actions"}, {"metrics": {"ISR": 1.0, "CSR": 1.0, "ep_length": 62, "SoC": 2142, "makespan": 63, "avg_agents_density": 0.19683379739551224, "runtime": 16.80538849113509}, "env_grid_search": {"num_agents": 64, "map_name": "validation-mazes-seed-127"}, "algorithm": "MA-MAPF-GPT-5actions"}]